{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25f531ad",
   "metadata": {},
   "source": [
    "# Bias - Variance Decomposition\n",
    "\n",
    "- Dataset: tranfusion\n",
    "- Discretization: unsupervised: EWD, EFD, FFD\n",
    "- Model: Categorical Naive Bayes\n",
    "- Updated: 07/03/23\n",
    "\n",
    "Process:\n",
    "- Load pre-trained model (sav)\n",
    "- Run bias-variance decomposition\n",
    "- Save result to \"transfusion_evaluation_cnb.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41ccebb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import skops.io as sio\n",
    "import mlxtend\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b563481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For model evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import zero_one_loss\n",
    "#This library is used to decompose bias and variance in our models\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfae4107",
   "metadata": {},
   "outputs": [],
   "source": [
    "import six\n",
    "import sys\n",
    "sys.modules['sklearn.externals.six'] = six"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1506c69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import \n",
    "import skops.io as sio\n",
    "import joblib\n",
    "import mlxtend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c62f4c",
   "metadata": {},
   "source": [
    "# 1. EWD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd585fc",
   "metadata": {},
   "source": [
    "## EWD, k = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb54debc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 748 entries, 0 to 747\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype\n",
      "---  ------      --------------  -----\n",
      " 0   Unnamed: 0  748 non-null    int64\n",
      " 1   recency     748 non-null    int64\n",
      " 2   frequency   748 non-null    int64\n",
      " 3   monetary    748 non-null    int64\n",
      " 4   time        748 non-null    int64\n",
      " 5   label       748 non-null    int64\n",
      "dtypes: int64(6)\n",
      "memory usage: 35.2 KB\n",
      "(748, 5) (748,)\n",
      "Class representation - original:  Counter({0: 570, 1: 178})\n",
      "Class representation - training data:  Counter({0: 428, 1: 133})\n",
      "Class representation - testing data:  Counter({0: 142, 1: 45})\n"
     ]
    }
   ],
   "source": [
    "# Data Prep\n",
    "# Complete code for data preperation\n",
    "# Read data\n",
    "df_ewd1 = pd.read_csv('tranfusion_ewd1.csv')\n",
    "disc = 'EWD'\n",
    "k = 4\n",
    "\n",
    "df_ewd1.info()\n",
    "data = df_ewd1.values\n",
    "data.shape\n",
    "\n",
    "features = df_ewd1.drop('label', axis = 1).columns\n",
    "\n",
    "# separate the data into X and y\n",
    "X = data[:, : len(features)]\n",
    "Y = data[:,-1]\n",
    "#X = df_ewd1[features]\n",
    "#Y = df_ewd1['label']\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "# Split train test\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state = 30, stratify=Y)\n",
    "\n",
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(Y)) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test)) \n",
    "\n",
    "# Check number of categories for features\n",
    "n_categories = df_ewd1[features].nunique()\n",
    "\n",
    "from imblearn.combine import SMOTEENN\n",
    "smt_enn = SMOTEENN(random_state=42)\n",
    "x_resample, y_resample = smt_enn.fit_resample(x_train, y_train)\n",
    "# # Check labels in traning dataset after SMOTE\n",
    "# pd.Series(y_resample) \\\n",
    "# .value_counts() \\\n",
    "# .plot(kind='bar', title='Class distribution after applying SMOTE ENN', xlabel='Blood donating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2842186d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tranfusion_CNB_EWD_4.sav\n"
     ]
    }
   ],
   "source": [
    "# Load models\n",
    "k=4\n",
    "model = 'CNB'\n",
    "dataset = 'tranfusion'\n",
    "discretizer = 'EWD'\n",
    "disc_param = 'k = 4'\n",
    "model_name = f\"{dataset}_{model}_{discretizer}_{k}.sav\"\n",
    "print(model_name)\n",
    "loaded_cnb = joblib.load(model_name)\n",
    "y_pred_cnb = loaded_cnb.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8474592a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decomposition\n",
    "f = open(\"transfusion_evaluation_cnb.txt\", \"a\")\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "loaded_cnb, x_resample, y_resample, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "\n",
    "print(f'Evaluation result: {model}, {discretizer}, {disc_param}', file = f)\n",
    "print('Average expected loss: %.3f' % avg_expected_loss, file = f)\n",
    "print('Average bias: %.3f' % avg_bias, file = f)\n",
    "print('Average variance: %.3f' % avg_var, file = f)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_cnb), file = f)\n",
    "\n",
    "end = time.time()\n",
    "print(f'Execution time {model}- default, {disc}, k = {k} is: {end - start}.', file = f) # Total time execution\n",
    "print('=='*20, file = f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067d47b0",
   "metadata": {},
   "source": [
    "## EWD, k = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecf38b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 748 entries, 0 to 747\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype\n",
      "---  ------      --------------  -----\n",
      " 0   Unnamed: 0  748 non-null    int64\n",
      " 1   recency     748 non-null    int64\n",
      " 2   frequency   748 non-null    int64\n",
      " 3   monetary    748 non-null    int64\n",
      " 4   time        748 non-null    int64\n",
      " 5   label       748 non-null    int64\n",
      "dtypes: int64(6)\n",
      "memory usage: 35.2 KB\n",
      "(748, 5) (748,)\n",
      "Class representation - original:  Counter({0: 570, 1: 178})\n",
      "Class representation - training data:  Counter({0: 428, 1: 133})\n",
      "Class representation - testing data:  Counter({0: 142, 1: 45})\n"
     ]
    }
   ],
   "source": [
    "# Data Prep\n",
    "# Complete code for data preperation\n",
    "# Read data\n",
    "df_ewd2 = pd.read_csv('tranfusion_ewd2.csv')\n",
    "disc = 'EWD'\n",
    "k = 7\n",
    "\n",
    "df_ewd2.info()\n",
    "data = df_ewd2.values\n",
    "data.shape\n",
    "\n",
    "features = df_ewd2.drop('label', axis = 1).columns\n",
    "\n",
    "# separate the data into X and y\n",
    "X = data[:, : len(features)]\n",
    "Y = data[:,-1]\n",
    "#X = df_ewd2[features]\n",
    "#Y = df_ewd2['label']\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "# Split train test\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state = 30, stratify=Y)\n",
    "\n",
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(Y)) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test)) \n",
    "\n",
    "# Check number of categories for features\n",
    "n_categories = df_ewd2[features].nunique()\n",
    "\n",
    "from imblearn.combine import SMOTEENN\n",
    "smt_enn = SMOTEENN(random_state=42)\n",
    "x_resample, y_resample = smt_enn.fit_resample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59a87fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tranfusion_CNB_EWD_7.sav\n"
     ]
    }
   ],
   "source": [
    "# Load models\n",
    "k=7\n",
    "model = 'CNB'\n",
    "dataset = 'tranfusion'\n",
    "discretizer = 'EWD'\n",
    "disc_param = 'k = 7'\n",
    "model_name = f\"{dataset}_{model}_{discretizer}_{k}.sav\"\n",
    "print(model_name)\n",
    "loaded_cnb = joblib.load(model_name)\n",
    "y_pred_cnb = loaded_cnb.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68aab87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decomposition\n",
    "f = open(\"transfusion_evaluation_cnb.txt\", \"a\")\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "loaded_cnb, x_resample, y_resample, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "\n",
    "print(f'Evaluation result: {model}, {discretizer}, {disc_param}', file = f)\n",
    "print('Average expected loss: %.3f' % avg_expected_loss, file = f)\n",
    "print('Average bias: %.3f' % avg_bias, file = f)\n",
    "print('Average variance: %.3f' % avg_var, file = f)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_cnb), file = f)\n",
    "\n",
    "end = time.time()\n",
    "print(f'Execution time {model}- default, {disc}, k = {k} is: {end - start}.', file = f) # Total time execution\n",
    "print('=='*20, file = f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410ee7c1",
   "metadata": {},
   "source": [
    "## EWD, k = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92c7e4ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 748 entries, 0 to 747\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype\n",
      "---  ------      --------------  -----\n",
      " 0   Unnamed: 0  748 non-null    int64\n",
      " 1   recency     748 non-null    int64\n",
      " 2   frequency   748 non-null    int64\n",
      " 3   monetary    748 non-null    int64\n",
      " 4   time        748 non-null    int64\n",
      " 5   label       748 non-null    int64\n",
      "dtypes: int64(6)\n",
      "memory usage: 35.2 KB\n",
      "(748, 5) (748,)\n",
      "Class representation - original:  Counter({0: 570, 1: 178})\n",
      "Class representation - training data:  Counter({0: 428, 1: 133})\n",
      "Class representation - testing data:  Counter({0: 142, 1: 45})\n"
     ]
    }
   ],
   "source": [
    "# Data Prep\n",
    "# Complete code for data preperation\n",
    "# Read data\n",
    "df_ewd3 = pd.read_csv('tranfusion_ewd3.csv')\n",
    "disc = 'EWD'\n",
    "k = 10\n",
    "\n",
    "df_ewd3.info()\n",
    "data = df_ewd3.values\n",
    "data.shape\n",
    "\n",
    "features = df_ewd3.drop('label', axis = 1).columns\n",
    "\n",
    "# separate the data into X and y\n",
    "X = data[:, : len(features)]\n",
    "Y = data[:,-1]\n",
    "#X = df_ewd3[features]\n",
    "#Y = df_ewd3['label']\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "# Split train test\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state = 30, stratify=Y)\n",
    "\n",
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(Y)) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test)) \n",
    "\n",
    "# Check number of categories for features\n",
    "n_categories = df_ewd3[features].nunique()\n",
    "\n",
    "from imblearn.combine import SMOTEENN\n",
    "smt_enn = SMOTEENN(random_state=42)\n",
    "x_resample, y_resample = smt_enn.fit_resample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64277f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tranfusion_CNB_EWD_10.sav\n"
     ]
    }
   ],
   "source": [
    "# Load models\n",
    "k=10\n",
    "model = 'CNB'\n",
    "dataset = 'tranfusion'\n",
    "discretizer = 'EWD'\n",
    "disc_param = 'k = 10'\n",
    "model_name = f\"{dataset}_{model}_{discretizer}_{k}.sav\"\n",
    "print(model_name)\n",
    "loaded_cnb = joblib.load(model_name)\n",
    "y_pred_cnb = loaded_cnb.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a672e659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decomposition\n",
    "f = open(\"transfusion_evaluation_cnb.txt\", \"a\")\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "loaded_cnb, x_resample, y_resample, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "\n",
    "print(f'Evaluation result: {model}, {discretizer}, {disc_param}', file = f)\n",
    "print('Average expected loss: %.3f' % avg_expected_loss, file = f)\n",
    "print('Average bias: %.3f' % avg_bias, file = f)\n",
    "print('Average variance: %.3f' % avg_var, file = f)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_cnb), file = f)\n",
    "\n",
    "end = time.time()\n",
    "print(f'Execution time {model}- default, {disc}, k = {k} is: {end - start}.', file = f) # Total time execution\n",
    "print('=='*20, file = f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780c5d70",
   "metadata": {},
   "source": [
    "# 2. EFD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72dcb79",
   "metadata": {},
   "source": [
    "# EFD, k = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "170fa18b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 748 entries, 0 to 747\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype\n",
      "---  ------      --------------  -----\n",
      " 0   Unnamed: 0  748 non-null    int64\n",
      " 1   recency     748 non-null    int64\n",
      " 2   frequency   748 non-null    int64\n",
      " 3   monetary    748 non-null    int64\n",
      " 4   time        748 non-null    int64\n",
      " 5   label       748 non-null    int64\n",
      "dtypes: int64(6)\n",
      "memory usage: 35.2 KB\n",
      "(748, 5) (748,)\n",
      "Class representation - original:  Counter({0: 570, 1: 178})\n",
      "Class representation - training data:  Counter({0: 428, 1: 133})\n",
      "Class representation - testing data:  Counter({0: 142, 1: 45})\n"
     ]
    }
   ],
   "source": [
    "# Data Prep\n",
    "# Complete code for data preperation\n",
    "# Read data\n",
    "df_efd1 = pd.read_csv('tranfusion_efd1.csv')\n",
    "disc = 'EFD'\n",
    "k = 4\n",
    "\n",
    "df_efd1.info()\n",
    "data = df_efd1.values\n",
    "data.shape\n",
    "\n",
    "features = df_efd1.drop('label', axis = 1).columns\n",
    "\n",
    "# separate the data into X and y\n",
    "X = data[:, : len(features)]\n",
    "Y = data[:,-1]\n",
    "#X = df_efd1[features]\n",
    "#Y = df_efd1['label']\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "# Split train test\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state = 30, stratify=Y)\n",
    "\n",
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(Y)) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test)) \n",
    "\n",
    "# Check number of categories for features\n",
    "n_categories = df_efd1[features].nunique()\n",
    "\n",
    "from imblearn.combine import SMOTEENN\n",
    "smt_enn = SMOTEENN(random_state=42)\n",
    "x_resample, y_resample = smt_enn.fit_resample(x_train, y_train)\n",
    "# # Check labels in traning dataset after SMOTE\n",
    "# pd.Series(y_resample) \\\n",
    "# .value_counts() \\\n",
    "# .plot(kind='bar', title='Class distribution after applying SMOTE ENN', xlabel='Blood donating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c570716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tranfusion_CNB_EFD_4.sav\n"
     ]
    }
   ],
   "source": [
    "# Load models\n",
    "k=4\n",
    "model = 'CNB'\n",
    "dataset = 'tranfusion'\n",
    "discretizer = 'EFD'\n",
    "disc_param = 'k = 4'\n",
    "model_name = f\"{dataset}_{model}_{discretizer}_{k}.sav\"\n",
    "print(model_name)\n",
    "loaded_cnb = joblib.load(model_name)\n",
    "y_pred_cnb = loaded_cnb.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "382b6786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decomposition\n",
    "f = open(\"transfusion_evaluation_cnb.txt\", \"a\")\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "loaded_cnb, x_resample, y_resample, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "\n",
    "print(f'Evaluation result: {model}, {discretizer}, {disc_param}', file = f)\n",
    "print('Average expected loss: %.3f' % avg_expected_loss, file = f)\n",
    "print('Average bias: %.3f' % avg_bias, file = f)\n",
    "print('Average variance: %.3f' % avg_var, file = f)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_cnb), file = f)\n",
    "\n",
    "end = time.time()\n",
    "print(f'Execution time {model}- default, {disc}, k = {k} is: {end - start}.', file = f) # Total time execution\n",
    "print('=='*20, file = f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f193d581",
   "metadata": {},
   "source": [
    "## EFD, k = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90230be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 748 entries, 0 to 747\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype\n",
      "---  ------      --------------  -----\n",
      " 0   Unnamed: 0  748 non-null    int64\n",
      " 1   recency     748 non-null    int64\n",
      " 2   frequency   748 non-null    int64\n",
      " 3   monetary    748 non-null    int64\n",
      " 4   time        748 non-null    int64\n",
      " 5   label       748 non-null    int64\n",
      "dtypes: int64(6)\n",
      "memory usage: 35.2 KB\n",
      "(748, 5) (748,)\n",
      "Class representation - original:  Counter({0: 570, 1: 178})\n",
      "Class representation - training data:  Counter({0: 428, 1: 133})\n",
      "Class representation - testing data:  Counter({0: 142, 1: 45})\n"
     ]
    }
   ],
   "source": [
    "# Data Prep\n",
    "# Complete code for data preperation\n",
    "# Read data\n",
    "df_efd2 = pd.read_csv('tranfusion_efd2.csv')\n",
    "disc = 'efd'\n",
    "k = 7\n",
    "\n",
    "df_efd2.info()\n",
    "data = df_efd2.values\n",
    "data.shape\n",
    "\n",
    "features = df_efd2.drop('label', axis = 1).columns\n",
    "\n",
    "# separate the data into X and y\n",
    "X = data[:, : len(features)]\n",
    "Y = data[:,-1]\n",
    "#X = df_efd2[features]\n",
    "#Y = df_efd2['label']\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "# Split train test\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state = 30, stratify=Y)\n",
    "\n",
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(Y)) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test)) \n",
    "\n",
    "# Check number of categories for features\n",
    "n_categories = df_efd2[features].nunique()\n",
    "\n",
    "from imblearn.combine import SMOTEENN\n",
    "smt_enn = SMOTEENN(random_state=42)\n",
    "x_resample, y_resample = smt_enn.fit_resample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ef1f941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tranfusion_CNB_EFD_7.sav\n"
     ]
    }
   ],
   "source": [
    "# Load models\n",
    "k=7\n",
    "model = 'CNB'\n",
    "dataset = 'tranfusion'\n",
    "discretizer = 'EFD'\n",
    "disc_param = 'k = 7'\n",
    "model_name = f\"{dataset}_{model}_{discretizer}_{k}.sav\"\n",
    "print(model_name)\n",
    "loaded_cnb = joblib.load(model_name)\n",
    "y_pred_cnb = loaded_cnb.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "11bc26ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decomposition\n",
    "f = open(\"transfusion_evaluation_cnb.txt\", \"a\")\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "loaded_cnb, x_resample, y_resample, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "\n",
    "print(f'Evaluation result: {model}, {discretizer}, {disc_param}', file = f)\n",
    "print('Average expected loss: %.3f' % avg_expected_loss, file = f)\n",
    "print('Average bias: %.3f' % avg_bias, file = f)\n",
    "print('Average variance: %.3f' % avg_var, file = f)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_cnb), file = f)\n",
    "\n",
    "end = time.time()\n",
    "print(f'Execution time {model}- default, {disc}, k = {k} is: {end - start}.', file = f) # Total time execution\n",
    "print('=='*20, file = f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa23913b",
   "metadata": {},
   "source": [
    "## EFD, k = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "43bfc1e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 748 entries, 0 to 747\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype\n",
      "---  ------      --------------  -----\n",
      " 0   Unnamed: 0  748 non-null    int64\n",
      " 1   recency     748 non-null    int64\n",
      " 2   frequency   748 non-null    int64\n",
      " 3   monetary    748 non-null    int64\n",
      " 4   time        748 non-null    int64\n",
      " 5   label       748 non-null    int64\n",
      "dtypes: int64(6)\n",
      "memory usage: 35.2 KB\n",
      "(748, 5) (748,)\n",
      "Class representation - original:  Counter({0: 570, 1: 178})\n",
      "Class representation - training data:  Counter({0: 428, 1: 133})\n",
      "Class representation - testing data:  Counter({0: 142, 1: 45})\n"
     ]
    }
   ],
   "source": [
    "# Data Prep\n",
    "# Complete code for data preperation\n",
    "# Read data\n",
    "df_efd3 = pd.read_csv('tranfusion_efd3.csv')\n",
    "disc = 'EFD'\n",
    "k = 10\n",
    "\n",
    "df_efd3.info()\n",
    "data = df_efd3.values\n",
    "data.shape\n",
    "\n",
    "features = df_efd3.drop('label', axis = 1).columns\n",
    "\n",
    "# separate the data into X and y\n",
    "X = data[:, : len(features)]\n",
    "Y = data[:,-1]\n",
    "#X = df_efd3[features]\n",
    "#Y = df_efd3['label']\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "# Split train test\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state = 30, stratify=Y)\n",
    "\n",
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(Y)) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test)) \n",
    "\n",
    "# Check number of categories for features\n",
    "n_categories = df_efd3[features].nunique()\n",
    "\n",
    "from imblearn.combine import SMOTEENN\n",
    "smt_enn = SMOTEENN(random_state=42)\n",
    "x_resample, y_resample = smt_enn.fit_resample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "156ca90e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tranfusion_CNB_EFD_10.sav\n"
     ]
    }
   ],
   "source": [
    "# Load models\n",
    "k=10\n",
    "model = 'CNB'\n",
    "dataset = 'tranfusion'\n",
    "discretizer = 'EFD'\n",
    "disc_param = 'k = 10'\n",
    "model_name = f\"{dataset}_{model}_{discretizer}_{k}.sav\"\n",
    "print(model_name)\n",
    "loaded_cnb = joblib.load(model_name)\n",
    "y_pred_cnb = loaded_cnb.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c9c9fe8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decomposition\n",
    "f = open(\"transfusion_evaluation_cnb.txt\", \"a\")\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "loaded_cnb, x_resample, y_resample, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "\n",
    "print(f'Evaluation result: {model}, {discretizer}, {disc_param}', file = f)\n",
    "print('Average expected loss: %.3f' % avg_expected_loss, file = f)\n",
    "print('Average bias: %.3f' % avg_bias, file = f)\n",
    "print('Average variance: %.3f' % avg_var, file = f)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_cnb), file = f)\n",
    "\n",
    "end = time.time()\n",
    "print(f'Execution time {model}- default, {disc}, k = {k} is: {end - start}.', file = f) # Total time execution\n",
    "print('=='*20, file = f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e0155b",
   "metadata": {},
   "source": [
    "# 3. FFD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d0c4eb",
   "metadata": {},
   "source": [
    "## FFD, m = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f503cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 748 entries, 0 to 747\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype\n",
      "---  ------      --------------  -----\n",
      " 0   Unnamed: 0  748 non-null    int64\n",
      " 1   recency     748 non-null    int64\n",
      " 2   frequency   748 non-null    int64\n",
      " 3   monetary    748 non-null    int64\n",
      " 4   time        748 non-null    int64\n",
      " 5   label       748 non-null    int64\n",
      "dtypes: int64(6)\n",
      "memory usage: 35.2 KB\n",
      "(748, 5) (748,)\n",
      "Class representation - original:  Counter({0: 570, 1: 178})\n",
      "Class representation - training data:  Counter({0: 428, 1: 133})\n",
      "Class representation - testing data:  Counter({0: 142, 1: 45})\n"
     ]
    }
   ],
   "source": [
    "# Complete code for data preperation\n",
    "# Read data\n",
    "df_ffd1 = pd.read_csv('tranfusion_ffd1.csv')\n",
    "disc = 'FFD'\n",
    "m = 10\n",
    "\n",
    "df_ffd1.info()\n",
    "data = df_ffd1.values\n",
    "data.shape\n",
    "\n",
    "features = df_ffd1.drop('label', axis = 1).columns\n",
    "\n",
    "# separate the data into X and y\n",
    "X = data[:, : len(features)]\n",
    "Y = data[:,-1]\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "# Split train test\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state = 30, stratify = Y)\n",
    "\n",
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(Y)) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test)) \n",
    "\n",
    "# Check number of categories for features\n",
    "n_categories = df_ffd1[features].nunique()\n",
    "\n",
    "from imblearn.combine import SMOTEENN\n",
    "smt_enn = SMOTEENN(random_state=42)\n",
    "x_resample, y_resample = smt_enn.fit_resample(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "932b4921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models\n",
    "model = 'CNB'\n",
    "dataset = 'tranfusion'\n",
    "discretizer = 'FFD'\n",
    "disc_param = 'm = 10'\n",
    "\n",
    "model_name = f\"{dataset}_{model}_{discretizer}_{m}.sav\"\n",
    "loaded_cnb = joblib.load(model_name)\n",
    "y_pred_cnb = loaded_cnb.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "895cf66d",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 17 is out of bounds for axis 1 with size 17",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [25]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[1;32m      4\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;66;03m# For measuring time execution\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m avg_expected_loss, avg_bias, avg_var \u001b[38;5;241m=\u001b[39m \u001b[43mbias_variance_decomp\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43mloaded_cnb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_resample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_resample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m0-1_loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m123\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#---\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEvaluation result: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdiscretizer\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdisc_param\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, file \u001b[38;5;241m=\u001b[39m f)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/mlxtend/evaluate/bias_variance_decomp.py:131\u001b[0m, in \u001b[0;36mbias_variance_decomp\u001b[0;34m(estimator, X_train, y_train, X_test, y_test, loss, num_rounds, random_seed, **fit_params)\u001b[0m\n\u001b[1;32m    129\u001b[0m         pred \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mpredict(X_test)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 131\u001b[0m         pred \u001b[38;5;241m=\u001b[39m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_boot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_boot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m     all_pred[i] \u001b[38;5;241m=\u001b[39m pred\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loss \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0-1_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/naive_bayes.py:81\u001b[0m, in \u001b[0;36m_BaseNB.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     79\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m     80\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_X(X)\n\u001b[0;32m---> 81\u001b[0m jll \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_joint_log_likelihood\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_[np\u001b[38;5;241m.\u001b[39margmax(jll, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/naive_bayes.py:1425\u001b[0m, in \u001b[0;36mCategoricalNB._joint_log_likelihood\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1423\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_):\n\u001b[1;32m   1424\u001b[0m     indices \u001b[38;5;241m=\u001b[39m X[:, i]\n\u001b[0;32m-> 1425\u001b[0m     jll \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_log_prob_\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m   1426\u001b[0m total_ll \u001b[38;5;241m=\u001b[39m jll \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_log_prior_\n\u001b[1;32m   1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m total_ll\n",
      "\u001b[0;31mIndexError\u001b[0m: index 17 is out of bounds for axis 1 with size 17"
     ]
    }
   ],
   "source": [
    "# Decomposition\n",
    "f = open(\"transfusion_evaluation_cnb.txt\", \"a\")\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "loaded_cnb, x_resample, y_resample, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "\n",
    "print(f'Evaluation result: {model}, {discretizer}, {disc_param}', file = f)\n",
    "print('Average expected loss: %.3f' % avg_expected_loss, file = f)\n",
    "print('Average bias: %.3f' % avg_bias, file = f)\n",
    "print('Average variance: %.3f' % avg_var, file = f)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_cnb), file = f)\n",
    "\n",
    "end = time.time()\n",
    "print(f'Execution time {model}- default, {disc}, m = {m} is: {end - start}.', file = f) # Total time execution\n",
    "print('=='*20, file = f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93abfab5",
   "metadata": {},
   "source": [
    "## FFD, m = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c5482f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 748 entries, 0 to 747\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype\n",
      "---  ------      --------------  -----\n",
      " 0   Unnamed: 0  748 non-null    int64\n",
      " 1   recency     748 non-null    int64\n",
      " 2   frequency   748 non-null    int64\n",
      " 3   monetary    748 non-null    int64\n",
      " 4   time        748 non-null    int64\n",
      " 5   label       748 non-null    int64\n",
      "dtypes: int64(6)\n",
      "memory usage: 35.2 KB\n",
      "(748, 5) (748,)\n",
      "Class representation - original:  Counter({0: 570, 1: 178})\n",
      "Class representation - training data:  Counter({0: 428, 1: 133})\n",
      "Class representation - testing data:  Counter({0: 142, 1: 45})\n"
     ]
    }
   ],
   "source": [
    "# Complete code for data preperation\n",
    "# Read data\n",
    "df_ffd2 = pd.read_csv('tranfusion_ffd2.csv')\n",
    "disc = 'FFD'\n",
    "m = 30\n",
    "\n",
    "df_ffd2.info()\n",
    "data = df_ffd2.values\n",
    "data.shape\n",
    "\n",
    "features = df_ffd2.drop('label', axis = 1).columns\n",
    "\n",
    "# separate the data into X and y\n",
    "X = data[:, : len(features)]\n",
    "Y = data[:,-1]\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "# Split train test\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state = 30, stratify = Y)\n",
    "\n",
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(Y)) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test)) \n",
    "\n",
    "# Check number of categories for features\n",
    "n_categories = df_ffd2[features].nunique()\n",
    "\n",
    "from imblearn.combine import SMOTEENN\n",
    "smt_enn = SMOTEENN(random_state=42)\n",
    "x_resample, y_resample = smt_enn.fit_resample(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1fb87d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tranfusion_CNB_FFD_30.sav\n"
     ]
    }
   ],
   "source": [
    "# Load models\n",
    "model = 'CNB'\n",
    "dataset = 'tranfusion'\n",
    "discretizer = 'FFD'\n",
    "disc_param = 'm = 30'\n",
    "\n",
    "model_name = f\"{dataset}_{model}_{discretizer}_{m}.sav\"\n",
    "print(model_name)\n",
    "loaded_cnb = joblib.load(model_name)\n",
    "y_pred_cnb = loaded_cnb.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e1bf1826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decomposition\n",
    "f = open(\"transfusion_evaluation_cnb.txt\", \"a\")\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "loaded_cnb, x_resample, y_resample, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "\n",
    "print(f'Evaluation result: {model}, {discretizer}, {disc_param}', file = f)\n",
    "print('Average expected loss: %.3f' % avg_expected_loss, file = f)\n",
    "print('Average bias: %.3f' % avg_bias, file = f)\n",
    "print('Average variance: %.3f' % avg_var, file = f)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_cnb), file = f)\n",
    "\n",
    "end = time.time()\n",
    "print(f'Execution time {model}- default, {disc}, m = {m} is: {end - start}.', file = f) # Total time execution\n",
    "print('=='*20, file = f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd27b19",
   "metadata": {},
   "source": [
    "## FFD, m = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "38b98e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 748 entries, 0 to 747\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype\n",
      "---  ------      --------------  -----\n",
      " 0   Unnamed: 0  748 non-null    int64\n",
      " 1   recency     748 non-null    int64\n",
      " 2   frequency   748 non-null    int64\n",
      " 3   monetary    748 non-null    int64\n",
      " 4   time        748 non-null    int64\n",
      " 5   label       748 non-null    int64\n",
      "dtypes: int64(6)\n",
      "memory usage: 35.2 KB\n",
      "(748, 5) (748,)\n",
      "Class representation - original:  Counter({0: 570, 1: 178})\n",
      "Class representation - training data:  Counter({0: 428, 1: 133})\n",
      "Class representation - testing data:  Counter({0: 142, 1: 45})\n"
     ]
    }
   ],
   "source": [
    "# Complete code for data preperation\n",
    "# Read data\n",
    "df_ffd3 = pd.read_csv('tranfusion_ffd3.csv')\n",
    "disc = 'FFD'\n",
    "m = 60\n",
    "\n",
    "df_ffd3.info()\n",
    "data = df_ffd3.values\n",
    "data.shape\n",
    "\n",
    "features = df_ffd3.drop('label', axis = 1).columns\n",
    "\n",
    "# separate the data into X and y\n",
    "X = data[:, : len(features)]\n",
    "Y = data[:,-1]\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "# Split train test\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state = 30, stratify = Y)\n",
    "\n",
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(Y)) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test)) \n",
    "\n",
    "# Check number of categories for features\n",
    "n_categories = df_ffd3[features].nunique()\n",
    "\n",
    "from imblearn.combine import SMOTEENN\n",
    "smt_enn = SMOTEENN(random_state=42)\n",
    "x_resample, y_resample = smt_enn.fit_resample(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "68e7891e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tranfusion_CNB_FFD_60.sav\n"
     ]
    }
   ],
   "source": [
    "# Load models\n",
    "model = 'CNB'\n",
    "dataset = 'tranfusion'\n",
    "discretizer = 'FFD'\n",
    "disc_param = 'm = 60'\n",
    "\n",
    "model_name = f\"{dataset}_{model}_{discretizer}_{m}.sav\"\n",
    "print(model_name)\n",
    "loaded_cnb = joblib.load(model_name)\n",
    "y_pred_cnb = loaded_cnb.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "084723b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decomposition\n",
    "f = open(\"transfusion_evaluation_cnb.txt\", \"a\")\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "loaded_cnb, x_resample, y_resample, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "\n",
    "print(f'Evaluation result: {model}, {discretizer}, {disc_param}', file = f)\n",
    "print('Average expected loss: %.3f' % avg_expected_loss, file = f)\n",
    "print('Average bias: %.3f' % avg_bias, file = f)\n",
    "print('Average variance: %.3f' % avg_var, file = f)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_cnb), file = f)\n",
    "\n",
    "end = time.time()\n",
    "print(f'Execution time {model}- default, {disc}, m = {m} is: {end - start}.', file = f) # Total time execution\n",
    "print('=='*20, file = f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422e27e1",
   "metadata": {},
   "source": [
    "## FFD, m = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9cad833f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 748 entries, 0 to 747\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype\n",
      "---  ------      --------------  -----\n",
      " 0   Unnamed: 0  748 non-null    int64\n",
      " 1   recency     748 non-null    int64\n",
      " 2   frequency   748 non-null    int64\n",
      " 3   monetary    748 non-null    int64\n",
      " 4   time        748 non-null    int64\n",
      " 5   label       748 non-null    int64\n",
      "dtypes: int64(6)\n",
      "memory usage: 35.2 KB\n",
      "(748, 5) (748,)\n",
      "Class representation - original:  Counter({0: 570, 1: 178})\n",
      "Class representation - training data:  Counter({0: 428, 1: 133})\n",
      "Class representation - testing data:  Counter({0: 142, 1: 45})\n"
     ]
    }
   ],
   "source": [
    "# Complete code for data preperation\n",
    "# Read data\n",
    "df_ffd4 = pd.read_csv('tranfusion_ffd4.csv')\n",
    "disc = 'FFD'\n",
    "m = 100\n",
    "\n",
    "df_ffd4.info()\n",
    "data = df_ffd4.values\n",
    "data.shape\n",
    "\n",
    "features = df_ffd4.drop('label', axis = 1).columns\n",
    "\n",
    "# separate the data into X and y\n",
    "X = data[:, : len(features)]\n",
    "Y = data[:,-1]\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "# Split train test\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state = 30, stratify = Y)\n",
    "\n",
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(Y)) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test)) \n",
    "\n",
    "# Check number of categories for features\n",
    "n_categories = df_ffd4[features].nunique()\n",
    "\n",
    "from imblearn.combine import SMOTEENN\n",
    "smt_enn = SMOTEENN(random_state=42)\n",
    "x_resample, y_resample = smt_enn.fit_resample(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "60f20a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tranfusion_CNB_FFD_100.sav\n"
     ]
    }
   ],
   "source": [
    "# Load models\n",
    "model = 'CNB'\n",
    "dataset = 'tranfusion'\n",
    "discretizer = 'FFD'\n",
    "disc_param = 'm = 100'\n",
    "\n",
    "model_name = f\"{dataset}_{model}_{discretizer}_{m}.sav\"\n",
    "print(model_name)\n",
    "loaded_cnb = joblib.load(model_name)\n",
    "y_pred_cnb = loaded_cnb.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2902f6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decomposition\n",
    "f = open(\"transfusion_evaluation_cnb.txt\", \"a\")\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "loaded_cnb, x_resample, y_resample, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "\n",
    "print(f'Evaluation result: {model}, {discretizer}, {disc_param}', file = f)\n",
    "print('Average expected loss: %.3f' % avg_expected_loss, file = f)\n",
    "print('Average bias: %.3f' % avg_bias, file = f)\n",
    "print('Average variance: %.3f' % avg_var, file = f)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_cnb), file = f)\n",
    "\n",
    "end = time.time()\n",
    "print(f'Execution time {model}- default, {disc}, m = {m} is: {end - start}.', file = f) # Total time execution\n",
    "print('=='*20, file = f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc2acb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
