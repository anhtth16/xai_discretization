{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "514e58db",
   "metadata": {},
   "source": [
    "# Classification models - unsupervised discretization\n",
    "\n",
    "Dataset: pendigits (REDO training models on the entired dataset) <br>\n",
    "By: Sam <br>\n",
    "Update at: 27/04/2023 <br>\n",
    "\n",
    "====\n",
    "\n",
    "Summary:<br>\n",
    "- Import unsupervised discretised datasets (already encoded categorical attributes)\n",
    "- Datasets are discretized from BNAIC (manually ChiMerge)\n",
    "- Perform 3 classification models: EWD (3 settings), EFD (3 settings) and FFD (4 settings)\n",
    "- Evaluation on testing data: Classification report (accuracy, precision, recall, f1-score) + G-mean\n",
    "- Export models after training: Knn-Hamming: skops\n",
    "- Write models performance to file: 'pendigits_models.txt'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349a2e49",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e959660",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "from pandas import set_option\n",
    "import numpy as np\n",
    "from numpy import arange\n",
    "## EDA\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c39986bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "# Cross validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score # 1 metric\n",
    "from sklearn.model_selection import cross_validate # more than 1 metric\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1d3237a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Naive Bayes\n",
    "from sklearn.naive_bayes import CategoricalNB # Categorical Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB # Multinominal Naive Bayes (suitable for NLP)\n",
    "from mixed_naive_bayes import MixedNB # Mixed Naive Bayes for combination of both discrete & continuous feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e9ddea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For decision tree ID3 \n",
    "# https://stackoverflow.com/questions/61867945/python-import-error-cannot-import-name-six-from-sklearn-externals\n",
    "import six\n",
    "import sys\n",
    "sys.modules['sklearn.externals.six'] = six\n",
    "import mlrose\n",
    "from id3 import Id3Estimator # ID3 Decision Tree (https://pypi.org/project/decision-tree-id3/)\n",
    "from id3 import export_graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "beb75f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Knn-VDM 3\n",
    "from vdm3 import ValueDifferenceMetric\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "039c536e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For model evaluation\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4ec1b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13679f21",
   "metadata": {},
   "source": [
    "# 1. EWD data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f773ca",
   "metadata": {},
   "source": [
    "## 1.1 EWD, k = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c5bf499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10992 entries, 0 to 10991\n",
      "Data columns (total 16 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   A2      10992 non-null  int64\n",
      " 1   A3      10992 non-null  int64\n",
      " 2   A4      10992 non-null  int64\n",
      " 3   A5      10992 non-null  int64\n",
      " 4   A6      10992 non-null  int64\n",
      " 5   A7      10992 non-null  int64\n",
      " 6   A8      10992 non-null  int64\n",
      " 7   A9      10992 non-null  int64\n",
      " 8   A10     10992 non-null  int64\n",
      " 9   A11     10992 non-null  int64\n",
      " 10  A12     10992 non-null  int64\n",
      " 11  A13     10992 non-null  int64\n",
      " 12  A14     10992 non-null  int64\n",
      " 13  A15     10992 non-null  int64\n",
      " 14  A16     10992 non-null  int64\n",
      " 15  label   10992 non-null  int64\n",
      "dtypes: int64(16)\n",
      "memory usage: 1.3 MB\n",
      "(10992, 15) (10992,)\n",
      "Class representation - original:  Counter({2: 1144, 4: 1144, 1: 1143, 0: 1143, 7: 1142, 6: 1056, 8: 1055, 5: 1055, 9: 1055, 3: 1055})\n",
      "Class representation - training data:  Counter({4: 858, 2: 858, 0: 857, 1: 857, 7: 857, 5: 792, 6: 792, 3: 791, 8: 791, 9: 791})\n",
      "Class representation - testing data:  Counter({2: 286, 0: 286, 4: 286, 1: 286, 7: 285, 8: 264, 6: 264, 9: 264, 3: 264, 5: 263})\n"
     ]
    }
   ],
   "source": [
    "# Complete code for data preperation\n",
    "# Read data\n",
    "df_ewd1 = pd.read_csv('pendigits_ewd1.csv')\n",
    "df_ewd1.drop(df_ewd1.columns[0], axis=1, inplace = True)\n",
    "df_ewd1.rename(columns={'class':'label'}, inplace=True)\n",
    "\n",
    "disc = 'EWD'\n",
    "k = 4\n",
    "\n",
    "df_ewd1.info()\n",
    "data = df_ewd1.values\n",
    "data.shape\n",
    "\n",
    "features = df_ewd1.drop('label', axis = 1).columns\n",
    "\n",
    "# separate the data into X and y\n",
    "X = data[:, : len(features)]\n",
    "Y = data[:,-1]\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "# Split train test\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state = 30, stratify=Y)\n",
    "\n",
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(Y)) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test)) \n",
    "\n",
    "# Check number of categories for features\n",
    "n_categories = df_ewd1[features].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22930726",
   "metadata": {},
   "source": [
    "### Models - EWD, k=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a0ca119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pendigits_KNN-Hamming_EWD_4.skops\n"
     ]
    }
   ],
   "source": [
    "# Knn-Hammingcomplete code\n",
    "\n",
    "model = 'KNN-Hamming'\n",
    "dataset = 'pendigits'\n",
    "discretizer = 'EWD'\n",
    "disc_param = 'k = 4'\n",
    "\n",
    "f = open(\"pendigits_models.txt\", \"a\")\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "# Knn-Hamming complete code\n",
    "knn_hamming = KNeighborsClassifier(n_neighbors=3, metric='hamming', algorithm='auto')\n",
    "knn_hamming.fit(x_train, y_train)\n",
    "\n",
    "# Testing\n",
    "y_pred_knn = knn_hamming.predict(x_test)\n",
    "knn_hamming.classes_\n",
    "print(f'Models results: model {model}, dataset {dataset}, discretization {discretizer} with parameter {disc_param}', file = f)\n",
    "print('Classification report', file = f)\n",
    "print(classification_report(y_test, y_pred_knn), file = f)\n",
    "\n",
    "from imblearn.metrics import geometric_mean_score as gmean\n",
    "print('G-mean:', gmean(y_test, y_pred_knn),file = f)\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model {model}- default, {disc}, k = {k} is: {end - start}.', file = f) # Total time execution\n",
    "print('=='*20, file = f)\n",
    "f.close()\n",
    "\n",
    "# Save models\n",
    "import skops.io as sio\n",
    "model_name = f\"{dataset}_{model}_{discretizer}_{k}.skops\"\n",
    "print(model_name)\n",
    "obj = sio.dump(knn_hamming, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c0a4f2",
   "metadata": {},
   "source": [
    "## 1.2 EWD, k = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817132b0",
   "metadata": {},
   "source": [
    "### Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7700c25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10992 entries, 0 to 10991\n",
      "Data columns (total 16 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   A2      10992 non-null  int64\n",
      " 1   A3      10992 non-null  int64\n",
      " 2   A4      10992 non-null  int64\n",
      " 3   A5      10992 non-null  int64\n",
      " 4   A6      10992 non-null  int64\n",
      " 5   A7      10992 non-null  int64\n",
      " 6   A8      10992 non-null  int64\n",
      " 7   A9      10992 non-null  int64\n",
      " 8   A10     10992 non-null  int64\n",
      " 9   A11     10992 non-null  int64\n",
      " 10  A12     10992 non-null  int64\n",
      " 11  A13     10992 non-null  int64\n",
      " 12  A14     10992 non-null  int64\n",
      " 13  A15     10992 non-null  int64\n",
      " 14  A16     10992 non-null  int64\n",
      " 15  label   10992 non-null  int64\n",
      "dtypes: int64(16)\n",
      "memory usage: 1.3 MB\n",
      "(10992, 15) (10992,)\n",
      "Class representation - original:  Counter({2: 1144, 4: 1144, 1: 1143, 0: 1143, 7: 1142, 6: 1056, 8: 1055, 5: 1055, 9: 1055, 3: 1055})\n",
      "Class representation - training data:  Counter({4: 858, 2: 858, 0: 857, 1: 857, 7: 857, 5: 792, 6: 792, 3: 791, 8: 791, 9: 791})\n",
      "Class representation - testing data:  Counter({2: 286, 0: 286, 4: 286, 1: 286, 7: 285, 8: 264, 6: 264, 9: 264, 3: 264, 5: 263})\n"
     ]
    }
   ],
   "source": [
    "# Complete code for data preperation\n",
    "# Read data\n",
    "df_ewd2 = pd.read_csv('pendigits_ewd2.csv')\n",
    "df_ewd2.drop(df_ewd2.columns[0], axis=1, inplace = True)\n",
    "df_ewd2.rename(columns={'class':'label'}, inplace=True)\n",
    "\n",
    "disc = 'EWD'\n",
    "k = 7\n",
    "\n",
    "df_ewd2.info()\n",
    "data = df_ewd2.values\n",
    "data.shape\n",
    "\n",
    "features = df_ewd2.drop('label', axis = 1).columns\n",
    "\n",
    "# separate the data into X and y\n",
    "X = data[:, : len(features)]\n",
    "Y = data[:,-1]\n",
    "#X = df_ewd2[features]\n",
    "#Y = df_ewd2['class']\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "# Split train test\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state = 30, stratify=Y)\n",
    "\n",
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(Y)) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test)) \n",
    "\n",
    "# Check number of categories for features\n",
    "n_categories = df_ewd2[features].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaeaca15",
   "metadata": {},
   "source": [
    "### Models - EWD, k=7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "197d7a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pendigits_KNN-Hamming_EWD_7.skops\n"
     ]
    }
   ],
   "source": [
    "# Knn-Hammingcomplete code\n",
    "\n",
    "model = 'KNN-Hamming'\n",
    "dataset = 'pendigits'\n",
    "discretizer = 'EWD'\n",
    "disc_param = 'k = 7'\n",
    "\n",
    "f = open(\"pendigits_models.txt\", \"a\")\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "# Knn-Hamming complete code\n",
    "knn_hamming = KNeighborsClassifier(n_neighbors=3, metric='hamming', algorithm='auto')\n",
    "knn_hamming.fit(x_train, y_train)\n",
    "\n",
    "# Testing\n",
    "y_pred_knn = knn_hamming.predict(x_test)\n",
    "knn_hamming.classes_\n",
    "print(f'Models results: model {model}, dataset {dataset}, discretization {discretizer} with parameter {disc_param}', \n",
    "      file = f)\n",
    "print('Classification report', file = f)\n",
    "print(classification_report(y_test, y_pred_knn), file = f)\n",
    "\n",
    "from imblearn.metrics import geometric_mean_score as gmean\n",
    "print('G-mean:', gmean(y_test, y_pred_knn),file = f)\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model {model}- default, {disc}, k = {k} is: {end - start}.', file = f) # Total time execution\n",
    "print('=='*20, file = f)\n",
    "f.close()\n",
    "\n",
    "# Save models\n",
    "import skops.io as sio\n",
    "model_name = f\"{dataset}_{model}_{discretizer}_{k}.skops\"\n",
    "print(model_name)\n",
    "obj = sio.dump(knn_hamming, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fe06a0",
   "metadata": {},
   "source": [
    "## 1.3 EWD, k = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5e59bf",
   "metadata": {},
   "source": [
    "### Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e236c05f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10992 entries, 0 to 10991\n",
      "Data columns (total 16 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   A2      10992 non-null  int64\n",
      " 1   A3      10992 non-null  int64\n",
      " 2   A4      10992 non-null  int64\n",
      " 3   A5      10992 non-null  int64\n",
      " 4   A6      10992 non-null  int64\n",
      " 5   A7      10992 non-null  int64\n",
      " 6   A8      10992 non-null  int64\n",
      " 7   A9      10992 non-null  int64\n",
      " 8   A10     10992 non-null  int64\n",
      " 9   A11     10992 non-null  int64\n",
      " 10  A12     10992 non-null  int64\n",
      " 11  A13     10992 non-null  int64\n",
      " 12  A14     10992 non-null  int64\n",
      " 13  A15     10992 non-null  int64\n",
      " 14  A16     10992 non-null  int64\n",
      " 15  label   10992 non-null  int64\n",
      "dtypes: int64(16)\n",
      "memory usage: 1.3 MB\n",
      "(10992, 15) (10992,)\n",
      "Class representation - original:  Counter({2: 1144, 4: 1144, 1: 1143, 0: 1143, 7: 1142, 6: 1056, 8: 1055, 5: 1055, 9: 1055, 3: 1055})\n",
      "Class representation - training data:  Counter({4: 858, 2: 858, 0: 857, 1: 857, 7: 857, 5: 792, 6: 792, 3: 791, 8: 791, 9: 791})\n",
      "Class representation - testing data:  Counter({2: 286, 0: 286, 4: 286, 1: 286, 7: 285, 8: 264, 6: 264, 9: 264, 3: 264, 5: 263})\n"
     ]
    }
   ],
   "source": [
    "# Complete code for data preperation\n",
    "# Read data\n",
    "df_ewd3 = pd.read_csv('pendigits_ewd3.csv')\n",
    "df_ewd3.drop(df_ewd3.columns[0], axis=1, inplace = True)\n",
    "df_ewd3.rename(columns={'class':'label'}, inplace=True)\n",
    "\n",
    "disc = 'EWD'\n",
    "k = 10\n",
    "\n",
    "df_ewd3.info()\n",
    "data = df_ewd3.values\n",
    "data.shape\n",
    "\n",
    "features = df_ewd3.drop('label', axis = 1).columns\n",
    "\n",
    "# separate the data into X and y\n",
    "X = data[:, : len(features)]\n",
    "Y = data[:,-1]\n",
    "#X = df_ewd3[features]\n",
    "#Y = df_ewd3['class']\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "# Split train test\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state = 30, stratify=Y)\n",
    "\n",
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(Y)) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test)) \n",
    "\n",
    "# Check number of categories for features\n",
    "n_categories = df_ewd3[features].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d33064",
   "metadata": {},
   "source": [
    "### Models - EWD, k=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d96b68c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pendigits_KNN-Hamming_EWD_10.skops\n"
     ]
    }
   ],
   "source": [
    "# Knn-Hammingcomplete code\n",
    "\n",
    "model = 'KNN-Hamming'\n",
    "dataset = 'pendigits'\n",
    "discretizer = 'EWD'\n",
    "disc_param = 'k = 10'\n",
    "\n",
    "f = open(\"pendigits_models.txt\", \"a\")\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "# Knn-Hamming complete code\n",
    "knn_hamming = KNeighborsClassifier(n_neighbors=3, metric='hamming', algorithm='auto')\n",
    "knn_hamming.fit(x_train, y_train)\n",
    "\n",
    "# Testing\n",
    "y_pred_knn = knn_hamming.predict(x_test)\n",
    "knn_hamming.classes_\n",
    "print(f'Models results: model {model}, dataset {dataset}, discretization {discretizer} with parameter {disc_param}', \n",
    "      file = f)\n",
    "print('Classification report', file = f)\n",
    "print(classification_report(y_test, y_pred_knn), file = f)\n",
    "\n",
    "from imblearn.metrics import geometric_mean_score as gmean\n",
    "print('G-mean:', gmean(y_test, y_pred_knn),file = f)\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model {model}- default, {disc}, k = {k} is: {end - start}.', file = f) # Total time execution\n",
    "print('=='*20, file = f)\n",
    "f.close()\n",
    "\n",
    "# Save models\n",
    "import skops.io as sio\n",
    "model_name = f\"{dataset}_{model}_{discretizer}_{k}.skops\"\n",
    "print(model_name)\n",
    "obj = sio.dump(knn_hamming, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb96c1d",
   "metadata": {},
   "source": [
    "# 2. EFD datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229a0ccb",
   "metadata": {},
   "source": [
    "## 2.1 EFD, k = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a46ad2",
   "metadata": {},
   "source": [
    "### Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb63c727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10992 entries, 0 to 10991\n",
      "Data columns (total 16 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   A2      10992 non-null  int64\n",
      " 1   A3      10992 non-null  int64\n",
      " 2   A4      10992 non-null  int64\n",
      " 3   A5      10992 non-null  int64\n",
      " 4   A6      10992 non-null  int64\n",
      " 5   A7      10992 non-null  int64\n",
      " 6   A8      10992 non-null  int64\n",
      " 7   A9      10992 non-null  int64\n",
      " 8   A10     10992 non-null  int64\n",
      " 9   A11     10992 non-null  int64\n",
      " 10  A12     10992 non-null  int64\n",
      " 11  A13     10992 non-null  int64\n",
      " 12  A14     10992 non-null  int64\n",
      " 13  A15     10992 non-null  int64\n",
      " 14  A16     10992 non-null  int64\n",
      " 15  label   10992 non-null  int64\n",
      "dtypes: int64(16)\n",
      "memory usage: 1.3 MB\n",
      "(10992, 15) (10992,)\n",
      "Class representation - original:  Counter({2: 1144, 4: 1144, 1: 1143, 0: 1143, 7: 1142, 6: 1056, 8: 1055, 5: 1055, 9: 1055, 3: 1055})\n",
      "Class representation - training data:  Counter({4: 858, 2: 858, 0: 857, 1: 857, 7: 857, 5: 792, 6: 792, 3: 791, 8: 791, 9: 791})\n",
      "Class representation - testing data:  Counter({2: 286, 0: 286, 4: 286, 1: 286, 7: 285, 8: 264, 6: 264, 9: 264, 3: 264, 5: 263})\n"
     ]
    }
   ],
   "source": [
    "# Complete code for data preperation\n",
    "# Read data\n",
    "df_efd1 = pd.read_csv('pendigits_efd1.csv')\n",
    "df_efd1.drop(df_efd1.columns[0], axis=1, inplace = True)\n",
    "df_efd1.rename(columns={'class':'label'}, inplace=True)\n",
    "\n",
    "disc = 'efd'\n",
    "k = 4\n",
    "\n",
    "df_efd1.info()\n",
    "data = df_efd1.values\n",
    "data.shape\n",
    "\n",
    "features = df_efd1.drop('label', axis = 1).columns\n",
    "\n",
    "# separate the data into X and y\n",
    "X = data[:, : len(features)]\n",
    "Y = data[:,-1]\n",
    "#X = df_efd1[features]\n",
    "#Y = df_efd1['class']\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "# Split train test\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state = 30, stratify=Y)\n",
    "\n",
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(Y)) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test)) \n",
    "\n",
    "# Check number of categories for features\n",
    "n_categories = df_efd1[features].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f674a1a2",
   "metadata": {},
   "source": [
    "### Models - EFD, k=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3bc109f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pendigits_KNN-Hamming_EFD_4.skops\n"
     ]
    }
   ],
   "source": [
    "# Knn-Hamming complete code\n",
    "\n",
    "model = 'KNN-Hamming'\n",
    "dataset = 'pendigits'\n",
    "discretizer = 'EFD'\n",
    "disc_param = 'k = 4'\n",
    "\n",
    "f = open(\"pendigits_models.txt\", \"a\")\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "# Knn-Hamming complete code\n",
    "knn_hamming = KNeighborsClassifier(n_neighbors=3, metric='hamming', algorithm='auto')\n",
    "knn_hamming.fit(x_train, y_train)\n",
    "\n",
    "# Testing\n",
    "y_pred_knn = knn_hamming.predict(x_test)\n",
    "knn_hamming.classes_\n",
    "print(f'Models results: model {model}, dataset {dataset}, discretization {discretizer} with parameter {disc_param}', \n",
    "      file = f)\n",
    "print('Classification report', file = f)\n",
    "print(classification_report(y_test, y_pred_knn), file = f)\n",
    "\n",
    "from imblearn.metrics import geometric_mean_score as gmean\n",
    "print('G-mean:', gmean(y_test, y_pred_knn),file = f)\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model {model}- default, {disc}, k = {k} is: {end - start}.', file = f) # Total time execution\n",
    "print('=='*20, file = f)\n",
    "f.close()\n",
    "\n",
    "# Save models\n",
    "import skops.io as sio\n",
    "model_name = f\"{dataset}_{model}_{discretizer}_{k}.skops\"\n",
    "print(model_name)\n",
    "obj = sio.dump(knn_hamming, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca03cff4",
   "metadata": {},
   "source": [
    "## 2.2 EFD, k = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c786d9",
   "metadata": {},
   "source": [
    "### Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b377cd85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10992 entries, 0 to 10991\n",
      "Data columns (total 16 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   A2      10992 non-null  int64\n",
      " 1   A3      10992 non-null  int64\n",
      " 2   A4      10992 non-null  int64\n",
      " 3   A5      10992 non-null  int64\n",
      " 4   A6      10992 non-null  int64\n",
      " 5   A7      10992 non-null  int64\n",
      " 6   A8      10992 non-null  int64\n",
      " 7   A9      10992 non-null  int64\n",
      " 8   A10     10992 non-null  int64\n",
      " 9   A11     10992 non-null  int64\n",
      " 10  A12     10992 non-null  int64\n",
      " 11  A13     10992 non-null  int64\n",
      " 12  A14     10992 non-null  int64\n",
      " 13  A15     10992 non-null  int64\n",
      " 14  A16     10992 non-null  int64\n",
      " 15  label   10992 non-null  int64\n",
      "dtypes: int64(16)\n",
      "memory usage: 1.3 MB\n",
      "(10992, 15) (10992,)\n",
      "Class representation - original:  Counter({2: 1144, 4: 1144, 1: 1143, 0: 1143, 7: 1142, 6: 1056, 8: 1055, 5: 1055, 9: 1055, 3: 1055})\n",
      "Class representation - training data:  Counter({4: 858, 2: 858, 0: 857, 1: 857, 7: 857, 5: 792, 6: 792, 3: 791, 8: 791, 9: 791})\n",
      "Class representation - testing data:  Counter({2: 286, 0: 286, 4: 286, 1: 286, 7: 285, 8: 264, 6: 264, 9: 264, 3: 264, 5: 263})\n"
     ]
    }
   ],
   "source": [
    "# Complete code for data preperation\n",
    "# Read data\n",
    "df_efd2 = pd.read_csv('pendigits_efd2.csv')\n",
    "df_efd2.drop(df_efd2.columns[0], axis=1, inplace = True)\n",
    "df_efd2.rename(columns={'class':'label'}, inplace=True)\n",
    "\n",
    "disc = 'efd'\n",
    "k = 7\n",
    "\n",
    "df_efd2.info()\n",
    "data = df_efd2.values\n",
    "data.shape\n",
    "\n",
    "features = df_efd2.drop('label', axis = 1).columns\n",
    "\n",
    "# separate the data into X and y\n",
    "X = data[:, : len(features)]\n",
    "Y = data[:,-1]\n",
    "#X = df_efd2[features]\n",
    "#Y = df_efd2['class']\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "# Split train test\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state = 30, stratify=Y)\n",
    "\n",
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(Y)) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test)) \n",
    "\n",
    "# Check number of categories for features\n",
    "n_categories = df_efd2[features].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f538866e",
   "metadata": {},
   "source": [
    "### Models, EFD, k=7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "efd5316d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pendigits_KNN-Hamming_EFD_7.skops\n"
     ]
    }
   ],
   "source": [
    "# Knn-Hammingcomplete code\n",
    "\n",
    "model = 'KNN-Hamming'\n",
    "dataset = 'pendigits'\n",
    "discretizer = 'EFD'\n",
    "disc_param = 'k = 7'\n",
    "\n",
    "f = open(\"pendigits_models.txt\", \"a\")\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "# Knn-Hamming complete code\n",
    "knn_hamming = KNeighborsClassifier(n_neighbors=3, metric='hamming', algorithm='auto')\n",
    "knn_hamming.fit(x_train, y_train)\n",
    "\n",
    "# Testing\n",
    "y_pred_knn = knn_hamming.predict(x_test)\n",
    "knn_hamming.classes_\n",
    "print(f'Models results: model {model}, dataset {dataset}, discretization {discretizer} with parameter {disc_param}', \n",
    "      file = f)\n",
    "print('Classification report', file = f)\n",
    "print(classification_report(y_test, y_pred_knn), file = f)\n",
    "\n",
    "from imblearn.metrics import geometric_mean_score as gmean\n",
    "print('G-mean:', gmean(y_test, y_pred_knn),file = f)\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model {model}- default, {disc}, k = {k} is: {end - start}.', file = f) # Total time execution\n",
    "print('=='*20, file = f)\n",
    "f.close()\n",
    "\n",
    "# Save models\n",
    "import skops.io as sio\n",
    "model_name = f\"{dataset}_{model}_{discretizer}_{k}.skops\"\n",
    "print(model_name)\n",
    "obj = sio.dump(knn_hamming, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2824762f",
   "metadata": {},
   "source": [
    "## 2.3 EFD, k = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d775ce0c",
   "metadata": {},
   "source": [
    "### Dataprep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "18d75756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10992 entries, 0 to 10991\n",
      "Data columns (total 16 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   A2      10992 non-null  int64\n",
      " 1   A3      10992 non-null  int64\n",
      " 2   A4      10992 non-null  int64\n",
      " 3   A5      10992 non-null  int64\n",
      " 4   A6      10992 non-null  int64\n",
      " 5   A7      10992 non-null  int64\n",
      " 6   A8      10992 non-null  int64\n",
      " 7   A9      10992 non-null  int64\n",
      " 8   A10     10992 non-null  int64\n",
      " 9   A11     10992 non-null  int64\n",
      " 10  A12     10992 non-null  int64\n",
      " 11  A13     10992 non-null  int64\n",
      " 12  A14     10992 non-null  int64\n",
      " 13  A15     10992 non-null  int64\n",
      " 14  A16     10992 non-null  int64\n",
      " 15  label   10992 non-null  int64\n",
      "dtypes: int64(16)\n",
      "memory usage: 1.3 MB\n",
      "(10992, 15) (10992,)\n",
      "Class representation - original:  Counter({2: 1144, 4: 1144, 1: 1143, 0: 1143, 7: 1142, 6: 1056, 8: 1055, 5: 1055, 9: 1055, 3: 1055})\n",
      "Class representation - training data:  Counter({4: 858, 2: 858, 0: 857, 1: 857, 7: 857, 5: 792, 6: 792, 3: 791, 8: 791, 9: 791})\n",
      "Class representation - testing data:  Counter({2: 286, 0: 286, 4: 286, 1: 286, 7: 285, 8: 264, 6: 264, 9: 264, 3: 264, 5: 263})\n"
     ]
    }
   ],
   "source": [
    "# Complete code for data preperation\n",
    "# Read data\n",
    "df_efd3 = pd.read_csv('pendigits_efd3.csv')\n",
    "df_efd3.drop(df_efd3.columns[0], axis=1, inplace = True)\n",
    "df_efd3.rename(columns={'class':'label'}, inplace=True)\n",
    "\n",
    "disc = 'efd'\n",
    "k = 10\n",
    "\n",
    "df_efd3.info()\n",
    "data = df_efd3.values\n",
    "data.shape\n",
    "\n",
    "features = df_efd3.drop('label', axis = 1).columns\n",
    "\n",
    "# separate the data into X and y\n",
    "X = data[:, : len(features)]\n",
    "Y = data[:,-1]\n",
    "#X = df_efd3[features]\n",
    "#Y = df_efd3['class']\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "# Split train test\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state = 30, stratify=Y)\n",
    "\n",
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(Y)) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test)) \n",
    "\n",
    "# Check number of categories for features\n",
    "n_categories = df_efd3[features].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648c53f5",
   "metadata": {},
   "source": [
    "### Models, EFD, k=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d253760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pendigits_KNN-Hamming_EFD_10.skops\n"
     ]
    }
   ],
   "source": [
    "# Knn-Hammingcomplete code\n",
    "\n",
    "model = 'KNN-Hamming'\n",
    "dataset = 'pendigits'\n",
    "discretizer = 'EFD'\n",
    "disc_param = 'k = 10'\n",
    "\n",
    "f = open(\"pendigits_models.txt\", \"a\")\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "# Knn-Hamming complete code\n",
    "knn_hamming = KNeighborsClassifier(n_neighbors=3, metric='hamming', algorithm='auto')\n",
    "knn_hamming.fit(x_train, y_train)\n",
    "\n",
    "# Testing\n",
    "y_pred_knn = knn_hamming.predict(x_test)\n",
    "knn_hamming.classes_\n",
    "print(f'Models results: model {model}, dataset {dataset}, discretization {discretizer} with parameter {disc_param}', \n",
    "      file = f)\n",
    "print('Classification report', file = f)\n",
    "print(classification_report(y_test, y_pred_knn), file = f)\n",
    "\n",
    "from imblearn.metrics import geometric_mean_score as gmean\n",
    "print('G-mean:', gmean(y_test, y_pred_knn),file = f)\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model {model}- default, {disc}, k = {k} is: {end - start}.', file = f) # Total time execution\n",
    "print('=='*20, file = f)\n",
    "f.close()\n",
    "\n",
    "# Save models\n",
    "import skops.io as sio\n",
    "model_name = f\"{dataset}_{model}_{discretizer}_{k}.skops\"\n",
    "print(model_name)\n",
    "obj = sio.dump(knn_hamming, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb83c91",
   "metadata": {},
   "source": [
    "# 3. FFD datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08b9c13",
   "metadata": {},
   "source": [
    "## 3.1 FFD, m =10 (tranfusion_ffd1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a0213f",
   "metadata": {},
   "source": [
    "### Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cdb422c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10992 entries, 0 to 10991\n",
      "Data columns (total 16 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   A2      10992 non-null  int64\n",
      " 1   A3      10992 non-null  int64\n",
      " 2   A4      10992 non-null  int64\n",
      " 3   A5      10992 non-null  int64\n",
      " 4   A6      10992 non-null  int64\n",
      " 5   A7      10992 non-null  int64\n",
      " 6   A8      10992 non-null  int64\n",
      " 7   A9      10992 non-null  int64\n",
      " 8   A10     10992 non-null  int64\n",
      " 9   A11     10992 non-null  int64\n",
      " 10  A12     10992 non-null  int64\n",
      " 11  A13     10992 non-null  int64\n",
      " 12  A14     10992 non-null  int64\n",
      " 13  A15     10992 non-null  int64\n",
      " 14  A16     10992 non-null  int64\n",
      " 15  label   10992 non-null  int64\n",
      "dtypes: int64(16)\n",
      "memory usage: 1.3 MB\n",
      "(10992, 15) (10992,)\n",
      "(8244, 15)\n",
      "(2748, 15)\n",
      "=================\n",
      "Class representation - original:  Counter({2: 1144, 4: 1144, 1: 1143, 0: 1143, 7: 1142, 6: 1056, 8: 1055, 5: 1055, 9: 1055, 3: 1055})\n",
      "Class representation - training data:  Counter({4: 858, 2: 858, 0: 857, 1: 857, 7: 857, 5: 792, 6: 792, 3: 791, 8: 791, 9: 791})\n",
      "Class representation - testing data:  Counter({2: 286, 0: 286, 4: 286, 1: 286, 7: 285, 8: 264, 6: 264, 9: 264, 3: 264, 5: 263})\n"
     ]
    }
   ],
   "source": [
    "# Complete code for data preperation\n",
    "# Read data\n",
    "df_ffd1 = pd.read_csv('pendigits_ffd1.csv')\n",
    "df_ffd1.drop(df_ffd1.columns[0], axis=1, inplace = True)\n",
    "df_ffd1.rename(columns={'class':'label'}, inplace=True)\n",
    "\n",
    "disc = 'ffd'\n",
    "m = 10\n",
    "\n",
    "df_ffd1.info()\n",
    "data = df_ffd1.values\n",
    "data.shape\n",
    "\n",
    "features = df_ffd1.drop('label', axis = 1).columns\n",
    "\n",
    "# separate the data into X and y\n",
    "X = data[:, : len(features)]\n",
    "Y = data[:,-1]\n",
    "#X = df_ffd1[features]\n",
    "#Y = df_ffd1['class']\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "# Split train test\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state = 30, stratify=Y)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print('=================')\n",
    "\n",
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(Y)) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test)) \n",
    "\n",
    "# Check number of categories for features\n",
    "n_categories = df_ffd1[features].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4383b4",
   "metadata": {},
   "source": [
    "### Models, FFD, m = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c271a43c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pendigits_KNN-Hamming_FFD_10.skops\n"
     ]
    }
   ],
   "source": [
    "# Knn-Hammingcomplete code\n",
    "\n",
    "model = 'KNN-Hamming'\n",
    "dataset = 'pendigits'\n",
    "discretizer = 'FFD'\n",
    "disc_param = 'm = 10'\n",
    "\n",
    "f = open(\"pendigits_models.txt\", \"a\")\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "# Knn-Hamming complete code\n",
    "knn_hamming = KNeighborsClassifier(n_neighbors=3, metric='hamming', algorithm='auto')\n",
    "knn_hamming.fit(x_train, y_train)\n",
    "\n",
    "# Testing\n",
    "y_pred_knn = knn_hamming.predict(x_test)\n",
    "knn_hamming.classes_\n",
    "print(f'Models results: model {model}, dataset {dataset}, discretization {discretizer} with parameter {disc_param}', \n",
    "      file = f)\n",
    "print('Classification report', file = f)\n",
    "print(classification_report(y_test, y_pred_knn), file = f)\n",
    "\n",
    "from imblearn.metrics import geometric_mean_score as gmean\n",
    "print('G-mean:', gmean(y_test, y_pred_knn),file = f)\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model {model}- default, {disc}, m = {m} is: {end - start}.', file = f) # Total time execution\n",
    "print('=='*20, file = f)\n",
    "f.close()\n",
    "\n",
    "# Save models\n",
    "import skops.io as sio\n",
    "model_name = f\"{dataset}_{model}_{discretizer}_{m}.skops\"\n",
    "print(model_name)\n",
    "obj = sio.dump(knn_hamming, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fda1383",
   "metadata": {},
   "source": [
    "## 3.1 FFD, m =30 (tranfusion_ffd2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15cec70c",
   "metadata": {},
   "source": [
    "### Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e2f34b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10992 entries, 0 to 10991\n",
      "Data columns (total 16 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   A2      10992 non-null  int64\n",
      " 1   A3      10992 non-null  int64\n",
      " 2   A4      10992 non-null  int64\n",
      " 3   A5      10992 non-null  int64\n",
      " 4   A6      10992 non-null  int64\n",
      " 5   A7      10992 non-null  int64\n",
      " 6   A8      10992 non-null  int64\n",
      " 7   A9      10992 non-null  int64\n",
      " 8   A10     10992 non-null  int64\n",
      " 9   A11     10992 non-null  int64\n",
      " 10  A12     10992 non-null  int64\n",
      " 11  A13     10992 non-null  int64\n",
      " 12  A14     10992 non-null  int64\n",
      " 13  A15     10992 non-null  int64\n",
      " 14  A16     10992 non-null  int64\n",
      " 15  label   10992 non-null  int64\n",
      "dtypes: int64(16)\n",
      "memory usage: 1.3 MB\n",
      "(10992, 15) (10992,)\n",
      "Class representation - original:  Counter({2: 1144, 4: 1144, 1: 1143, 0: 1143, 7: 1142, 6: 1056, 8: 1055, 5: 1055, 9: 1055, 3: 1055})\n",
      "Class representation - training data:  Counter({4: 858, 2: 858, 0: 857, 1: 857, 7: 857, 5: 792, 6: 792, 3: 791, 8: 791, 9: 791})\n",
      "Class representation - testing data:  Counter({2: 286, 0: 286, 4: 286, 1: 286, 7: 285, 8: 264, 6: 264, 9: 264, 3: 264, 5: 263})\n"
     ]
    }
   ],
   "source": [
    "# Complete code for data preperation\n",
    "# Read data\n",
    "df_ffd2 = pd.read_csv('pendigits_ffd2.csv')\n",
    "df_ffd2.drop(df_ffd2.columns[0], axis=1, inplace = True)\n",
    "df_ffd2.rename(columns={'class':'label'}, inplace=True)\n",
    "\n",
    "disc = 'ffd'\n",
    "m = 30\n",
    "\n",
    "df_ffd2.info()\n",
    "data = df_ffd2.values\n",
    "data.shape\n",
    "\n",
    "features = df_ffd2.drop('label', axis = 1).columns\n",
    "\n",
    "# separate the data into X and y\n",
    "X = data[:, : len(features)]\n",
    "Y = data[:,-1]\n",
    "#X = df_ffd2[features]\n",
    "#Y = df_ffd2['class']\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "# Split train test\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state = 30, stratify=Y)\n",
    "\n",
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(Y)) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test)) \n",
    "\n",
    "# Check number of categories for features\n",
    "n_categories = df_ffd2[features].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a239b47",
   "metadata": {},
   "source": [
    "### Models, FFD, m = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "640bebd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pendigits_KNN-Hamming_FFD_30.skops\n"
     ]
    }
   ],
   "source": [
    "# Knn-Hammingcomplete code\n",
    "\n",
    "model = 'KNN-Hamming'\n",
    "dataset = 'pendigits'\n",
    "discretizer = 'FFD'\n",
    "disc_param = 'm = 30'\n",
    "\n",
    "f = open(\"pendigits_models.txt\", \"a\")\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "# Knn-Hamming complete code\n",
    "knn_hamming = KNeighborsClassifier(n_neighbors=3, metric='hamming', algorithm='auto')\n",
    "knn_hamming.fit(x_train, y_train)\n",
    "\n",
    "# Testing\n",
    "y_pred_knn = knn_hamming.predict(x_test)\n",
    "knn_hamming.classes_\n",
    "print(f'Models results: model {model}, dataset {dataset}, discretization {discretizer} with parameter {disc_param}', \n",
    "      file = f)\n",
    "print('Classification report', file = f)\n",
    "print(classification_report(y_test, y_pred_knn), file = f)\n",
    "\n",
    "from imblearn.metrics import geometric_mean_score as gmean\n",
    "print('G-mean:', gmean(y_test, y_pred_knn),file = f)\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model {model}- default, {disc}, m = {m} is: {end - start}.', file = f) # Total time execution\n",
    "print('=='*20, file = f)\n",
    "f.close()\n",
    "\n",
    "# Save models\n",
    "import skops.io as sio\n",
    "model_name = f\"{dataset}_{model}_{discretizer}_{m}.skops\"\n",
    "print(model_name)\n",
    "obj = sio.dump(knn_hamming, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1526d6c8",
   "metadata": {},
   "source": [
    "## 3.3 FFD, m =60 (tranfusion_ffd3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79807cd",
   "metadata": {},
   "source": [
    "### Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0040f50e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10992 entries, 0 to 10991\n",
      "Data columns (total 16 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   A2      10992 non-null  int64\n",
      " 1   A3      10992 non-null  int64\n",
      " 2   A4      10992 non-null  int64\n",
      " 3   A5      10992 non-null  int64\n",
      " 4   A6      10992 non-null  int64\n",
      " 5   A7      10992 non-null  int64\n",
      " 6   A8      10992 non-null  int64\n",
      " 7   A9      10992 non-null  int64\n",
      " 8   A10     10992 non-null  int64\n",
      " 9   A11     10992 non-null  int64\n",
      " 10  A12     10992 non-null  int64\n",
      " 11  A13     10992 non-null  int64\n",
      " 12  A14     10992 non-null  int64\n",
      " 13  A15     10992 non-null  int64\n",
      " 14  A16     10992 non-null  int64\n",
      " 15  label   10992 non-null  int64\n",
      "dtypes: int64(16)\n",
      "memory usage: 1.3 MB\n",
      "(10992, 15) (10992,)\n",
      "(8244, 15)\n",
      "(2748, 15)\n",
      "=================\n",
      "Class representation - original:  Counter({2: 1144, 4: 1144, 1: 1143, 0: 1143, 7: 1142, 6: 1056, 8: 1055, 5: 1055, 9: 1055, 3: 1055})\n",
      "Class representation - training data:  Counter({4: 858, 2: 858, 0: 857, 1: 857, 7: 857, 5: 792, 6: 792, 3: 791, 8: 791, 9: 791})\n",
      "Class representation - testing data:  Counter({2: 286, 0: 286, 4: 286, 1: 286, 7: 285, 8: 264, 6: 264, 9: 264, 3: 264, 5: 263})\n"
     ]
    }
   ],
   "source": [
    "# Complete code for data preperation\n",
    "# Read data\n",
    "df_ffd3 = pd.read_csv('pendigits_ffd3.csv')\n",
    "df_ffd3.drop(df_ffd3.columns[0], axis=1, inplace = True)\n",
    "df_ffd3.rename(columns={'class':'label'}, inplace=True)\n",
    "\n",
    "disc = 'ffd'\n",
    "m = 60\n",
    "\n",
    "df_ffd3.info()\n",
    "data = df_ffd3.values\n",
    "data.shape\n",
    "\n",
    "features = df_ffd3.drop('label', axis = 1).columns\n",
    "\n",
    "# separate the data into X and y\n",
    "X = data[:, : len(features)]\n",
    "Y = data[:,-1]\n",
    "#X = df_ffd3[features]\n",
    "#Y = df_ffd3['class']\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "# Split train test\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state = 30, stratify=Y)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print('=================')\n",
    "\n",
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(Y)) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test)) \n",
    "\n",
    "# Check number of categories for features\n",
    "n_categories = df_ffd3[features].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4809619f",
   "metadata": {},
   "source": [
    "### Models, FFD, m = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a96e449e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pendigits_KNN-Hamming_FFD_60.skops\n"
     ]
    }
   ],
   "source": [
    "# Knn-Hammingcomplete code\n",
    "\n",
    "model = 'KNN-Hamming'\n",
    "dataset = 'pendigits'\n",
    "discretizer = 'FFD'\n",
    "disc_param = 'm = 60'\n",
    "\n",
    "f = open(\"pendigits_models.txt\", \"a\")\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "# Knn-Hamming complete code\n",
    "knn_hamming = KNeighborsClassifier(n_neighbors=3, metric='hamming', algorithm='auto')\n",
    "knn_hamming.fit(x_train, y_train)\n",
    "\n",
    "# Testing\n",
    "y_pred_knn = knn_hamming.predict(x_test)\n",
    "knn_hamming.classes_\n",
    "print(f'Models results: model {model}, dataset {dataset}, discretization {discretizer} with parameter {disc_param}', \n",
    "      file = f)\n",
    "print('Classification report', file = f)\n",
    "print(classification_report(y_test, y_pred_knn), file = f)\n",
    "\n",
    "from imblearn.metrics import geometric_mean_score as gmean\n",
    "print('G-mean:', gmean(y_test, y_pred_knn),file = f)\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model {model}- default, {disc}, m = {m} is: {end - start}.', file = f) # Total time execution\n",
    "print('=='*20, file = f)\n",
    "f.close()\n",
    "\n",
    "# Save models\n",
    "import skops.io as sio\n",
    "model_name = f\"{dataset}_{model}_{discretizer}_{m}.skops\"\n",
    "print(model_name)\n",
    "obj = sio.dump(knn_hamming, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fd8e81",
   "metadata": {},
   "source": [
    "## 3.3 FFD, m =100 (tranfusion_ffd4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3bb0a9",
   "metadata": {},
   "source": [
    "### Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9241faf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10992 entries, 0 to 10991\n",
      "Data columns (total 16 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   A2      10992 non-null  int64\n",
      " 1   A3      10992 non-null  int64\n",
      " 2   A4      10992 non-null  int64\n",
      " 3   A5      10992 non-null  int64\n",
      " 4   A6      10992 non-null  int64\n",
      " 5   A7      10992 non-null  int64\n",
      " 6   A8      10992 non-null  int64\n",
      " 7   A9      10992 non-null  int64\n",
      " 8   A10     10992 non-null  int64\n",
      " 9   A11     10992 non-null  int64\n",
      " 10  A12     10992 non-null  int64\n",
      " 11  A13     10992 non-null  int64\n",
      " 12  A14     10992 non-null  int64\n",
      " 13  A15     10992 non-null  int64\n",
      " 14  A16     10992 non-null  int64\n",
      " 15  label   10992 non-null  int64\n",
      "dtypes: int64(16)\n",
      "memory usage: 1.3 MB\n",
      "(10992, 15) (10992,)\n",
      "Class representation - original:  Counter({2: 1144, 4: 1144, 1: 1143, 0: 1143, 7: 1142, 6: 1056, 8: 1055, 5: 1055, 9: 1055, 3: 1055})\n",
      "Class representation - training data:  Counter({4: 858, 2: 858, 0: 857, 1: 857, 7: 857, 5: 792, 6: 792, 3: 791, 8: 791, 9: 791})\n",
      "Class representation - testing data:  Counter({2: 286, 0: 286, 4: 286, 1: 286, 7: 285, 8: 264, 6: 264, 9: 264, 3: 264, 5: 263})\n"
     ]
    }
   ],
   "source": [
    "# Complete code for data preperation\n",
    "# Read data\n",
    "df_ffd4 = pd.read_csv('pendigits_ffd4.csv')\n",
    "df_ffd4.drop(df_ffd4.columns[0], axis=1, inplace = True)\n",
    "df_ffd4.rename(columns={'class':'label'}, inplace=True)\n",
    "\n",
    "disc = 'ffd'\n",
    "m = 100\n",
    "\n",
    "df_ffd4.info()\n",
    "data = df_ffd4.values\n",
    "data.shape\n",
    "\n",
    "features = df_ffd4.drop('label', axis = 1).columns\n",
    "\n",
    "# separate the data into X and y\n",
    "X = data[:, : len(features)]\n",
    "Y = data[:,-1]\n",
    "#X = df_ffd4[features]\n",
    "#Y = df_ffd4['class']\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "# Split train test\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state = 30, stratify=Y)\n",
    "\n",
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(Y)) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test)) \n",
    "\n",
    "# Check number of categories for features\n",
    "n_categories = df_ffd4[features].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060773d1",
   "metadata": {},
   "source": [
    "### Models, FFD, m = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "408625bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pendigits_KNN-Hamming_FFD_100.skops\n"
     ]
    }
   ],
   "source": [
    "# Knn-Hammingcomplete code\n",
    "\n",
    "model = 'KNN-Hamming'\n",
    "dataset = 'pendigits'\n",
    "discretizer = 'FFD'\n",
    "disc_param = 'm = 100'\n",
    "\n",
    "f = open(\"pendigits_models.txt\", \"a\")\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "# Knn-Hamming complete code\n",
    "knn_hamming = KNeighborsClassifier(n_neighbors=3, metric='hamming', algorithm='auto')\n",
    "knn_hamming.fit(x_train, y_train)\n",
    "\n",
    "# Testing\n",
    "y_pred_knn = knn_hamming.predict(x_test)\n",
    "knn_hamming.classes_\n",
    "print(f'Models results: model {model}, dataset {dataset}, discretization {discretizer} with parameter {disc_param}', \n",
    "      file = f)\n",
    "print('Classification report', file = f)\n",
    "print(classification_report(y_test, y_pred_knn), file = f)\n",
    "\n",
    "from imblearn.metrics import geometric_mean_score as gmean\n",
    "print('G-mean:', gmean(y_test, y_pred_knn),file = f)\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model {model}- default, {disc}, m = {m} is: {end - start}.', file = f) # Total time execution\n",
    "print('=='*20, file = f)\n",
    "f.close()\n",
    "\n",
    "# Save models\n",
    "import skops.io as sio\n",
    "model_name = f\"{dataset}_{model}_{discretizer}_{m}.skops\"\n",
    "print(model_name)\n",
    "obj = sio.dump(knn_hamming, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b530c5d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "361241f9a80b796977997c633c663aa5cf3bdc315ac376a4c38a1a056ab6874d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
