{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e739595",
   "metadata": {},
   "source": [
    "# Two-sided Wilcoxon SIGNED test - bias\n",
    "\n",
    "By: Sam<br>\n",
    "Updated at: 27/04/23<br>\n",
    "Compare performance of discretizers <br>\n",
    "\n",
    "===\n",
    "\n",
    "Matched pairs settings\n",
    "- Sample: 540 ML models after discretization (as at 27/04/2023)\n",
    "- Purpose: pair-wise comparison metrics of the models using different discretization method\n",
    "    - Test 1.1: Compare bias between pairs of discretizers, regardless of algorithms\n",
    "    - Test 1.2-1.6: Compare bias between pairs of discretizers, filter by models (CNB, ID3, Knn-Hamming, Knn-VDM, KNN)\n",
    "    \n",
    "===\n",
    "\n",
    "Input data: instrinsic properties and model performance metrics <br>\n",
    "ChiMerge manuallly and ChiMerge-SB are merged together. <br>\n",
    "!!! **NB: Please update the data for metrics and export to csv before running this script!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1810bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5845bab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import evaluation data (updated at 27/04/2023)\n",
    "data = pd.read_csv(\"all_evaluation_270423.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e6fd0c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>disc</th>\n",
       "      <th>param</th>\n",
       "      <th>inconsistency</th>\n",
       "      <th>models</th>\n",
       "      <th>con_features</th>\n",
       "      <th>size</th>\n",
       "      <th>time_disc</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time_train</th>\n",
       "      <th>bias</th>\n",
       "      <th>variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iris</td>\n",
       "      <td>EWD</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0667</td>\n",
       "      <td>ID3</td>\n",
       "      <td>4</td>\n",
       "      <td>150</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.008698225</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>iris</td>\n",
       "      <td>EWD</td>\n",
       "      <td>7</td>\n",
       "      <td>0.02</td>\n",
       "      <td>ID3</td>\n",
       "      <td>4</td>\n",
       "      <td>150</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.010634899</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>iris</td>\n",
       "      <td>EWD</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>ID3</td>\n",
       "      <td>4</td>\n",
       "      <td>150</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.010643005</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>iris</td>\n",
       "      <td>EFD</td>\n",
       "      <td>4</td>\n",
       "      <td>0.04</td>\n",
       "      <td>ID3</td>\n",
       "      <td>4</td>\n",
       "      <td>150</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.009439945</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>iris</td>\n",
       "      <td>EFD</td>\n",
       "      <td>7</td>\n",
       "      <td>0.04</td>\n",
       "      <td>ID3</td>\n",
       "      <td>4</td>\n",
       "      <td>150</td>\n",
       "      <td>0.0239</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.010675907</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset disc  param  inconsistency  models  con_features size  time_disc  \\\n",
       "0    iris  EWD      4          0.0667    ID3             4  150     0.0164   \n",
       "1    iris  EWD      7            0.02    ID3             4  150     0.0157   \n",
       "2    iris  EWD     10          0.0067    ID3             4  150     0.0164   \n",
       "3    iris  EFD      4            0.04    ID3             4  150     0.0167   \n",
       "4    iris  EFD      7            0.04    ID3             4  150     0.0239   \n",
       "\n",
       "  accuracy   time_train   bias variance  \n",
       "0     0.84  0.008698225  0.158    0.055  \n",
       "1     0.79  0.010634899  0.158    0.054  \n",
       "2     0.95  0.010643005  0.053    0.014  \n",
       "3     0.84  0.009439945  0.158    0.049  \n",
       "4     0.95  0.010675907  0.053     0.07  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb690ad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['EWD', 'EFD', 'FFD', 'ChiMerge', 'DT', 'ChiMerge-SB'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['disc'].unique() # get list of discretizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82abae21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['dataset', 'disc', 'param', ' inconsistency ', 'models', 'con_features',\n",
       "       'size', 'time_disc', 'accuracy', 'time_train', 'bias', 'variance'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4baafad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 540 entries, 0 to 539\n",
      "Data columns (total 12 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   dataset          540 non-null    object \n",
      " 1   disc             540 non-null    object \n",
      " 2   param            540 non-null    int64  \n",
      " 3    inconsistency   540 non-null    object \n",
      " 4   models           540 non-null    object \n",
      " 5   con_features     540 non-null    int64  \n",
      " 6   size             540 non-null    object \n",
      " 7   time_disc        540 non-null    float64\n",
      " 8   accuracy         540 non-null    object \n",
      " 9   time_train       540 non-null    object \n",
      " 10  bias             540 non-null    object \n",
      " 11  variance         540 non-null    object \n",
      "dtypes: float64(1), int64(2), object(9)\n",
      "memory usage: 50.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4cf2753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ID3', 'CNB', 'Knn-VDM', 'Knn-Hamming'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['models'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f48fed5",
   "metadata": {},
   "source": [
    "# Wilcoxon_Complete pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ae483f",
   "metadata": {},
   "source": [
    "## 1.  Wilcoxon signed t test, bias\n",
    "Ref: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.wilcoxon.html\n",
    "Implement 4 replications: (DONE)\n",
    "- Regardless algorithms\n",
    "- Filter for each algorithm: CNB, ID3, Knn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa58850",
   "metadata": {},
   "source": [
    "## 1.1 bias, no filter in algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ef5cead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n",
      "90\n",
      "120\n",
      "120\n",
      "120\n"
     ]
    }
   ],
   "source": [
    "# Preparation: Prepare list of metrics for each discretization (test_list)\n",
    "# Step 1: Obtain bias for each discretization, convert into numeric, string values will be return as NaN\n",
    "ewd_acc = pd.to_numeric(data[data['disc']==\"EWD\"]['bias'],errors='coerce').tolist()\n",
    "efd_acc = pd.to_numeric(data[data['disc']==\"EFD\"]['bias'],errors='coerce').tolist()\n",
    "ffd_acc = pd.to_numeric(data[data['disc']==\"FFD\"]['bias'],errors='coerce').tolist()\n",
    "cm_acc = pd.to_numeric(data[(data['disc']==\"ChiMerge\") | (data['disc'] == \"ChiMerge-SB\")]['bias'],errors='coerce').tolist()\n",
    "dt_acc = pd.to_numeric(data[data['disc']==\"DT\"]['bias'],errors='coerce').tolist()\n",
    "# Check number of metrics available for each discretizer\n",
    "print(len(ewd_acc))\n",
    "print(len(efd_acc))\n",
    "print(len(ffd_acc))\n",
    "print(len(cm_acc))\n",
    "print(len(dt_acc))\n",
    "\n",
    "# Step 2: filter numeric values\n",
    "raw_list = [ewd_acc, efd_acc, ffd_acc, cm_acc, dt_acc]\n",
    "num_list = [] # filter numeric values only\n",
    "for metric in raw_list:\n",
    "    metric_new = [x for x in metric if (math.isnan(x) == False)] # using list comprehension\n",
    "    num_list.append(metric_new)\n",
    "    \n",
    "# Step 3: random sample\n",
    "# For discretization methods with different value, randomly select so that the final sample size are equal\n",
    "# Reference: https://docs.python.org/3/library/random.html\n",
    "k = min(len(metric) for metric in num_list)\n",
    "test_list = []\n",
    "for metric in num_list:\n",
    "    random.seed(20)\n",
    "    if len(metric) > k:\n",
    "        metric = random.sample(metric, k=k)\n",
    "    else: metric = metric\n",
    "    #print(metric)\n",
    "    test_list.append(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8612d553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialiation\n",
    "disc_key = ['ewd', 'efd', 'ffd', 'cm', 'dt']\n",
    "disc_value = test_list # list of metrics for each discretization after preparation\n",
    "test_stat = []\n",
    "p_value = []\n",
    "disc_compare = []\n",
    "# Create dictionary store discretization and series of bias\n",
    "disc = {}\n",
    "for key in disc_key:\n",
    "    for value in disc_value:\n",
    "        disc[key] = value\n",
    "        disc_value.remove(value)\n",
    "        break  \n",
    "\n",
    "# Create loop for Wilcoxon test (two sided) - handle diff = 0\n",
    "for i in disc_key:\n",
    "    for j in disc_key:\n",
    "        if i != j:\n",
    "            disc_compare.append(f'{i} vs {j}')\n",
    "            # print(f'{i} vs {j}')\n",
    "            # Compute difference list\n",
    "            diff_list = []\n",
    "            for m in range(0, len(disc[i])):\n",
    "                diff = disc[i][m] - disc[j][m]\n",
    "                diff_list.append(diff)\n",
    "                                \n",
    "            if all(item == 0 for item in diff_list) == False: # if the diff list does not contain all 0\n",
    "                test_stat.append(stats.wilcoxon(diff_list).statistic)\n",
    "                p_value.append(stats.wilcoxon(diff_list).pvalue)\n",
    "            else: # if the diff list contain only0, cannot do Wilcoxon test\n",
    "                error = 'N/A'\n",
    "                test_stat.append(error)\n",
    "                p_value.append(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fcac455c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 3 lists to dataframe\n",
    "disc_compare = pd.DataFrame(disc_compare, columns=['disc_compare'])\n",
    "test_stat = pd.DataFrame(test_stat, columns=['wtest_stat'])\n",
    "p_value = pd.DataFrame(p_value, columns=['p_value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "128116ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result table\n",
    "wt_result = pd.concat([disc_compare, test_stat, p_value], axis = 1)\n",
    "# Drop duplicate\n",
    "wt_result.drop_duplicates(subset=['p_value'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "468124b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disc_compare</th>\n",
       "      <th>wtest_stat</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ewd vs efd</td>\n",
       "      <td>1234.5</td>\n",
       "      <td>0.091318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ewd vs ffd</td>\n",
       "      <td>1251.0</td>\n",
       "      <td>0.107865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ewd vs cm</td>\n",
       "      <td>1163.0</td>\n",
       "      <td>0.060075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ewd vs dt</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>0.018986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>efd vs ffd</td>\n",
       "      <td>1488.5</td>\n",
       "      <td>0.947372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>efd vs cm</td>\n",
       "      <td>1358.0</td>\n",
       "      <td>0.363353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>efd vs dt</td>\n",
       "      <td>1283.5</td>\n",
       "      <td>0.200523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ffd vs cm</td>\n",
       "      <td>1468.0</td>\n",
       "      <td>0.584134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ffd vs dt</td>\n",
       "      <td>1369.5</td>\n",
       "      <td>0.303605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>cm vs dt</td>\n",
       "      <td>1419.0</td>\n",
       "      <td>0.545064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   disc_compare  wtest_stat   p_value\n",
       "0    ewd vs efd      1234.5  0.091318\n",
       "1    ewd vs ffd      1251.0  0.107865\n",
       "2     ewd vs cm      1163.0  0.060075\n",
       "3     ewd vs dt      1100.0  0.018986\n",
       "5    efd vs ffd      1488.5  0.947372\n",
       "6     efd vs cm      1358.0  0.363353\n",
       "7     efd vs dt      1283.5  0.200523\n",
       "10    ffd vs cm      1468.0  0.584134\n",
       "11    ffd vs dt      1369.5  0.303605\n",
       "15     cm vs dt      1419.0  0.545064"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wt_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "264c7d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting result\n",
    "\n",
    "model = 'all'\n",
    "metric = 'bias'\n",
    "test = 'two_sided'\n",
    "\n",
    "filename = f\"wilcoxon_{metric}_{model}-{test}.csv\"\n",
    "wt_result['model'] = model\n",
    "wt_result['metric'] = metric\n",
    "\n",
    "wt_result.to_csv(filename, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f913a1e4",
   "metadata": {},
   "source": [
    "## 1.2 bias, only CNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8106b10b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "30\n",
      "40\n",
      "40\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "# Preparation: Prepare list of metrics for each discretization (test_list)\n",
    "# Step 1: Obtain bias for each discretization, convert into numeric, string values will be return as NaN\n",
    "# Filter for CNB\n",
    "# Obtain bias for each discretization, convert into numeric, string values will be return as NaN\n",
    "ewd_acc_cnb = pd.to_numeric(data[(data['disc']==\"EWD\") & (data['models']==\"CNB\")]['bias'],errors='coerce').tolist()\n",
    "efd_acc_cnb = pd.to_numeric(data[(data['disc']==\"EFD\") & (data['models']==\"CNB\")]['bias'],errors='coerce').tolist()\n",
    "ffd_acc_cnb = pd.to_numeric(data[(data['disc']==\"FFD\") & (data['models']==\"CNB\")]['bias'],errors='coerce').tolist()\n",
    "cm_acc_cnb = pd.to_numeric(data[((data['disc']==\"ChiMerge\") | (data['disc'] == \"ChiMerge-SB\")) & (data['models']==\"CNB\")]['bias'],errors='coerce').tolist()\n",
    "dt_acc_cnb = pd.to_numeric(data[(data['disc']==\"DT\") & (data['models']==\"CNB\")]['bias'],errors='coerce').tolist()\n",
    "# Check number of metrics available for each discretizer\n",
    "print(len(ewd_acc_cnb))\n",
    "print(len(efd_acc_cnb))\n",
    "print(len(ffd_acc_cnb))\n",
    "print(len(cm_acc_cnb))\n",
    "print(len(dt_acc_cnb))\n",
    "\n",
    "# Step 2: filter numeric values\n",
    "raw_list = [ewd_acc_cnb,efd_acc_cnb, ffd_acc_cnb, cm_acc_cnb, dt_acc_cnb]\n",
    "num_list = [] # filter numeric values only\n",
    "for metric in raw_list:\n",
    "    metric_new = [x for x in metric if (math.isnan(x) == False)] # using list comprehension\n",
    "    num_list.append(metric_new)\n",
    "    \n",
    "# Step 3: random sample\n",
    "# For discretization methods with different value, randomly select so that the final sample size are equal\n",
    "# Reference: https://docs.python.org/3/library/random.html\n",
    "k = min(len(metric) for metric in num_list)\n",
    "test_list = []\n",
    "for metric in num_list:\n",
    "    random.seed(20)\n",
    "    if len(metric) > k:\n",
    "        metric = random.sample(metric, k=k)\n",
    "    else: metric = metric\n",
    "    #print(metric)\n",
    "    test_list.append(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5307c38f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anhtth/opt/anaconda3/lib/python3.9/site-packages/scipy/stats/morestats.py:3141: UserWarning: Exact p-value calculation does not work if there are ties. Switching to normal approximation.\n",
      "  warnings.warn(\"Exact p-value calculation does not work if there are \"\n"
     ]
    }
   ],
   "source": [
    "# Initialiation\n",
    "disc_key = ['ewd', 'efd', 'ffd', 'cm', 'dt']\n",
    "disc_value = test_list # list of metrics for each discretization after preparation\n",
    "test_stat = []\n",
    "p_value = []\n",
    "disc_compare = []\n",
    "# Create dictionary store discretization and series of bias\n",
    "disc = {}\n",
    "for key in disc_key:\n",
    "    for value in disc_value:\n",
    "        disc[key] = value\n",
    "        disc_value.remove(value)\n",
    "        break  \n",
    "\n",
    "# Create loop for Wilcoxon test (two sided) - handle diff = 0\n",
    "for i in disc_key:\n",
    "    for j in disc_key:\n",
    "        if i != j:\n",
    "            disc_compare.append(f'{i} vs {j}')\n",
    "            # print(f'{i} vs {j}')\n",
    "            # Compute difference list\n",
    "            diff_list = []\n",
    "            for m in range(0, len(disc[i])):\n",
    "                diff = disc[i][m] - disc[j][m]\n",
    "                diff_list.append(diff)\n",
    "                \n",
    "            if all(item == 0 for item in diff_list) == False: # if the diff list does not contain all 0\n",
    "                test_stat.append(stats.wilcoxon(diff_list).statistic)\n",
    "                p_value.append(stats.wilcoxon(diff_list).pvalue)\n",
    "            else: # if the diff list contain only0, cannot do Wilcoxon test\n",
    "                error = 'N/A'\n",
    "                test_stat.append(error)\n",
    "                p_value.append(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c24d6a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 3 lists to dataframe\n",
    "disc_compare = pd.DataFrame(disc_compare, columns=['disc_compare'])\n",
    "test_stat = pd.DataFrame(test_stat, columns=['wtest_stat'])\n",
    "p_value = pd.DataFrame(p_value, columns=['p_value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6c42f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result table\n",
    "wt_result = pd.concat([disc_compare, test_stat, p_value], axis = 1)\n",
    "# Drop duplicate\n",
    "wt_result.drop_duplicates(subset=['p_value'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7dde02f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disc_compare</th>\n",
       "      <th>wtest_stat</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ewd vs efd</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.454889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ewd vs ffd</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.176192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ewd vs cm</td>\n",
       "      <td>81.5</td>\n",
       "      <td>0.155971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>efd vs ffd</td>\n",
       "      <td>115.0</td>\n",
       "      <td>0.726184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>efd vs cm</td>\n",
       "      <td>117.0</td>\n",
       "      <td>0.774529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ffd vs cm</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0.502840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ffd vs dt</td>\n",
       "      <td>96.5</td>\n",
       "      <td>0.508904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>cm vs ewd</td>\n",
       "      <td>81.5</td>\n",
       "      <td>0.146517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>cm vs dt</td>\n",
       "      <td>103.0</td>\n",
       "      <td>0.940481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   disc_compare  wtest_stat   p_value\n",
       "0    ewd vs efd        94.0  0.454889\n",
       "1    ewd vs ffd        84.0  0.176192\n",
       "2     ewd vs cm        81.5  0.155971\n",
       "5    efd vs ffd       115.0  0.726184\n",
       "6     efd vs cm       117.0  0.774529\n",
       "10    ffd vs cm       105.0  0.502840\n",
       "11    ffd vs dt        96.5  0.508904\n",
       "12    cm vs ewd        81.5  0.146517\n",
       "15     cm vs dt       103.0  0.940481"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wt_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5693c601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting result\n",
    "\n",
    "model = 'CNB'\n",
    "metric = 'bias'\n",
    "test = 'two_sided'\n",
    "\n",
    "filename = f\"wilcoxon_{metric}_{model}-{test}.csv\"\n",
    "wt_result['model'] = model\n",
    "wt_result['metric'] = metric\n",
    "\n",
    "wt_result.to_csv(filename, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da97b22e",
   "metadata": {},
   "source": [
    "## 1.3 bias, only ID3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a3a4c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "30\n",
      "40\n",
      "40\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "# Preparation: Prepare list of metrics for each discretization (test_list)\n",
    "# Step 1: Obtain bias for each discretization, convert into numeric, string values will be return as NaN\n",
    "# Filter for ID3\n",
    "# Obtain bias for each discretization, convert into numeric, string values will be return as NaN\n",
    "ewd_acc_ID3 = pd.to_numeric(data[(data['disc']==\"EWD\") & (data['models']==\"ID3\")]['bias'],errors='coerce').tolist()\n",
    "efd_acc_ID3 = pd.to_numeric(data[(data['disc']==\"EFD\") & (data['models']==\"ID3\")]['bias'],errors='coerce').tolist()\n",
    "ffd_acc_ID3 = pd.to_numeric(data[(data['disc']==\"FFD\") & (data['models']==\"ID3\")]['bias'],errors='coerce').tolist()\n",
    "cm_acc_ID3 = pd.to_numeric(data[((data['disc']==\"ChiMerge\") | (data['disc'] == \"ChiMerge-SB\")) & (data['models']==\"ID3\")]['bias'],errors='coerce').tolist()\n",
    "dt_acc_ID3 = pd.to_numeric(data[(data['disc']==\"DT\") & (data['models']==\"ID3\")]['bias'],errors='coerce').tolist()\n",
    "# Check number of metrics available for each discretizer\n",
    "print(len(ewd_acc_ID3))\n",
    "print(len(efd_acc_ID3))\n",
    "print(len(ffd_acc_ID3))\n",
    "print(len(cm_acc_ID3))\n",
    "print(len(dt_acc_ID3))\n",
    "\n",
    "# Step 2: filter numeric values\n",
    "raw_list = [ewd_acc_ID3,efd_acc_ID3, ffd_acc_ID3, cm_acc_ID3, dt_acc_ID3]\n",
    "num_list = [] # filter numeric values only\n",
    "for metric in raw_list:\n",
    "    metric_new = [x for x in metric if (math.isnan(x) == False)] # using list comprehension\n",
    "    num_list.append(metric_new)\n",
    "    \n",
    "# Step 3: random sample\n",
    "# For discretization methods with different value, randomly select so that the final sample size are equal\n",
    "# Reference: https://docs.python.org/3/library/random.html\n",
    "k = min(len(metric) for metric in num_list)\n",
    "test_list = []\n",
    "for metric in num_list:\n",
    "    random.seed(20)\n",
    "    if len(metric) > k:\n",
    "        metric = random.sample(metric, k=k)\n",
    "    else: metric = metric\n",
    "    #print(metric)\n",
    "    test_list.append(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4be48448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialiation\n",
    "disc_key = ['ewd', 'efd', 'ffd', 'cm', 'dt']\n",
    "disc_value = test_list # list of metrics for each discretization after preparation\n",
    "test_stat = []\n",
    "p_value = []\n",
    "disc_compare = []\n",
    "# Create dictionary store discretization and series of bias\n",
    "disc = {}\n",
    "for key in disc_key:\n",
    "    for value in disc_value:\n",
    "        disc[key] = value\n",
    "        disc_value.remove(value)\n",
    "        break  \n",
    "\n",
    "# Create loop for Wilcoxon test (two sided) - handle diff = 0\n",
    "for i in disc_key:\n",
    "    for j in disc_key:\n",
    "        if i != j:\n",
    "            disc_compare.append(f'{i} vs {j}')\n",
    "            # print(f'{i} vs {j}')\n",
    "            # Compute difference list\n",
    "            diff_list = []\n",
    "            for m in range(0, len(disc[i])):\n",
    "                diff = disc[i][m] - disc[j][m]\n",
    "                diff_list.append(diff)\n",
    "                              \n",
    "            if all(item == 0 for item in diff_list) == False: # if the diff list does not contain all 0\n",
    "                test_stat.append(stats.wilcoxon(diff_list).statistic)\n",
    "                p_value.append(stats.wilcoxon(diff_list).pvalue)\n",
    "            else: # if the diff list contain only0, cannot do Wilcoxon test\n",
    "                error = 'N/A'\n",
    "                test_stat.append(error)\n",
    "                p_value.append(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "edaa296d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 3 lists to dataframe\n",
    "disc_compare = pd.DataFrame(disc_compare, columns=['disc_compare'])\n",
    "test_stat = pd.DataFrame(test_stat, columns=['wtest_stat'])\n",
    "p_value = pd.DataFrame(p_value, columns=['p_value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "401dfa3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result table\n",
    "wt_result = pd.concat([disc_compare, test_stat, p_value], axis = 1)\n",
    "# Drop duplicate\n",
    "wt_result.drop_duplicates(subset=['p_value'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0edd8d64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disc_compare</th>\n",
       "      <th>wtest_stat</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ewd vs efd</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.016386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ewd vs ffd</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.349333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ewd vs cm</td>\n",
       "      <td>207.5</td>\n",
       "      <td>0.607087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ewd vs dt</td>\n",
       "      <td>161.0</td>\n",
       "      <td>0.141379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>efd vs ffd</td>\n",
       "      <td>224.5</td>\n",
       "      <td>0.869297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>efd vs cm</td>\n",
       "      <td>197.5</td>\n",
       "      <td>0.471568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>efd vs dt</td>\n",
       "      <td>222.0</td>\n",
       "      <td>0.829013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ffd vs cm</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.032480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ffd vs dt</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.616391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>cm vs dt</td>\n",
       "      <td>164.0</td>\n",
       "      <td>0.247323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   disc_compare  wtest_stat   p_value\n",
       "0    ewd vs efd        81.0  0.016386\n",
       "1    ewd vs ffd       187.0  0.349333\n",
       "2     ewd vs cm       207.5  0.607087\n",
       "3     ewd vs dt       161.0  0.141379\n",
       "5    efd vs ffd       224.5  0.869297\n",
       "6     efd vs cm       197.5  0.471568\n",
       "7     efd vs dt       222.0  0.829013\n",
       "10    ffd vs cm       100.0  0.032480\n",
       "11    ffd vs dt       181.0  0.616391\n",
       "15     cm vs dt       164.0  0.247323"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wt_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "da7dfe5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting result\n",
    "\n",
    "model = 'ID3'\n",
    "metric = 'bias'\n",
    "test = 'two_sided'\n",
    "\n",
    "filename = f\"wilcoxon_{metric}_{model}-{test}.csv\"\n",
    "wt_result['model'] = model\n",
    "wt_result['metric'] = metric\n",
    "\n",
    "wt_result.to_csv(filename, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0751228c",
   "metadata": {},
   "source": [
    "## 1.4 bias, only KNN-VDM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f924ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "9\n",
      "12\n",
      "8\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "# Preparation: Prepare list of metrics for each discretization (test_list)\n",
    "# Step 1: Obtain bias for each discretization, convert into numeric, string values will be return as NaN\n",
    "# Filter for Knn-VDM\n",
    "# Obtain bias for each discretization, convert into numeric, string values will be return as NaN\n",
    "ewd_acc_knn_vdm = pd.to_numeric(data[(data['disc']==\"EWD\") & (data['models']==\"Knn-VDM\")]['bias'],errors='coerce').tolist()\n",
    "efd_acc_knn_vdm = pd.to_numeric(data[(data['disc']==\"EFD\") & (data['models']==\"Knn-VDM\")]['bias'],errors='coerce').tolist()\n",
    "ffd_acc_knn_vdm = pd.to_numeric(data[(data['disc']==\"FFD\") & (data['models']==\"Knn-VDM\")]['bias'],errors='coerce').tolist()\n",
    "cm_acc_knn_vdm = pd.to_numeric(data[((data['disc']==\"ChiMerge\") | (data['disc'] == \"ChiMerge-SB\")) & (data['models']==\"Knn-VDM\")]['bias'],errors='coerce').tolist()\n",
    "dt_acc_knn_vdm = pd.to_numeric(data[(data['disc']==\"ChiMerge\") & (data['models']==\"Knn-VDM\")]['bias'],errors='coerce').tolist()\n",
    "\n",
    "# Check number of metrics available for each discretizer\n",
    "print(len(ewd_acc_knn_vdm))\n",
    "print(len(efd_acc_knn_vdm))\n",
    "print(len(ffd_acc_knn_vdm))\n",
    "print(len(cm_acc_knn_vdm))\n",
    "print(len(dt_acc_knn_vdm))\n",
    "\n",
    "# Step 2: filter numeric values\n",
    "raw_list = [ewd_acc_knn_vdm,efd_acc_knn_vdm, ffd_acc_knn_vdm, cm_acc_knn_vdm, dt_acc_knn_vdm]\n",
    "num_list = [] # filter numeric values only\n",
    "for metric in raw_list:\n",
    "    metric_new = [x for x in metric if (math.isnan(x) == False)] # using list comprehension\n",
    "    num_list.append(metric_new)\n",
    "    \n",
    "# Step 3: random sample\n",
    "# For discretization methods with different value, randomly select so that the final sample size are equal\n",
    "# Reference: https://docs.python.org/3/library/random.html\n",
    "k = min(len(metric) for metric in num_list)\n",
    "test_list = []\n",
    "for metric in num_list:\n",
    "    random.seed(20)\n",
    "    if len(metric) > k:\n",
    "        metric = random.sample(metric, k=k)\n",
    "    else: metric = metric\n",
    "    #print(metric)\n",
    "    test_list.append(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dbd8b869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.105, 0.026, 0.053, 0.22, 0.214, 0.171], [0.105, 0.053, 0.053, 0.214, 0.214, 0.214, 0.307, 0.286, 0.29], [0.026, 0.053, 0.132, 0.132, 0.214, 0.197, 0.191, 0.202, 0.32, 0.299, 0.307, 0.147], [0.053, 0.053, 0.198, 0.234, 0.219], [0.053, 0.053, 0.198, 0.234, 0.219]]\n"
     ]
    }
   ],
   "source": [
    "print(num_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0bd52114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c35b52f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.171, 0.026, 0.053, 0.22, 0.105], [0.053, 0.214, 0.214, 0.307, 0.105], [0.147, 0.307, 0.132, 0.214, 0.053], [0.053, 0.053, 0.198, 0.234, 0.219], [0.053, 0.053, 0.198, 0.234, 0.219]]\n"
     ]
    }
   ],
   "source": [
    "print(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "03a78dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(len(test_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8c005139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialiation\n",
    "disc_key = ['ewd', 'efd', 'ffd', 'cm', 'dt']\n",
    "disc_value = test_list # list of metrics for each discretization after preparation\n",
    "test_stat = []\n",
    "p_value = []\n",
    "disc_compare = []\n",
    "# Create dictionary store discretization and series of bias\n",
    "disc = {}\n",
    "for key in disc_key:\n",
    "    for value in disc_value:\n",
    "        disc[key] = value\n",
    "        disc_value.remove(value)\n",
    "        break  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "889fa084",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anhtth/opt/anaconda3/lib/python3.9/site-packages/scipy/stats/morestats.py:3141: UserWarning: Exact p-value calculation does not work if there are ties. Switching to normal approximation.\n",
      "  warnings.warn(\"Exact p-value calculation does not work if there are \"\n",
      "/Users/anhtth/opt/anaconda3/lib/python3.9/site-packages/scipy/stats/morestats.py:3155: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    }
   ],
   "source": [
    "# Create loop for Wilcoxon test (two sided)\n",
    "for i in disc_key:\n",
    "    for j in disc_key:\n",
    "        if i != j:\n",
    "            disc_compare.append(f'{i} vs {j}')\n",
    "            # print(f'{i} vs {j}')\n",
    "            # Compute difference list\n",
    "            diff_list = []\n",
    "            for m in range(0, len(disc[i])):\n",
    "                diff = disc[i][m] - disc[j][m]\n",
    "                diff_list.append(diff)\n",
    "                                \n",
    "            if all(item == 0 for item in diff_list) == False: # if the diff list does not contain all 0\n",
    "                test_stat.append(stats.wilcoxon(diff_list).statistic)\n",
    "                p_value.append(stats.wilcoxon(diff_list).pvalue)\n",
    "            else: # if the diff list contain only0, cannot do Wilcoxon test\n",
    "                error = 'N/A'\n",
    "                test_stat.append(error)\n",
    "                p_value.append(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a31e4d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 3 lists to dataframe\n",
    "disc_compare = pd.DataFrame(disc_compare, columns=['disc_compare'])\n",
    "test_stat = pd.DataFrame(test_stat, columns=['wtest_stat'])\n",
    "p_value = pd.DataFrame(p_value, columns=['p_value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3e8b0807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result table\n",
    "wt_result = pd.concat([disc_compare, test_stat, p_value], axis = 1)\n",
    "# Drop duplicate\n",
    "wt_result.drop_duplicates(subset=['p_value'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c2e41873",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disc_compare</th>\n",
       "      <th>wtest_stat</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ewd vs efd</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.273322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ewd vs ffd</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.8125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ewd vs cm</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.4375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>efd vs cm</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.465209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ffd vs efd</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>cm vs dt</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   disc_compare wtest_stat   p_value\n",
       "0    ewd vs efd        2.0  0.273322\n",
       "1    ewd vs ffd        6.0    0.8125\n",
       "2     ewd vs cm        4.0    0.4375\n",
       "6     efd vs cm        3.0  0.465209\n",
       "9    ffd vs efd        6.5       1.0\n",
       "15     cm vs dt        N/A       N/A"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wt_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "16d2dcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting result\n",
    "\n",
    "model = 'KNN-VDM'\n",
    "metric = 'bias'\n",
    "test = 'two_sided'\n",
    "\n",
    "filename = f\"wilcoxon_{metric}_{model}-{test}.csv\"\n",
    "wt_result['model'] = model\n",
    "wt_result['metric'] = metric\n",
    "\n",
    "wt_result.to_csv(filename, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dba50ff",
   "metadata": {},
   "source": [
    "## 1.5 bias, only KNN-Hamming\n",
    "\n",
    "Knn-Hamming is applied for 5 datasets during Capita Selecta phases (post BNAIC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "873c048c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "21\n",
      "28\n",
      "32\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "# Preparation: Prepare list of metrics for each discretization (test_list)\n",
    "# Step 1: Obtain bias for each discretization, convert into numeric, string values will be return as NaN\n",
    "# Filter for Knn-VDM\n",
    "# Obtain bias for each discretization, convert into numeric, string values will be return as NaN\n",
    "ewd_acc_knn_hamming = pd.to_numeric(data[(data['disc']==\"EWD\") & (data['models']==\"Knn-Hamming\")]['bias'],errors='coerce').tolist()\n",
    "efd_acc_knn_hamming = pd.to_numeric(data[(data['disc']==\"EFD\") & (data['models']==\"Knn-Hamming\")]['bias'],errors='coerce').tolist()\n",
    "ffd_acc_knn_hamming = pd.to_numeric(data[(data['disc']==\"FFD\") & (data['models']==\"Knn-Hamming\")]['bias'],errors='coerce').tolist()\n",
    "cm_acc_knn_hamming = pd.to_numeric(data[((data['disc']==\"ChiMerge\") | (data['disc'] == \"ChiMerge-SB\")) & (data['models']==\"Knn-Hamming\")]['bias'],errors='coerce').tolist()\n",
    "dt_acc_knn_hamming = pd.to_numeric(data[(data['disc']==\"ChiMerge\") & (data['models']==\"Knn-Hamming\")]['bias'],errors='coerce').tolist()\n",
    "\n",
    "# Check number of metrics available for each discretizer\n",
    "print(len(ewd_acc_knn_hamming))\n",
    "print(len(efd_acc_knn_hamming))\n",
    "print(len(ffd_acc_knn_hamming))\n",
    "print(len(cm_acc_knn_hamming))\n",
    "print(len(dt_acc_knn_hamming))\n",
    "\n",
    "# Step 2: filter numeric values\n",
    "raw_list = [ewd_acc_knn_hamming,efd_acc_knn_hamming, ffd_acc_knn_hamming, cm_acc_knn_hamming, dt_acc_knn_hamming]\n",
    "num_list = [] # filter numeric values only\n",
    "for metric in raw_list:\n",
    "    metric_new = [x for x in metric if (math.isnan(x) == False)] # using list comprehension\n",
    "    num_list.append(metric_new)\n",
    "    \n",
    "# Step 3: random sample\n",
    "# For discretization methods with different value, randomly select so that the final sample size are equal\n",
    "# Reference: https://docs.python.org/3/library/random.html\n",
    "k = min(len(metric) for metric in num_list)\n",
    "test_list = []\n",
    "for metric in num_list:\n",
    "    random.seed(20)\n",
    "    if len(metric) > k:\n",
    "        metric = random.sample(metric, k=k)\n",
    "    else: metric = metric\n",
    "    #print(metric)\n",
    "    test_list.append(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fffc7969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialiation\n",
    "disc_key = ['ewd', 'efd', 'ffd', 'cm', 'dt']\n",
    "disc_value = test_list # list of metrics for each discretization after preparation\n",
    "test_stat = []\n",
    "p_value = []\n",
    "disc_compare = []\n",
    "# Create dictionary store discretization and series of bias\n",
    "disc = {}\n",
    "for key in disc_key:\n",
    "    for value in disc_value:\n",
    "        disc[key] = value\n",
    "        disc_value.remove(value)\n",
    "        break \n",
    "        \n",
    "# Create loop for Wilcoxon test (two sided)\n",
    "for i in disc_key:\n",
    "    for j in disc_key:\n",
    "        if i != j:\n",
    "            disc_compare.append(f'{i} vs {j}')\n",
    "            # print(f'{i} vs {j}')\n",
    "            # Compute difference list\n",
    "            diff_list = []\n",
    "            for m in range(0, len(disc[i])):\n",
    "                diff = disc[i][m] - disc[j][m]\n",
    "                diff_list.append(diff)\n",
    "            if all(item == 0 for item in diff_list) == False: # if the diff list does not contain all 0\n",
    "                test_stat.append(stats.wilcoxon(diff_list).statistic)\n",
    "                p_value.append(stats.wilcoxon(diff_list).pvalue)\n",
    "            else: # if the diff list contain only0, cannot do Wilcoxon test\n",
    "                error = 'N/A'\n",
    "                test_stat.append(error)\n",
    "                p_value.append(error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e7334085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 3 lists to dataframe\n",
    "disc_compare = pd.DataFrame(disc_compare, columns=['disc_compare'])\n",
    "test_stat = pd.DataFrame(test_stat, columns=['wtest_stat'])\n",
    "p_value = pd.DataFrame(p_value, columns=['p_value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cca9c056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result table\n",
    "wt_result = pd.concat([disc_compare, test_stat, p_value], axis = 1)\n",
    "# Drop duplicate\n",
    "wt_result.drop_duplicates(subset=['p_value'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e146a27d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disc_compare</th>\n",
       "      <th>wtest_stat</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ewd vs efd</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.063965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ewd vs ffd</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.518555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ewd vs cm</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.677246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>efd vs ffd</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.380371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>efd vs cm</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.969727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>efd vs dt</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.850098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ffd vs cm</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.339355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ffd vs dt</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.109863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>cm vs dt</td>\n",
       "      <td>31.5</td>\n",
       "      <td>0.622070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>dt vs cm</td>\n",
       "      <td>31.5</td>\n",
       "      <td>0.569336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   disc_compare  wtest_stat   p_value\n",
       "0    ewd vs efd        15.0  0.063965\n",
       "1    ewd vs ffd        30.0  0.518555\n",
       "2     ewd vs cm        33.0  0.677246\n",
       "5    efd vs ffd        27.0  0.380371\n",
       "6     efd vs cm        38.0  0.969727\n",
       "7     efd vs dt        36.0  0.850098\n",
       "10    ffd vs cm        26.0  0.339355\n",
       "11    ffd vs dt        18.0  0.109863\n",
       "15     cm vs dt        31.5  0.622070\n",
       "19     dt vs cm        31.5  0.569336"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wt_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "310a64e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting result\n",
    "\n",
    "model = 'KNN-Hamming'\n",
    "metric = 'bias'\n",
    "test = 'two_sided'\n",
    "\n",
    "filename = f\"wilcoxon_{metric}_{model}-{test}.csv\"\n",
    "wt_result['model'] = model\n",
    "wt_result['metric'] = metric\n",
    "\n",
    "wt_result.to_csv(filename, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa320a5",
   "metadata": {},
   "source": [
    "## 1.6 bias, KNN (Knn-VDM and Knn-Hamming)\n",
    "\n",
    "Merge both result from Knn-VDM and KNN-Hamming\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b52f711a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "30\n",
      "40\n",
      "40\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "# Preparation: Prepare list of metrics for each discretization (test_list)\n",
    "# Step 1: Obtain bias for each discretization, convert into numeric, string values will be return as NaN\n",
    "# Filter for Knn-VDM\n",
    "# Obtain bias for each discretization, convert into numeric, string values will be return as NaN\n",
    "ewd_acc_knn = pd.to_numeric(data[(data['disc']==\"EWD\") & ((data['models']==\"Knn-Hamming\") | (data['models']==\"Knn-VDM\"))]['bias'],errors='coerce').tolist()\n",
    "efd_acc_knn = pd.to_numeric(data[(data['disc']==\"EFD\") & ((data['models']==\"Knn-Hamming\") | (data['models']==\"Knn-VDM\"))]['bias'],errors='coerce').tolist()\n",
    "ffd_acc_knn = pd.to_numeric(data[(data['disc']==\"FFD\") & ((data['models']==\"Knn-Hamming\") | (data['models']==\"Knn-VDM\"))]['bias'],errors='coerce').tolist()\n",
    "cm_acc_knn = pd.to_numeric(data[((data['disc']==\"ChiMerge\") | (data['disc'] == \"ChiMerge-SB\")) & ((data['models']==\"Knn-Hamming\") | (data['models']==\"Knn-VDM\"))]['bias'],errors='coerce').tolist()\n",
    "dt_acc_knn = pd.to_numeric(data[(data['disc']==\"ChiMerge\") & ((data['models']==\"Knn-Hamming\") | (data['models']==\"Knn-VDM\"))]['bias'],errors='coerce').tolist()\n",
    "\n",
    "# Check number of metrics available for each discretizer\n",
    "print(len(ewd_acc_knn))\n",
    "print(len(efd_acc_knn))\n",
    "print(len(ffd_acc_knn))\n",
    "print(len(cm_acc_knn))\n",
    "print(len(dt_acc_knn))\n",
    "\n",
    "# Step 2: filter numeric values\n",
    "raw_list = [ewd_acc_knn,efd_acc_knn, ffd_acc_knn, cm_acc_knn, dt_acc_knn]\n",
    "num_list = [] # filter numeric values only\n",
    "for metric in raw_list:\n",
    "    metric_new = [x for x in metric if (math.isnan(x) == False)] # using list comprehension\n",
    "    num_list.append(metric_new)\n",
    "    \n",
    "# Step 3: random sample\n",
    "# For discretization methods with different value, randomly select so that the final sample size are equal\n",
    "# Reference: https://docs.python.org/3/library/random.html\n",
    "k = min(len(metric) for metric in num_list)\n",
    "test_list = []\n",
    "for metric in num_list:\n",
    "    random.seed(20)\n",
    "    if len(metric) > k:\n",
    "        metric = random.sample(metric, k=k)\n",
    "    else: metric = metric\n",
    "    #print(metric)\n",
    "    test_list.append(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e417064c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anhtth/opt/anaconda3/lib/python3.9/site-packages/scipy/stats/morestats.py:3141: UserWarning: Exact p-value calculation does not work if there are ties. Switching to normal approximation.\n",
      "  warnings.warn(\"Exact p-value calculation does not work if there are \"\n"
     ]
    }
   ],
   "source": [
    "# Initialiation\n",
    "disc_key = ['ewd', 'efd', 'ffd', 'cm', 'dt']\n",
    "disc_value = test_list # list of metrics for each discretization after preparation\n",
    "test_stat = []\n",
    "p_value = []\n",
    "disc_compare = []\n",
    "# Create dictionary store discretization and series of bias\n",
    "disc = {}\n",
    "for key in disc_key:\n",
    "    for value in disc_value:\n",
    "        disc[key] = value\n",
    "        disc_value.remove(value)\n",
    "        break \n",
    "        \n",
    "# Create loop for Wilcoxon test (two sided)\n",
    "for i in disc_key:\n",
    "    for j in disc_key:\n",
    "        if i != j:\n",
    "            disc_compare.append(f'{i} vs {j}')\n",
    "            # print(f'{i} vs {j}')\n",
    "            # Compute difference list\n",
    "            diff_list = []\n",
    "            for m in range(0, len(disc[i])):\n",
    "                diff = disc[i][m] - disc[j][m]\n",
    "                diff_list.append(diff)\n",
    "            if all(item == 0 for item in diff_list) == False: # if the diff list does not contain all 0\n",
    "                test_stat.append(stats.wilcoxon(diff_list).statistic)\n",
    "                p_value.append(stats.wilcoxon(diff_list).pvalue)\n",
    "            else: # if the diff list contain only0, cannot do Wilcoxon test\n",
    "                error = 'N/A'\n",
    "                test_stat.append(error)\n",
    "                p_value.append(error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3e9618bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 3 lists to dataframe\n",
    "disc_compare = pd.DataFrame(disc_compare, columns=['disc_compare'])\n",
    "test_stat = pd.DataFrame(test_stat, columns=['wtest_stat'])\n",
    "p_value = pd.DataFrame(p_value, columns=['p_value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "72a1bfc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disc_compare</th>\n",
       "      <th>wtest_stat</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ewd vs efd</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.430679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ewd vs ffd</td>\n",
       "      <td>64.5</td>\n",
       "      <td>0.579056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ewd vs cm</td>\n",
       "      <td>75.5</td>\n",
       "      <td>0.963226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ewd vs dt</td>\n",
       "      <td>57.5</td>\n",
       "      <td>0.403763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>efd vs ffd</td>\n",
       "      <td>38.5</td>\n",
       "      <td>0.071411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>efd vs cm</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.352875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>efd vs dt</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.817581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ffd vs ewd</td>\n",
       "      <td>64.5</td>\n",
       "      <td>0.611221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ffd vs efd</td>\n",
       "      <td>38.5</td>\n",
       "      <td>0.079681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ffd vs cm</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.301054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ffd vs dt</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.120209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>cm vs ewd</td>\n",
       "      <td>75.5</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>cm vs dt</td>\n",
       "      <td>41.5</td>\n",
       "      <td>0.170527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>dt vs ewd</td>\n",
       "      <td>57.5</td>\n",
       "      <td>0.377823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   disc_compare  wtest_stat   p_value\n",
       "0    ewd vs efd        59.0  0.430679\n",
       "1    ewd vs ffd        64.5  0.579056\n",
       "2     ewd vs cm        75.5  0.963226\n",
       "3     ewd vs dt        57.5  0.403763\n",
       "5    efd vs ffd        38.5  0.071411\n",
       "6     efd vs cm        56.0  0.352875\n",
       "7     efd vs dt        71.0  0.817581\n",
       "8    ffd vs ewd        64.5  0.611221\n",
       "9    ffd vs efd        38.5  0.079681\n",
       "10    ffd vs cm        48.0  0.301054\n",
       "11    ffd vs dt        43.0  0.120209\n",
       "12    cm vs ewd        75.5  1.000000\n",
       "15     cm vs dt        41.5  0.170527\n",
       "16    dt vs ewd        57.5  0.377823"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Result table\n",
    "wt_result = pd.concat([disc_compare, test_stat, p_value], axis = 1)\n",
    "# Drop duplicate\n",
    "wt_result.drop_duplicates(subset=['p_value'], inplace=True)\n",
    "wt_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fbdc16df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting result\n",
    "\n",
    "model = 'KNN'\n",
    "metric = 'bias'\n",
    "test = 'two_sided'\n",
    "\n",
    "filename = f\"wilcoxon_{metric}_{model}-{test}.csv\"\n",
    "wt_result['model'] = model\n",
    "wt_result['metric'] = metric\n",
    "\n",
    "wt_result.to_csv(filename, index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
