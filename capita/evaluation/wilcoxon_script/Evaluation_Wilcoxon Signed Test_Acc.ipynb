{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e739595",
   "metadata": {},
   "source": [
    "# Two-sided Wilcoxon SIGNED test - ACCURACY\n",
    "\n",
    "By: Sam<br>\n",
    "Updated at: 27/04/23<br>\n",
    "Compare performance of discretizers <br>\n",
    "\n",
    "===\n",
    "\n",
    "Matched pairs settings\n",
    "- Sample: 540 ML models after discretization (as at 27/04/23)\n",
    "- Purpose: pair-wise comparison metrics of the models using different discretization method\n",
    "    - Test 1.1: Compare accuracy between pairs of discretizers, regardless of algorithms\n",
    "    - Test 1.2-1.6: Compare accuracy between pairs of discretizers, filter by models (CNB, ID3, Knn-Hamming, Knn-VDM, KNN)\n",
    "    \n",
    "===\n",
    "\n",
    "Input data: instrinsic properties and model performance metrics <br>\n",
    "ChiMerge manuallly and ChiMerge-SB are merged together. <br>\n",
    "!!! **NB: Please update the data for metrics and export to csv before running this script!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1810bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5845bab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import evaluation data (updated at 27/04/2023)\n",
    "data = pd.read_csv(\"all_evaluation_270423.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e6fd0c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>disc</th>\n",
       "      <th>param</th>\n",
       "      <th>inconsistency</th>\n",
       "      <th>models</th>\n",
       "      <th>con_features</th>\n",
       "      <th>size</th>\n",
       "      <th>time_disc</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time_train</th>\n",
       "      <th>bias</th>\n",
       "      <th>variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iris</td>\n",
       "      <td>EWD</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0667</td>\n",
       "      <td>ID3</td>\n",
       "      <td>4</td>\n",
       "      <td>150</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.008698225</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>iris</td>\n",
       "      <td>EWD</td>\n",
       "      <td>7</td>\n",
       "      <td>0.02</td>\n",
       "      <td>ID3</td>\n",
       "      <td>4</td>\n",
       "      <td>150</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.010634899</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>iris</td>\n",
       "      <td>EWD</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>ID3</td>\n",
       "      <td>4</td>\n",
       "      <td>150</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.010643005</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>iris</td>\n",
       "      <td>EFD</td>\n",
       "      <td>4</td>\n",
       "      <td>0.04</td>\n",
       "      <td>ID3</td>\n",
       "      <td>4</td>\n",
       "      <td>150</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.009439945</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>iris</td>\n",
       "      <td>EFD</td>\n",
       "      <td>7</td>\n",
       "      <td>0.04</td>\n",
       "      <td>ID3</td>\n",
       "      <td>4</td>\n",
       "      <td>150</td>\n",
       "      <td>0.0239</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.010675907</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset disc  param  inconsistency  models  con_features size  time_disc  \\\n",
       "0    iris  EWD      4          0.0667    ID3             4  150     0.0164   \n",
       "1    iris  EWD      7            0.02    ID3             4  150     0.0157   \n",
       "2    iris  EWD     10          0.0067    ID3             4  150     0.0164   \n",
       "3    iris  EFD      4            0.04    ID3             4  150     0.0167   \n",
       "4    iris  EFD      7            0.04    ID3             4  150     0.0239   \n",
       "\n",
       "  accuracy   time_train   bias variance  \n",
       "0     0.84  0.008698225  0.158    0.055  \n",
       "1     0.79  0.010634899  0.158    0.054  \n",
       "2     0.95  0.010643005  0.053    0.014  \n",
       "3     0.84  0.009439945  0.158    0.049  \n",
       "4     0.95  0.010675907  0.053     0.07  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb690ad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['EWD', 'EFD', 'FFD', 'ChiMerge', 'DT', 'ChiMerge-SB'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['disc'].unique() # get list of discretizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82abae21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['dataset', 'disc', 'param', ' inconsistency ', 'models', 'con_features',\n",
       "       'size', 'time_disc', 'accuracy', 'time_train', 'bias', 'variance'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4baafad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 540 entries, 0 to 539\n",
      "Data columns (total 12 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   dataset          540 non-null    object \n",
      " 1   disc             540 non-null    object \n",
      " 2   param            540 non-null    int64  \n",
      " 3    inconsistency   540 non-null    object \n",
      " 4   models           540 non-null    object \n",
      " 5   con_features     540 non-null    int64  \n",
      " 6   size             540 non-null    object \n",
      " 7   time_disc        540 non-null    float64\n",
      " 8   accuracy         540 non-null    object \n",
      " 9   time_train       540 non-null    object \n",
      " 10  bias             540 non-null    object \n",
      " 11  variance         540 non-null    object \n",
      "dtypes: float64(1), int64(2), object(9)\n",
      "memory usage: 50.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4cf2753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ID3', 'CNB', 'Knn-VDM', 'Knn-Hamming'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['models'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f48fed5",
   "metadata": {},
   "source": [
    "# Wilcoxon_Complete pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ae483f",
   "metadata": {},
   "source": [
    "## 1.  Wilcoxon signed t test, accuracy\n",
    "Ref: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.wilcoxon.html\n",
    "Implement 4 replications: (DONE)\n",
    "- Regardless algorithms\n",
    "- Filter for each algorithm: CNB, ID3, Knn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa58850",
   "metadata": {},
   "source": [
    "## 1.1 Accuracy, no filter in algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ef5cead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n",
      "90\n",
      "120\n",
      "120\n",
      "120\n"
     ]
    }
   ],
   "source": [
    "# Preparation: Prepare list of metrics for each discretization (test_list)\n",
    "# Step 1: Obtain accuracy for each discretization, convert into numeric, string values will be return as NaN\n",
    "ewd_acc = pd.to_numeric(data[data['disc']==\"EWD\"]['accuracy'],errors='coerce').tolist()\n",
    "efd_acc = pd.to_numeric(data[data['disc']==\"EFD\"]['accuracy'],errors='coerce').tolist()\n",
    "ffd_acc = pd.to_numeric(data[data['disc']==\"FFD\"]['accuracy'],errors='coerce').tolist()\n",
    "cm_acc = pd.to_numeric(data[(data['disc']==\"ChiMerge\") | (data['disc'] == \"ChiMerge-SB\")]['accuracy'],errors='coerce').tolist()\n",
    "dt_acc = pd.to_numeric(data[data['disc']==\"DT\"]['accuracy'],errors='coerce').tolist()\n",
    "# Check number of metrics available for each discretizer\n",
    "print(len(ewd_acc))\n",
    "print(len(efd_acc))\n",
    "print(len(ffd_acc))\n",
    "print(len(cm_acc))\n",
    "print(len(dt_acc))\n",
    "\n",
    "# Step 2: filter numeric values\n",
    "raw_list = [ewd_acc, efd_acc, ffd_acc, cm_acc, dt_acc]\n",
    "num_list = [] # filter numeric values only\n",
    "for metric in raw_list:\n",
    "    metric_new = [x for x in metric if (math.isnan(x) == False)] # using list comprehension\n",
    "    num_list.append(metric_new)\n",
    "    \n",
    "# Step 3: random sample\n",
    "# For discretization methods with different value, randomly select so that the final sample size are equal\n",
    "# Reference: https://docs.python.org/3/library/random.html\n",
    "k = min(len(metric) for metric in num_list)\n",
    "test_list = []\n",
    "for metric in num_list:\n",
    "    random.seed(20)\n",
    "    if len(metric) > k:\n",
    "        metric = random.sample(metric, k=k)\n",
    "    else: metric = metric\n",
    "    #print(metric)\n",
    "    test_list.append(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8612d553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialiation\n",
    "disc_key = ['ewd', 'efd', 'ffd', 'cm', 'dt']\n",
    "disc_value = test_list # list of metrics for each discretization after preparation\n",
    "test_stat = []\n",
    "p_value = []\n",
    "disc_compare = []\n",
    "# Create dictionary store discretization and series of accuracy\n",
    "disc = {}\n",
    "for key in disc_key:\n",
    "    for value in disc_value:\n",
    "        disc[key] = value\n",
    "        disc_value.remove(value)\n",
    "        break  \n",
    "\n",
    "# Create loop for Wilcoxon test (two sided) - handle diff = 0\n",
    "for i in disc_key:\n",
    "    for j in disc_key:\n",
    "        if i != j:\n",
    "            disc_compare.append(f'{i} vs {j}')\n",
    "            # print(f'{i} vs {j}')\n",
    "            # Compute difference list\n",
    "            diff_list = []\n",
    "            for m in range(0, len(disc[i])):\n",
    "                diff = disc[i][m] - disc[j][m]\n",
    "                diff_list.append(diff)\n",
    "                                \n",
    "            if all(item == 0 for item in diff_list) == False: # if the diff list does not contain all 0\n",
    "                test_stat.append(stats.wilcoxon(diff_list).statistic)\n",
    "                p_value.append(stats.wilcoxon(diff_list).pvalue)\n",
    "            else: # if the diff list contain only0, cannot do Wilcoxon test\n",
    "                error = 'N/A'\n",
    "                test_stat.append(error)\n",
    "                p_value.append(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fcac455c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 3 lists to dataframe\n",
    "disc_compare = pd.DataFrame(disc_compare, columns=['disc_compare'])\n",
    "test_stat = pd.DataFrame(test_stat, columns=['wtest_stat'])\n",
    "p_value = pd.DataFrame(p_value, columns=['p_value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "128116ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result table\n",
    "wt_result = pd.concat([disc_compare, test_stat, p_value], axis = 1)\n",
    "# Drop duplicate\n",
    "wt_result.drop_duplicates(subset=['p_value'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "468124b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disc_compare</th>\n",
       "      <th>wtest_stat</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ewd vs efd</td>\n",
       "      <td>1417.5</td>\n",
       "      <td>0.669683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ewd vs ffd</td>\n",
       "      <td>1391.5</td>\n",
       "      <td>0.205254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ewd vs cm</td>\n",
       "      <td>1178.0</td>\n",
       "      <td>0.033979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ewd vs dt</td>\n",
       "      <td>992.5</td>\n",
       "      <td>0.004083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>efd vs ffd</td>\n",
       "      <td>1634.0</td>\n",
       "      <td>0.900682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>efd vs cm</td>\n",
       "      <td>1415.0</td>\n",
       "      <td>0.185245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>efd vs dt</td>\n",
       "      <td>1005.5</td>\n",
       "      <td>0.004979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ffd vs cm</td>\n",
       "      <td>1283.5</td>\n",
       "      <td>0.147236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ffd vs dt</td>\n",
       "      <td>1049.5</td>\n",
       "      <td>0.014442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>cm vs dt</td>\n",
       "      <td>1402.5</td>\n",
       "      <td>0.224373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   disc_compare  wtest_stat   p_value\n",
       "0    ewd vs efd      1417.5  0.669683\n",
       "1    ewd vs ffd      1391.5  0.205254\n",
       "2     ewd vs cm      1178.0  0.033979\n",
       "3     ewd vs dt       992.5  0.004083\n",
       "5    efd vs ffd      1634.0  0.900682\n",
       "6     efd vs cm      1415.0  0.185245\n",
       "7     efd vs dt      1005.5  0.004979\n",
       "10    ffd vs cm      1283.5  0.147236\n",
       "11    ffd vs dt      1049.5  0.014442\n",
       "15     cm vs dt      1402.5  0.224373"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wt_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "264c7d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting result\n",
    "\n",
    "model = 'all'\n",
    "metric = 'accuracy'\n",
    "test = 'two_sided'\n",
    "\n",
    "filename = f\"wilcoxon_{metric}_{model}-{test}.csv\"\n",
    "wt_result['model'] = model\n",
    "wt_result['metric'] = metric\n",
    "\n",
    "wt_result.to_csv(filename, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f913a1e4",
   "metadata": {},
   "source": [
    "## 1.2 Accuracy, only CNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8106b10b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "30\n",
      "40\n",
      "40\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "# Preparation: Prepare list of metrics for each discretization (test_list)\n",
    "# Step 1: Obtain accuracy for each discretization, convert into numeric, string values will be return as NaN\n",
    "# Filter for CNB\n",
    "# Obtain accuracy for each discretization, convert into numeric, string values will be return as NaN\n",
    "ewd_acc_cnb = pd.to_numeric(data[(data['disc']==\"EWD\") & (data['models']==\"CNB\")]['accuracy'],errors='coerce').tolist()\n",
    "efd_acc_cnb = pd.to_numeric(data[(data['disc']==\"EFD\") & (data['models']==\"CNB\")]['accuracy'],errors='coerce').tolist()\n",
    "ffd_acc_cnb = pd.to_numeric(data[(data['disc']==\"FFD\") & (data['models']==\"CNB\")]['accuracy'],errors='coerce').tolist()\n",
    "cm_acc_cnb = pd.to_numeric(data[((data['disc']==\"ChiMerge\") | (data['disc'] == \"ChiMerge-SB\")) & (data['models']==\"CNB\")]['accuracy'],errors='coerce').tolist()\n",
    "dt_acc_cnb = pd.to_numeric(data[(data['disc']==\"DT\") & (data['models']==\"CNB\")]['accuracy'],errors='coerce').tolist()\n",
    "# Check number of metrics available for each discretizer\n",
    "print(len(ewd_acc_cnb))\n",
    "print(len(efd_acc_cnb))\n",
    "print(len(ffd_acc_cnb))\n",
    "print(len(cm_acc_cnb))\n",
    "print(len(dt_acc_cnb))\n",
    "\n",
    "# Step 2: filter numeric values\n",
    "raw_list = [ewd_acc_cnb,efd_acc_cnb, ffd_acc_cnb, cm_acc_cnb, dt_acc_cnb]\n",
    "num_list = [] # filter numeric values only\n",
    "for metric in raw_list:\n",
    "    metric_new = [x for x in metric if (math.isnan(x) == False)] # using list comprehension\n",
    "    num_list.append(metric_new)\n",
    "    \n",
    "# Step 3: random sample\n",
    "# For discretization methods with different value, randomly select so that the final sample size are equal\n",
    "# Reference: https://docs.python.org/3/library/random.html\n",
    "k = min(len(metric) for metric in num_list)\n",
    "test_list = []\n",
    "for metric in num_list:\n",
    "    random.seed(20)\n",
    "    if len(metric) > k:\n",
    "        metric = random.sample(metric, k=k)\n",
    "    else: metric = metric\n",
    "    #print(metric)\n",
    "    test_list.append(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5307c38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialiation\n",
    "disc_key = ['ewd', 'efd', 'ffd', 'cm', 'dt']\n",
    "disc_value = test_list # list of metrics for each discretization after preparation\n",
    "test_stat = []\n",
    "p_value = []\n",
    "disc_compare = []\n",
    "# Create dictionary store discretization and series of accuracy\n",
    "disc = {}\n",
    "for key in disc_key:\n",
    "    for value in disc_value:\n",
    "        disc[key] = value\n",
    "        disc_value.remove(value)\n",
    "        break  \n",
    "\n",
    "# Create loop for Wilcoxon test (two sided) - handle diff = 0\n",
    "for i in disc_key:\n",
    "    for j in disc_key:\n",
    "        if i != j:\n",
    "            disc_compare.append(f'{i} vs {j}')\n",
    "            # print(f'{i} vs {j}')\n",
    "            # Compute difference list\n",
    "            diff_list = []\n",
    "            for m in range(0, len(disc[i])):\n",
    "                diff = disc[i][m] - disc[j][m]\n",
    "                diff_list.append(diff)\n",
    "                \n",
    "            if all(item == 0 for item in diff_list) == False: # if the diff list does not contain all 0\n",
    "                test_stat.append(stats.wilcoxon(diff_list).statistic)\n",
    "                p_value.append(stats.wilcoxon(diff_list).pvalue)\n",
    "            else: # if the diff list contain only0, cannot do Wilcoxon test\n",
    "                error = 'N/A'\n",
    "                test_stat.append(error)\n",
    "                p_value.append(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c24d6a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 3 lists to dataframe\n",
    "disc_compare = pd.DataFrame(disc_compare, columns=['disc_compare'])\n",
    "test_stat = pd.DataFrame(test_stat, columns=['wtest_stat'])\n",
    "p_value = pd.DataFrame(p_value, columns=['p_value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6c42f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result table\n",
    "wt_result = pd.concat([disc_compare, test_stat, p_value], axis = 1)\n",
    "# Drop duplicate\n",
    "wt_result.drop_duplicates(subset=['p_value'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7dde02f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disc_compare</th>\n",
       "      <th>wtest_stat</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ewd vs efd</td>\n",
       "      <td>127.5</td>\n",
       "      <td>0.749358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ewd vs ffd</td>\n",
       "      <td>125.5</td>\n",
       "      <td>0.483793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ewd vs cm</td>\n",
       "      <td>139.5</td>\n",
       "      <td>0.360409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ewd vs dt</td>\n",
       "      <td>143.0</td>\n",
       "      <td>0.408823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>efd vs ffd</td>\n",
       "      <td>94.5</td>\n",
       "      <td>0.185640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>efd vs cm</td>\n",
       "      <td>155.0</td>\n",
       "      <td>0.839979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>efd vs dt</td>\n",
       "      <td>151.0</td>\n",
       "      <td>0.756920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ffd vs cm</td>\n",
       "      <td>89.0</td>\n",
       "      <td>0.135956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ffd vs dt</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.073212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>cm vs dt</td>\n",
       "      <td>125.0</td>\n",
       "      <td>0.691467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   disc_compare  wtest_stat   p_value\n",
       "0    ewd vs efd       127.5  0.749358\n",
       "1    ewd vs ffd       125.5  0.483793\n",
       "2     ewd vs cm       139.5  0.360409\n",
       "3     ewd vs dt       143.0  0.408823\n",
       "5    efd vs ffd        94.5  0.185640\n",
       "6     efd vs cm       155.0  0.839979\n",
       "7     efd vs dt       151.0  0.756920\n",
       "10    ffd vs cm        89.0  0.135956\n",
       "11    ffd vs dt        64.0  0.073212\n",
       "15     cm vs dt       125.0  0.691467"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wt_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5693c601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting result\n",
    "\n",
    "model = 'CNB'\n",
    "metric = 'accuracy'\n",
    "test = 'two_sided'\n",
    "\n",
    "filename = f\"wilcoxon_{metric}_{model}-{test}.csv\"\n",
    "wt_result['model'] = model\n",
    "wt_result['metric'] = metric\n",
    "\n",
    "wt_result.to_csv(filename, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da97b22e",
   "metadata": {},
   "source": [
    "## 1.3 Accuracy, only ID3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a3a4c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "30\n",
      "40\n",
      "40\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "# Preparation: Prepare list of metrics for each discretization (test_list)\n",
    "# Step 1: Obtain accuracy for each discretization, convert into numeric, string values will be return as NaN\n",
    "# Filter for ID3\n",
    "# Obtain accuracy for each discretization, convert into numeric, string values will be return as NaN\n",
    "ewd_acc_ID3 = pd.to_numeric(data[(data['disc']==\"EWD\") & (data['models']==\"ID3\")]['accuracy'],errors='coerce').tolist()\n",
    "efd_acc_ID3 = pd.to_numeric(data[(data['disc']==\"EFD\") & (data['models']==\"ID3\")]['accuracy'],errors='coerce').tolist()\n",
    "ffd_acc_ID3 = pd.to_numeric(data[(data['disc']==\"FFD\") & (data['models']==\"ID3\")]['accuracy'],errors='coerce').tolist()\n",
    "cm_acc_ID3 = pd.to_numeric(data[((data['disc']==\"ChiMerge\") | (data['disc'] == \"ChiMerge-SB\")) & (data['models']==\"ID3\")]['accuracy'],errors='coerce').tolist()\n",
    "dt_acc_ID3 = pd.to_numeric(data[(data['disc']==\"DT\") & (data['models']==\"ID3\")]['accuracy'],errors='coerce').tolist()\n",
    "# Check number of metrics available for each discretizer\n",
    "print(len(ewd_acc_ID3))\n",
    "print(len(efd_acc_ID3))\n",
    "print(len(ffd_acc_ID3))\n",
    "print(len(cm_acc_ID3))\n",
    "print(len(dt_acc_ID3))\n",
    "\n",
    "# Step 2: filter numeric values\n",
    "raw_list = [ewd_acc_ID3,efd_acc_ID3, ffd_acc_ID3, cm_acc_ID3, dt_acc_ID3]\n",
    "num_list = [] # filter numeric values only\n",
    "for metric in raw_list:\n",
    "    metric_new = [x for x in metric if (math.isnan(x) == False)] # using list comprehension\n",
    "    num_list.append(metric_new)\n",
    "    \n",
    "# Step 3: random sample\n",
    "# For discretization methods with different value, randomly select so that the final sample size are equal\n",
    "# Reference: https://docs.python.org/3/library/random.html\n",
    "k = min(len(metric) for metric in num_list)\n",
    "test_list = []\n",
    "for metric in num_list:\n",
    "    random.seed(20)\n",
    "    if len(metric) > k:\n",
    "        metric = random.sample(metric, k=k)\n",
    "    else: metric = metric\n",
    "    #print(metric)\n",
    "    test_list.append(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4be48448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialiation\n",
    "disc_key = ['ewd', 'efd', 'ffd', 'cm', 'dt']\n",
    "disc_value = test_list # list of metrics for each discretization after preparation\n",
    "test_stat = []\n",
    "p_value = []\n",
    "disc_compare = []\n",
    "# Create dictionary store discretization and series of accuracy\n",
    "disc = {}\n",
    "for key in disc_key:\n",
    "    for value in disc_value:\n",
    "        disc[key] = value\n",
    "        disc_value.remove(value)\n",
    "        break  \n",
    "\n",
    "# Create loop for Wilcoxon test (two sided) - handle diff = 0\n",
    "for i in disc_key:\n",
    "    for j in disc_key:\n",
    "        if i != j:\n",
    "            disc_compare.append(f'{i} vs {j}')\n",
    "            # print(f'{i} vs {j}')\n",
    "            # Compute difference list\n",
    "            diff_list = []\n",
    "            for m in range(0, len(disc[i])):\n",
    "                diff = disc[i][m] - disc[j][m]\n",
    "                diff_list.append(diff)\n",
    "                              \n",
    "            if all(item == 0 for item in diff_list) == False: # if the diff list does not contain all 0\n",
    "                test_stat.append(stats.wilcoxon(diff_list).statistic)\n",
    "                p_value.append(stats.wilcoxon(diff_list).pvalue)\n",
    "            else: # if the diff list contain only0, cannot do Wilcoxon test\n",
    "                error = 'N/A'\n",
    "                test_stat.append(error)\n",
    "                p_value.append(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "edaa296d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 3 lists to dataframe\n",
    "disc_compare = pd.DataFrame(disc_compare, columns=['disc_compare'])\n",
    "test_stat = pd.DataFrame(test_stat, columns=['wtest_stat'])\n",
    "p_value = pd.DataFrame(p_value, columns=['p_value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "401dfa3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result table\n",
    "wt_result = pd.concat([disc_compare, test_stat, p_value], axis = 1)\n",
    "# Drop duplicate\n",
    "wt_result.drop_duplicates(subset=['p_value'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0edd8d64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disc_compare</th>\n",
       "      <th>wtest_stat</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ewd vs efd</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.418021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ewd vs ffd</td>\n",
       "      <td>178.5</td>\n",
       "      <td>0.398865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ewd vs cm</td>\n",
       "      <td>170.0</td>\n",
       "      <td>0.198444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ewd vs dt</td>\n",
       "      <td>147.5</td>\n",
       "      <td>0.080323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>efd vs ffd</td>\n",
       "      <td>224.0</td>\n",
       "      <td>0.861158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>efd vs cm</td>\n",
       "      <td>223.5</td>\n",
       "      <td>0.853066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>efd vs dt</td>\n",
       "      <td>174.5</td>\n",
       "      <td>0.352265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ffd vs cm</td>\n",
       "      <td>170.0</td>\n",
       "      <td>0.646463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ffd vs dt</td>\n",
       "      <td>92.5</td>\n",
       "      <td>0.034918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>cm vs dt</td>\n",
       "      <td>183.5</td>\n",
       "      <td>0.313220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   disc_compare  wtest_stat   p_value\n",
       "0    ewd vs efd        75.0  0.418021\n",
       "1    ewd vs ffd       178.5  0.398865\n",
       "2     ewd vs cm       170.0  0.198444\n",
       "3     ewd vs dt       147.5  0.080323\n",
       "5    efd vs ffd       224.0  0.861158\n",
       "6     efd vs cm       223.5  0.853066\n",
       "7     efd vs dt       174.5  0.352265\n",
       "10    ffd vs cm       170.0  0.646463\n",
       "11    ffd vs dt        92.5  0.034918\n",
       "15     cm vs dt       183.5  0.313220"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wt_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "da7dfe5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting result\n",
    "\n",
    "model = 'ID3'\n",
    "metric = 'accuracy'\n",
    "test = 'two_sided'\n",
    "\n",
    "filename = f\"wilcoxon_{metric}_{model}-{test}.csv\"\n",
    "wt_result['model'] = model\n",
    "wt_result['metric'] = metric\n",
    "\n",
    "wt_result.to_csv(filename, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0751228c",
   "metadata": {},
   "source": [
    "## 1.4 Accuracy, only KNN-VDM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f924ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "9\n",
      "12\n",
      "8\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "# Preparation: Prepare list of metrics for each discretization (test_list)\n",
    "# Step 1: Obtain accuracy for each discretization, convert into numeric, string values will be return as NaN\n",
    "# Filter for Knn-VDM\n",
    "# Obtain accuracy for each discretization, convert into numeric, string values will be return as NaN\n",
    "ewd_acc_knn_vdm = pd.to_numeric(data[(data['disc']==\"EWD\") & (data['models']==\"Knn-VDM\")]['accuracy'],errors='coerce').tolist()\n",
    "efd_acc_knn_vdm = pd.to_numeric(data[(data['disc']==\"EFD\") & (data['models']==\"Knn-VDM\")]['accuracy'],errors='coerce').tolist()\n",
    "ffd_acc_knn_vdm = pd.to_numeric(data[(data['disc']==\"FFD\") & (data['models']==\"Knn-VDM\")]['accuracy'],errors='coerce').tolist()\n",
    "cm_acc_knn_vdm = pd.to_numeric(data[((data['disc']==\"ChiMerge\") | (data['disc'] == \"ChiMerge-SB\")) & (data['models']==\"Knn-VDM\")]['accuracy'],errors='coerce').tolist()\n",
    "dt_acc_knn_vdm = pd.to_numeric(data[(data['disc']==\"ChiMerge\") & (data['models']==\"Knn-VDM\")]['accuracy'],errors='coerce').tolist()\n",
    "\n",
    "# Check number of metrics available for each discretizer\n",
    "print(len(ewd_acc_knn_vdm))\n",
    "print(len(efd_acc_knn_vdm))\n",
    "print(len(ffd_acc_knn_vdm))\n",
    "print(len(cm_acc_knn_vdm))\n",
    "print(len(dt_acc_knn_vdm))\n",
    "\n",
    "# Step 2: filter numeric values\n",
    "raw_list = [ewd_acc_knn_vdm,efd_acc_knn_vdm, ffd_acc_knn_vdm, cm_acc_knn_vdm, dt_acc_knn_vdm]\n",
    "num_list = [] # filter numeric values only\n",
    "for metric in raw_list:\n",
    "    metric_new = [x for x in metric if (math.isnan(x) == False)] # using list comprehension\n",
    "    num_list.append(metric_new)\n",
    "    \n",
    "# Step 3: random sample\n",
    "# For discretization methods with different value, randomly select so that the final sample size are equal\n",
    "# Reference: https://docs.python.org/3/library/random.html\n",
    "k = min(len(metric) for metric in num_list)\n",
    "test_list = []\n",
    "for metric in num_list:\n",
    "    random.seed(20)\n",
    "    if len(metric) > k:\n",
    "        metric = random.sample(metric, k=k)\n",
    "    else: metric = metric\n",
    "    #print(metric)\n",
    "    test_list.append(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dbd8b869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.87, 0.97, 0.95, 0.79, 0.77, 0.68], [0.92, 0.95, 0.95, 0.77, 0.77, 0.77, 0.68, 0.7, 0.71], [0.97, 0.95, 0.84, 0.84, 0.77, 0.8, 0.79, 0.81, 0.71, 0.71, 0.69, 0.68], [0.95, 0.95, 0.8, 0.77, 0.79], [0.95, 0.95, 0.8, 0.77, 0.79]]\n"
     ]
    }
   ],
   "source": [
    "print(num_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0bd52114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c35b52f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.68, 0.97, 0.95, 0.79, 0.87], [0.95, 0.77, 0.77, 0.68, 0.92], [0.68, 0.69, 0.84, 0.77, 0.95], [0.95, 0.95, 0.8, 0.77, 0.79], [0.95, 0.95, 0.8, 0.77, 0.79]]\n"
     ]
    }
   ],
   "source": [
    "print(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "03a78dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(len(test_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8c005139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialiation\n",
    "disc_key = ['ewd', 'efd', 'ffd', 'cm', 'dt']\n",
    "disc_value = test_list # list of metrics for each discretization after preparation\n",
    "test_stat = []\n",
    "p_value = []\n",
    "disc_compare = []\n",
    "# Create dictionary store discretization and series of accuracy\n",
    "disc = {}\n",
    "for key in disc_key:\n",
    "    for value in disc_value:\n",
    "        disc[key] = value\n",
    "        disc_value.remove(value)\n",
    "        break  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "889fa084",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anhtth/opt/anaconda3/lib/python3.9/site-packages/scipy/stats/morestats.py:3141: UserWarning: Exact p-value calculation does not work if there are ties. Switching to normal approximation.\n",
      "  warnings.warn(\"Exact p-value calculation does not work if there are \"\n",
      "/Users/anhtth/opt/anaconda3/lib/python3.9/site-packages/scipy/stats/morestats.py:3155: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    }
   ],
   "source": [
    "# Create loop for Wilcoxon test (two sided)\n",
    "for i in disc_key:\n",
    "    for j in disc_key:\n",
    "        if i != j:\n",
    "            disc_compare.append(f'{i} vs {j}')\n",
    "            # print(f'{i} vs {j}')\n",
    "            # Compute difference list\n",
    "            diff_list = []\n",
    "            for m in range(0, len(disc[i])):\n",
    "                diff = disc[i][m] - disc[j][m]\n",
    "                diff_list.append(diff)\n",
    "                                \n",
    "            if all(item == 0 for item in diff_list) == False: # if the diff list does not contain all 0\n",
    "                test_stat.append(stats.wilcoxon(diff_list).statistic)\n",
    "                p_value.append(stats.wilcoxon(diff_list).pvalue)\n",
    "            else: # if the diff list contain only0, cannot do Wilcoxon test\n",
    "                error = 'N/A'\n",
    "                test_stat.append(error)\n",
    "                p_value.append(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a31e4d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 3 lists to dataframe\n",
    "disc_compare = pd.DataFrame(disc_compare, columns=['disc_compare'])\n",
    "test_stat = pd.DataFrame(test_stat, columns=['wtest_stat'])\n",
    "p_value = pd.DataFrame(p_value, columns=['p_value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3e8b0807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result table\n",
    "wt_result = pd.concat([disc_compare, test_stat, p_value], axis = 1)\n",
    "# Drop duplicate\n",
    "wt_result.drop_duplicates(subset=['p_value'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c2e41873",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disc_compare</th>\n",
       "      <th>wtest_stat</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ewd vs efd</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.8125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ewd vs ffd</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.273322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ewd vs cm</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>efd vs ffd</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>efd vs cm</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.465209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>cm vs dt</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   disc_compare wtest_stat   p_value\n",
       "0    ewd vs efd        6.0    0.8125\n",
       "1    ewd vs ffd        2.0  0.273322\n",
       "2     ewd vs cm        5.0     0.625\n",
       "5    efd vs ffd        7.0       1.0\n",
       "6     efd vs cm        3.0  0.465209\n",
       "15     cm vs dt        N/A       N/A"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wt_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "16d2dcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting result\n",
    "\n",
    "model = 'KNN-VDM'\n",
    "metric = 'accuracy'\n",
    "test = 'two_sided'\n",
    "\n",
    "filename = f\"wilcoxon_{metric}_{model}-{test}.csv\"\n",
    "wt_result['model'] = model\n",
    "wt_result['metric'] = metric\n",
    "\n",
    "wt_result.to_csv(filename, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dba50ff",
   "metadata": {},
   "source": [
    "## 1.5 Accuracy, only KNN-Hamming\n",
    "\n",
    "Knn-Hamming is applied for 5 datasets during Capita Selecta phases (post BNAIC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "873c048c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "21\n",
      "28\n",
      "32\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "# Preparation: Prepare list of metrics for each discretization (test_list)\n",
    "# Step 1: Obtain accuracy for each discretization, convert into numeric, string values will be return as NaN\n",
    "# Filter for Knn-VDM\n",
    "# Obtain accuracy for each discretization, convert into numeric, string values will be return as NaN\n",
    "ewd_acc_knn_hamming = pd.to_numeric(data[(data['disc']==\"EWD\") & (data['models']==\"Knn-Hamming\")]['accuracy'],errors='coerce').tolist()\n",
    "efd_acc_knn_hamming = pd.to_numeric(data[(data['disc']==\"EFD\") & (data['models']==\"Knn-Hamming\")]['accuracy'],errors='coerce').tolist()\n",
    "ffd_acc_knn_hamming = pd.to_numeric(data[(data['disc']==\"FFD\") & (data['models']==\"Knn-Hamming\")]['accuracy'],errors='coerce').tolist()\n",
    "cm_acc_knn_hamming = pd.to_numeric(data[((data['disc']==\"ChiMerge\") | (data['disc'] == \"ChiMerge-SB\")) & (data['models']==\"Knn-Hamming\")]['accuracy'],errors='coerce').tolist()\n",
    "dt_acc_knn_hamming = pd.to_numeric(data[(data['disc']==\"ChiMerge\") & (data['models']==\"Knn-Hamming\")]['accuracy'],errors='coerce').tolist()\n",
    "\n",
    "# Check number of metrics available for each discretizer\n",
    "print(len(ewd_acc_knn_hamming))\n",
    "print(len(efd_acc_knn_hamming))\n",
    "print(len(ffd_acc_knn_hamming))\n",
    "print(len(cm_acc_knn_hamming))\n",
    "print(len(dt_acc_knn_hamming))\n",
    "\n",
    "# Step 2: filter numeric values\n",
    "raw_list = [ewd_acc_knn_hamming,efd_acc_knn_hamming, ffd_acc_knn_hamming, cm_acc_knn_hamming, dt_acc_knn_hamming]\n",
    "num_list = [] # filter numeric values only\n",
    "for metric in raw_list:\n",
    "    metric_new = [x for x in metric if (math.isnan(x) == False)] # using list comprehension\n",
    "    num_list.append(metric_new)\n",
    "    \n",
    "# Step 3: random sample\n",
    "# For discretization methods with different value, randomly select so that the final sample size are equal\n",
    "# Reference: https://docs.python.org/3/library/random.html\n",
    "k = min(len(metric) for metric in num_list)\n",
    "test_list = []\n",
    "for metric in num_list:\n",
    "    random.seed(20)\n",
    "    if len(metric) > k:\n",
    "        metric = random.sample(metric, k=k)\n",
    "    else: metric = metric\n",
    "    #print(metric)\n",
    "    test_list.append(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fffc7969",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anhtth/opt/anaconda3/lib/python3.9/site-packages/scipy/stats/morestats.py:3141: UserWarning: Exact p-value calculation does not work if there are ties. Switching to normal approximation.\n",
      "  warnings.warn(\"Exact p-value calculation does not work if there are \"\n",
      "/Users/anhtth/opt/anaconda3/lib/python3.9/site-packages/scipy/stats/morestats.py:3155: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    }
   ],
   "source": [
    "# Initialiation\n",
    "disc_key = ['ewd', 'efd', 'ffd', 'cm', 'dt']\n",
    "disc_value = test_list # list of metrics for each discretization after preparation\n",
    "test_stat = []\n",
    "p_value = []\n",
    "disc_compare = []\n",
    "# Create dictionary store discretization and series of accuracy\n",
    "disc = {}\n",
    "for key in disc_key:\n",
    "    for value in disc_value:\n",
    "        disc[key] = value\n",
    "        disc_value.remove(value)\n",
    "        break \n",
    "        \n",
    "# Create loop for Wilcoxon test (two sided)\n",
    "for i in disc_key:\n",
    "    for j in disc_key:\n",
    "        if i != j:\n",
    "            disc_compare.append(f'{i} vs {j}')\n",
    "            # print(f'{i} vs {j}')\n",
    "            # Compute difference list\n",
    "            diff_list = []\n",
    "            for m in range(0, len(disc[i])):\n",
    "                diff = disc[i][m] - disc[j][m]\n",
    "                diff_list.append(diff)\n",
    "            if all(item == 0 for item in diff_list) == False: # if the diff list does not contain all 0\n",
    "                test_stat.append(stats.wilcoxon(diff_list).statistic)\n",
    "                p_value.append(stats.wilcoxon(diff_list).pvalue)\n",
    "            else: # if the diff list contain only0, cannot do Wilcoxon test\n",
    "                error = 'N/A'\n",
    "                test_stat.append(error)\n",
    "                p_value.append(error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e7334085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 3 lists to dataframe\n",
    "disc_compare = pd.DataFrame(disc_compare, columns=['disc_compare'])\n",
    "test_stat = pd.DataFrame(test_stat, columns=['wtest_stat'])\n",
    "p_value = pd.DataFrame(p_value, columns=['p_value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cca9c056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result table\n",
    "wt_result = pd.concat([disc_compare, test_stat, p_value], axis = 1)\n",
    "# Drop duplicate\n",
    "wt_result.drop_duplicates(subset=['p_value'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e146a27d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disc_compare</th>\n",
       "      <th>wtest_stat</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ewd vs efd</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.027786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ewd vs ffd</td>\n",
       "      <td>28.5</td>\n",
       "      <td>0.469727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ewd vs cm</td>\n",
       "      <td>33.5</td>\n",
       "      <td>0.677246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ewd vs dt</td>\n",
       "      <td>38.5</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>efd vs ffd</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.339355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>efd vs cm</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.733398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>efd vs dt</td>\n",
       "      <td>37.5</td>\n",
       "      <td>0.969727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ffd vs ewd</td>\n",
       "      <td>28.5</td>\n",
       "      <td>0.423828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ffd vs cm</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.266113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ffd vs dt</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.182098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>dt vs efd</td>\n",
       "      <td>37.5</td>\n",
       "      <td>0.909668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   disc_compare  wtest_stat   p_value\n",
       "0    ewd vs efd         2.5  0.027786\n",
       "1    ewd vs ffd        28.5  0.469727\n",
       "2     ewd vs cm        33.5  0.677246\n",
       "3     ewd vs dt        38.5  1.000000\n",
       "5    efd vs ffd        26.0  0.339355\n",
       "6     efd vs cm        34.0  0.733398\n",
       "7     efd vs dt        37.5  0.969727\n",
       "8    ffd vs ewd        28.5  0.423828\n",
       "10    ffd vs cm        24.0  0.266113\n",
       "11    ffd vs dt        18.0  0.182098\n",
       "17    dt vs efd        37.5  0.909668"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wt_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "310a64e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting result\n",
    "\n",
    "model = 'KNN-Hamming'\n",
    "metric = 'accuracy'\n",
    "test = 'two_sided'\n",
    "\n",
    "filename = f\"wilcoxon_{metric}_{model}-{test}.csv\"\n",
    "wt_result['model'] = model\n",
    "wt_result['metric'] = metric\n",
    "\n",
    "wt_result.to_csv(filename, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa320a5",
   "metadata": {},
   "source": [
    "## 1.6 Accuracy, KNN (Knn-VDM and Knn-Hamming)\n",
    "\n",
    "Merge both result from Knn-VDM and KNN-Hamming\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b52f711a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "30\n",
      "40\n",
      "40\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "# Preparation: Prepare list of metrics for each discretization (test_list)\n",
    "# Step 1: Obtain accuracy for each discretization, convert into numeric, string values will be return as NaN\n",
    "# Filter for Knn-VDM\n",
    "# Obtain accuracy for each discretization, convert into numeric, string values will be return as NaN\n",
    "ewd_acc_knn = pd.to_numeric(data[(data['disc']==\"EWD\") & ((data['models']==\"Knn-Hamming\") | (data['models']==\"Knn-VDM\"))]['accuracy'],errors='coerce').tolist()\n",
    "efd_acc_knn = pd.to_numeric(data[(data['disc']==\"EFD\") & ((data['models']==\"Knn-Hamming\") | (data['models']==\"Knn-VDM\"))]['accuracy'],errors='coerce').tolist()\n",
    "ffd_acc_knn = pd.to_numeric(data[(data['disc']==\"FFD\") & ((data['models']==\"Knn-Hamming\") | (data['models']==\"Knn-VDM\"))]['accuracy'],errors='coerce').tolist()\n",
    "cm_acc_knn = pd.to_numeric(data[((data['disc']==\"ChiMerge\") | (data['disc'] == \"ChiMerge-SB\")) & ((data['models']==\"Knn-Hamming\") | (data['models']==\"Knn-VDM\"))]['accuracy'],errors='coerce').tolist()\n",
    "dt_acc_knn = pd.to_numeric(data[(data['disc']==\"ChiMerge\") & ((data['models']==\"Knn-Hamming\") | (data['models']==\"Knn-VDM\"))]['accuracy'],errors='coerce').tolist()\n",
    "\n",
    "# Check number of metrics available for each discretizer\n",
    "print(len(ewd_acc_knn))\n",
    "print(len(efd_acc_knn))\n",
    "print(len(ffd_acc_knn))\n",
    "print(len(cm_acc_knn))\n",
    "print(len(dt_acc_knn))\n",
    "\n",
    "# Step 2: filter numeric values\n",
    "raw_list = [ewd_acc_knn,efd_acc_knn, ffd_acc_knn, cm_acc_knn, dt_acc_knn]\n",
    "num_list = [] # filter numeric values only\n",
    "for metric in raw_list:\n",
    "    metric_new = [x for x in metric if (math.isnan(x) == False)] # using list comprehension\n",
    "    num_list.append(metric_new)\n",
    "    \n",
    "# Step 3: random sample\n",
    "# For discretization methods with different value, randomly select so that the final sample size are equal\n",
    "# Reference: https://docs.python.org/3/library/random.html\n",
    "k = min(len(metric) for metric in num_list)\n",
    "test_list = []\n",
    "for metric in num_list:\n",
    "    random.seed(20)\n",
    "    if len(metric) > k:\n",
    "        metric = random.sample(metric, k=k)\n",
    "    else: metric = metric\n",
    "    #print(metric)\n",
    "    test_list.append(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e417064c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anhtth/opt/anaconda3/lib/python3.9/site-packages/scipy/stats/morestats.py:3141: UserWarning: Exact p-value calculation does not work if there are ties. Switching to normal approximation.\n",
      "  warnings.warn(\"Exact p-value calculation does not work if there are \"\n"
     ]
    }
   ],
   "source": [
    "# Initialiation\n",
    "disc_key = ['ewd', 'efd', 'ffd', 'cm', 'dt']\n",
    "disc_value = test_list # list of metrics for each discretization after preparation\n",
    "test_stat = []\n",
    "p_value = []\n",
    "disc_compare = []\n",
    "# Create dictionary store discretization and series of accuracy\n",
    "disc = {}\n",
    "for key in disc_key:\n",
    "    for value in disc_value:\n",
    "        disc[key] = value\n",
    "        disc_value.remove(value)\n",
    "        break \n",
    "        \n",
    "# Create loop for Wilcoxon test (two sided)\n",
    "for i in disc_key:\n",
    "    for j in disc_key:\n",
    "        if i != j:\n",
    "            disc_compare.append(f'{i} vs {j}')\n",
    "            # print(f'{i} vs {j}')\n",
    "            # Compute difference list\n",
    "            diff_list = []\n",
    "            for m in range(0, len(disc[i])):\n",
    "                diff = disc[i][m] - disc[j][m]\n",
    "                diff_list.append(diff)\n",
    "            if all(item == 0 for item in diff_list) == False: # if the diff list does not contain all 0\n",
    "                test_stat.append(stats.wilcoxon(diff_list).statistic)\n",
    "                p_value.append(stats.wilcoxon(diff_list).pvalue)\n",
    "            else: # if the diff list contain only0, cannot do Wilcoxon test\n",
    "                error = 'N/A'\n",
    "                test_stat.append(error)\n",
    "                p_value.append(error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3e9618bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 3 lists to dataframe\n",
    "disc_compare = pd.DataFrame(disc_compare, columns=['disc_compare'])\n",
    "test_stat = pd.DataFrame(test_stat, columns=['wtest_stat'])\n",
    "p_value = pd.DataFrame(p_value, columns=['p_value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "72a1bfc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disc_compare</th>\n",
       "      <th>wtest_stat</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ewd vs efd</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.468667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ewd vs ffd</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.206894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ewd vs cm</td>\n",
       "      <td>63.5</td>\n",
       "      <td>0.579056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ewd vs dt</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.917590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>efd vs ffd</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.033971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>efd vs cm</td>\n",
       "      <td>47.5</td>\n",
       "      <td>0.190094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>efd vs dt</td>\n",
       "      <td>51.5</td>\n",
       "      <td>0.629192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ffd vs cm</td>\n",
       "      <td>45.5</td>\n",
       "      <td>0.242908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ffd vs dt</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.120528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>cm vs ewd</td>\n",
       "      <td>63.5</td>\n",
       "      <td>0.547668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>cm vs efd</td>\n",
       "      <td>47.5</td>\n",
       "      <td>0.174255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>cm vs dt</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.325384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   disc_compare  wtest_stat   p_value\n",
       "0    ewd vs efd        54.0  0.468667\n",
       "1    ewd vs ffd        49.0  0.206894\n",
       "2     ewd vs cm        63.5  0.579056\n",
       "3     ewd vs dt        66.0  0.917590\n",
       "5    efd vs ffd        27.0  0.033971\n",
       "6     efd vs cm        47.5  0.190094\n",
       "7     efd vs dt        51.5  0.629192\n",
       "10    ffd vs cm        45.5  0.242908\n",
       "11    ffd vs dt        38.0  0.120528\n",
       "12    cm vs ewd        63.5  0.547668\n",
       "13    cm vs efd        47.5  0.174255\n",
       "15     cm vs dt        49.0  0.325384"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Result table\n",
    "wt_result = pd.concat([disc_compare, test_stat, p_value], axis = 1)\n",
    "# Drop duplicate\n",
    "wt_result.drop_duplicates(subset=['p_value'], inplace=True)\n",
    "wt_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fbdc16df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting result\n",
    "\n",
    "model = 'KNN'\n",
    "metric = 'accuracy'\n",
    "test = 'two_sided'\n",
    "\n",
    "filename = f\"wilcoxon_{metric}_{model}-{test}.csv\"\n",
    "wt_result['model'] = model\n",
    "wt_result['metric'] = metric\n",
    "\n",
    "wt_result.to_csv(filename, index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
