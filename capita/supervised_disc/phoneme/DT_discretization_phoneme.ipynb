{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f157f86a",
   "metadata": {},
   "source": [
    "# Discretization of pre-processed data using Decision Tree discretization\n",
    "## Dataset: phoneme\n",
    "\n",
    "By: Sam\n",
    "Update: 23/02/2023\n",
    "Replicate using Malina script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398df39e",
   "metadata": {},
   "source": [
    "### About Dataset\n",
    "\n",
    "Raw dataset is in format arff, must convert to csv (using tool: https://pulipulichen.github.io/jieba-js/weka/arff2csv/)\n",
    "\n",
    "Five different attributes were chosen to characterize each vowel: they are the amplitudes of the five first harmonics AHi, normalised by the total energy Ene (integrated on all the frequencies): AHi/Ene. The phonemes are transcribed as follows: sh as in she, dcl as in dark, iy as the vowel in she, aa as the vowel in dark, and ao as the first vowel in water.\n",
    "=> All attributes are numeric.\n",
    "\n",
    "The aim of the present database is to distinguish between nasal and oral vowels. There are thus two different classes:\n",
    "- Class 0 : Nasals\n",
    "- Class 1 : Orals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac57553",
   "metadata": {},
   "source": [
    "# 1. Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "071e0340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter #for Chi Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3120ee79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read clean dataset for discretization\n",
    "data0 = pd.read_csv('clean_phoneme.csv')\n",
    "#phoneme dataset\n",
    "phoneme = data0\n",
    "phoneme.drop(['id'], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "166cab73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.489927</td>\n",
       "      <td>-0.451528</td>\n",
       "      <td>-1.047990</td>\n",
       "      <td>-0.598693</td>\n",
       "      <td>-0.020418</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.641265</td>\n",
       "      <td>0.109245</td>\n",
       "      <td>0.292130</td>\n",
       "      <td>-0.916804</td>\n",
       "      <td>0.240223</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.870593</td>\n",
       "      <td>-0.459862</td>\n",
       "      <td>0.578159</td>\n",
       "      <td>0.806634</td>\n",
       "      <td>0.835248</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.628439</td>\n",
       "      <td>-0.316284</td>\n",
       "      <td>1.934295</td>\n",
       "      <td>-1.427099</td>\n",
       "      <td>-0.136583</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.596399</td>\n",
       "      <td>0.015938</td>\n",
       "      <td>2.043206</td>\n",
       "      <td>-1.688448</td>\n",
       "      <td>-0.948127</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5399</th>\n",
       "      <td>-0.658318</td>\n",
       "      <td>1.331760</td>\n",
       "      <td>-0.081621</td>\n",
       "      <td>1.794253</td>\n",
       "      <td>-1.082181</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5400</th>\n",
       "      <td>-0.044375</td>\n",
       "      <td>-0.010512</td>\n",
       "      <td>0.030989</td>\n",
       "      <td>-0.019379</td>\n",
       "      <td>1.281061</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5401</th>\n",
       "      <td>0.246882</td>\n",
       "      <td>-0.793228</td>\n",
       "      <td>1.190101</td>\n",
       "      <td>1.423194</td>\n",
       "      <td>-1.303036</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5402</th>\n",
       "      <td>-0.778907</td>\n",
       "      <td>-0.383111</td>\n",
       "      <td>1.727029</td>\n",
       "      <td>-1.432389</td>\n",
       "      <td>-1.208085</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5403</th>\n",
       "      <td>-0.794604</td>\n",
       "      <td>-0.640053</td>\n",
       "      <td>0.632221</td>\n",
       "      <td>0.720280</td>\n",
       "      <td>-1.231182</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5404 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            V1        V2        V3        V4        V5  Class\n",
       "0     0.489927 -0.451528 -1.047990 -0.598693 -0.020418      1\n",
       "1    -0.641265  0.109245  0.292130 -0.916804  0.240223      1\n",
       "2     0.870593 -0.459862  0.578159  0.806634  0.835248      1\n",
       "3    -0.628439 -0.316284  1.934295 -1.427099 -0.136583      1\n",
       "4    -0.596399  0.015938  2.043206 -1.688448 -0.948127      1\n",
       "...        ...       ...       ...       ...       ...    ...\n",
       "5399 -0.658318  1.331760 -0.081621  1.794253 -1.082181      1\n",
       "5400 -0.044375 -0.010512  0.030989 -0.019379  1.281061      2\n",
       "5401  0.246882 -0.793228  1.190101  1.423194 -1.303036      2\n",
       "5402 -0.778907 -0.383111  1.727029 -1.432389 -1.208085      1\n",
       "5403 -0.794604 -0.640053  0.632221  0.720280 -1.231182      2\n",
       "\n",
       "[5404 rows x 6 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phoneme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e3ab739e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import label encoder\n",
    "from sklearn import preprocessing\n",
    "\n",
    "phoneme.rename(columns={'Class':'class'}, inplace=True)\n",
    "  \n",
    "# label_encoder object knows how to understand word labels.\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "  \n",
    "# Encode labels in column 'species'.\n",
    "phoneme['class']= label_encoder.fit_transform(phoneme['class'])\n",
    "  \n",
    "phoneme['class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4433a200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of continuous feature to discretize\n",
    "num_list = phoneme.columns.to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0846d5e0-dd24-4eb5-b532-22b9978ded56",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_list.remove('class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "36c9bb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_list = pd.DataFrame(phoneme['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "29861962-5863-4830-b83c-d41e98a99587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['V1', 'V2', 'V3', 'V4', 'V5']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1602000e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5399</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5400</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5401</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5402</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5403</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5404 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      class\n",
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0\n",
       "...     ...\n",
       "5399      0\n",
       "5400      1\n",
       "5401      1\n",
       "5402      0\n",
       "5403      1\n",
       "\n",
       "[5404 rows x 1 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_list\n",
    "y_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ef8524",
   "metadata": {},
   "source": [
    "# 3. Decision Tree discretization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c38279-b3df-4fcb-9343-c36bb36c6232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install feature_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "51fd490d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from feature_engine.discretisation import DecisionTreeDiscretiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0eb9d809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.489927</td>\n",
       "      <td>-0.451528</td>\n",
       "      <td>-1.047990</td>\n",
       "      <td>-0.598693</td>\n",
       "      <td>-0.020418</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.641265</td>\n",
       "      <td>0.109245</td>\n",
       "      <td>0.292130</td>\n",
       "      <td>-0.916804</td>\n",
       "      <td>0.240223</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.870593</td>\n",
       "      <td>-0.459862</td>\n",
       "      <td>0.578159</td>\n",
       "      <td>0.806634</td>\n",
       "      <td>0.835248</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.628439</td>\n",
       "      <td>-0.316284</td>\n",
       "      <td>1.934295</td>\n",
       "      <td>-1.427099</td>\n",
       "      <td>-0.136583</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.596399</td>\n",
       "      <td>0.015938</td>\n",
       "      <td>2.043206</td>\n",
       "      <td>-1.688448</td>\n",
       "      <td>-0.948127</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5399</th>\n",
       "      <td>-0.658318</td>\n",
       "      <td>1.331760</td>\n",
       "      <td>-0.081621</td>\n",
       "      <td>1.794253</td>\n",
       "      <td>-1.082181</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5400</th>\n",
       "      <td>-0.044375</td>\n",
       "      <td>-0.010512</td>\n",
       "      <td>0.030989</td>\n",
       "      <td>-0.019379</td>\n",
       "      <td>1.281061</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5401</th>\n",
       "      <td>0.246882</td>\n",
       "      <td>-0.793228</td>\n",
       "      <td>1.190101</td>\n",
       "      <td>1.423194</td>\n",
       "      <td>-1.303036</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5402</th>\n",
       "      <td>-0.778907</td>\n",
       "      <td>-0.383111</td>\n",
       "      <td>1.727029</td>\n",
       "      <td>-1.432389</td>\n",
       "      <td>-1.208085</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5403</th>\n",
       "      <td>-0.794604</td>\n",
       "      <td>-0.640053</td>\n",
       "      <td>0.632221</td>\n",
       "      <td>0.720280</td>\n",
       "      <td>-1.231182</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5404 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            V1        V2        V3        V4        V5  class\n",
       "0     0.489927 -0.451528 -1.047990 -0.598693 -0.020418      0\n",
       "1    -0.641265  0.109245  0.292130 -0.916804  0.240223      0\n",
       "2     0.870593 -0.459862  0.578159  0.806634  0.835248      0\n",
       "3    -0.628439 -0.316284  1.934295 -1.427099 -0.136583      0\n",
       "4    -0.596399  0.015938  2.043206 -1.688448 -0.948127      0\n",
       "...        ...       ...       ...       ...       ...    ...\n",
       "5399 -0.658318  1.331760 -0.081621  1.794253 -1.082181      0\n",
       "5400 -0.044375 -0.010512  0.030989 -0.019379  1.281061      1\n",
       "5401  0.246882 -0.793228  1.190101  1.423194 -1.303036      1\n",
       "5402 -0.778907 -0.383111  1.727029 -1.432389 -1.208085      0\n",
       "5403 -0.794604 -0.640053  0.632221  0.720280 -1.231182      1\n",
       "\n",
       "[5404 rows x 6 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "data = phoneme\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "360539f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate into train and test sets\n",
    "X_train, X_test, y_train, y_test =  train_test_split(\n",
    "            data,\n",
    "            data['class'], test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e2a7a2",
   "metadata": {},
   "source": [
    "# DT scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9cf709cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train : (3782, 6)\n",
      "X_test : (1622, 6)\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "data = phoneme\n",
    "# let's separate into training and testing set\n",
    "# Separate into train and test sets\n",
    "X_train, X_test, y_train, y_test =  train_test_split(\n",
    "            data,\n",
    "            data['class'], test_size=0.3, random_state=0)\n",
    "\n",
    "print(\"X_train :\", X_train.shape)\n",
    "print(\"X_test :\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52472bc7",
   "metadata": {},
   "source": [
    "## 2.1 DT with small max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "023afc4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            V1        V2        V3        V4        V5  class\n",
      "3974  0.343898  0.117700  0.061708  0.047408  0.181390      0\n",
      "2580  0.343898  0.117700  0.468303  0.297604  0.181390      0\n",
      "2027  0.343898  0.462159  0.174142  0.047408  0.181390      0\n",
      "4752  0.011869  0.462159  0.061708  0.047408  0.181390      0\n",
      "4160  0.343898  0.117700  0.468303  0.047408  0.181390      0\n",
      "...        ...       ...       ...       ...       ...    ...\n",
      "4770  0.011869  0.462159  0.061708  0.047408  0.181390      0\n",
      "803   0.428233  0.462159  0.468303  0.600168  0.593137      0\n",
      "4563  0.011869  0.462159  0.061708  0.047408  0.181390      0\n",
      "536   0.011869  0.233533  0.174142  0.047408  0.181390      0\n",
      "3349  0.428233  0.221080  0.468303  0.600168  0.665370      1\n",
      "\n",
      "[5404 rows x 6 columns]\n",
      "DT discreizer binner dict:\n",
      "{'V1': GridSearchCV(cv=3, estimator=DecisionTreeClassifier(random_state=29),\n",
      "             param_grid={'max_depth': [2]}, scoring='accuracy'), 'V2': GridSearchCV(cv=3, estimator=DecisionTreeClassifier(random_state=29),\n",
      "             param_grid={'max_depth': [2]}, scoring='accuracy'), 'V3': GridSearchCV(cv=3, estimator=DecisionTreeClassifier(random_state=29),\n",
      "             param_grid={'max_depth': [2]}, scoring='accuracy'), 'V4': GridSearchCV(cv=3, estimator=DecisionTreeClassifier(random_state=29),\n",
      "             param_grid={'max_depth': [2]}, scoring='accuracy'), 'V5': GridSearchCV(cv=3, estimator=DecisionTreeClassifier(random_state=29),\n",
      "             param_grid={'max_depth': [2]}, scoring='accuracy')}\n",
      " \n",
      "Computation time: \n",
      "0.1791543960571289\n"
     ]
    }
   ],
   "source": [
    "#make DT discreizer\n",
    "# 'max_depth': [2] => 2^2 = 4 intervals max. \n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "treeDisc = DecisionTreeDiscretiser(cv=3,\n",
    "                                   scoring='accuracy',\n",
    "                                   variables=num_list,\n",
    "                                   regression=False,\n",
    "                                   param_grid={'max_depth': [2]},\n",
    "                                   random_state=29,\n",
    "                                   )\n",
    "\n",
    "treeDisc.fit(X_train, y_train)\n",
    "\n",
    "# transform the data\n",
    "train_t= treeDisc.transform(X_train)\n",
    "test_t= treeDisc.transform(X_test)\n",
    "\n",
    "#add on to categorical dataset again\n",
    "disc = pd.concat([train_t, test_t], axis=0)\n",
    "print(disc)\n",
    "#categorical = categorical.drop('label', axis=1)\n",
    "\n",
    "print('DT discreizer binner dict:')\n",
    "print(treeDisc.binner_dict_)\n",
    "print(' ')\n",
    "print('Computation time: ')\n",
    "end = time.time()\n",
    "print(end - start) # Total time execution for this sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "48c650a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of bins: V1\n",
      "4\n",
      "Entries per interval for V1\n",
      "Counter({0.34389782403027436: 3026, 0.42823250296559906: 1193, 0.011869436201780416: 957, 0.1456953642384106: 228})\n",
      " \n",
      "No of bins: V2\n",
      "4\n",
      "Entries per interval for V2\n",
      "Counter({0.4621588089330025: 2283, 0.11769991015274034: 1608, 0.23353293413173654: 958, 0.2210796915167095: 555})\n",
      " \n",
      "No of bins: V3\n",
      "4\n",
      "Entries per interval for V3\n",
      "Counter({0.46830265848670755: 2802, 0.06170752324598478: 1685, 0.1741424802110818: 538, 0.23863636363636365: 379})\n",
      " \n",
      "No of bins: V4\n",
      "4\n",
      "Entries per interval for V4\n",
      "Counter({0.04740834386852086: 2272, 0.6001676445934618: 1701, 0.29760403530895335: 1099, 0.4252336448598131: 332})\n",
      " \n",
      "No of bins: V5\n",
      "4\n",
      "Entries per interval for V5\n",
      "Counter({0.18139029688631428: 3952, 0.5931372549019608: 597, 0.5746478873239437: 505, 0.6653696498054474: 350})\n",
      " \n",
      "No of bins: class\n",
      "2\n",
      "Entries per interval for class\n",
      "Counter({0: 3818, 1: 1586})\n",
      " \n"
     ]
    }
   ],
   "source": [
    "#Show number of bins for each variable\n",
    "#no of bins\n",
    "for i in disc:\n",
    "    print('No of bins: ' + i)\n",
    "    print(disc[i].nunique())\n",
    "    #show start of intervals of each bin\n",
    "    print('Entries per interval for ' + i)\n",
    "    print(Counter(disc[i]))\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d84ab78b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            V1        V2        V3        V4        V5  class\n",
      "3974  0.343898  0.117700  0.061708  0.047408  0.181390      0\n",
      "2580  0.343898  0.117700  0.468303  0.297604  0.181390      0\n",
      "2027  0.343898  0.462159  0.174142  0.047408  0.181390      0\n",
      "4752  0.011869  0.462159  0.061708  0.047408  0.181390      0\n",
      "4160  0.343898  0.117700  0.468303  0.047408  0.181390      0\n",
      "...        ...       ...       ...       ...       ...    ...\n",
      "4770  0.011869  0.462159  0.061708  0.047408  0.181390      0\n",
      "803   0.428233  0.462159  0.468303  0.600168  0.593137      0\n",
      "4563  0.011869  0.462159  0.061708  0.047408  0.181390      0\n",
      "536   0.011869  0.233533  0.174142  0.047408  0.181390      0\n",
      "3349  0.428233  0.221080  0.468303  0.600168  0.665370      1\n",
      "\n",
      "[5404 rows x 6 columns]\n",
      "      V1  V2  V3  V4  V5  class\n",
      "0      2   0   0   0   0      0\n",
      "1      2   0   3   1   0      0\n",
      "2      2   3   1   0   0      0\n",
      "3      0   3   0   0   0      0\n",
      "4      2   0   3   0   0      0\n",
      "...   ..  ..  ..  ..  ..    ...\n",
      "5399   0   3   0   0   0      0\n",
      "5400   3   3   3   3   2      0\n",
      "5401   0   3   0   0   0      0\n",
      "5402   0   2   1   0   0      0\n",
      "5403   3   1   3   3   3      1\n",
      "\n",
      "[5404 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "#ordinal encoding\n",
    "from numpy import asarray\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "# define data\n",
    "data1 = asarray(disc)\n",
    "print(disc)\n",
    "# define ordinal encoding\n",
    "encoder = OrdinalEncoder()\n",
    "# transform data\n",
    "result = pd.DataFrame(encoder.fit_transform(disc))\n",
    "#print(result)\n",
    "disc_ord = pd.DataFrame(result).astype(int)\n",
    "tmp_col = phoneme.columns\n",
    "disc_ord.columns = tmp_col # change column name\n",
    "#print(disc_ord)\n",
    "#disc_ord = pd.concat([categorical, disc_ord], axis=1)\n",
    "print(disc_ord)\n",
    "disc_ord.isna().sum()\n",
    "# Export this dataset for discretization\n",
    "disc_ord.to_csv('DT_small_discretized_phoneme.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b18ff652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5404 entries, 0 to 5403\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   V1      5404 non-null   int64\n",
      " 1   V2      5404 non-null   int64\n",
      " 2   V3      5404 non-null   int64\n",
      " 3   V4      5404 non-null   int64\n",
      " 4   V5      5404 non-null   int64\n",
      " 5   class   5404 non-null   int64\n",
      "dtypes: int64(6)\n",
      "memory usage: 253.4 KB\n"
     ]
    }
   ],
   "source": [
    "disc_ord.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c3279d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2.2 DT with medium max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9a40d313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            V1        V2        V3        V4        V5  class\n",
      "3974  0.354664  0.127789  0.032720  0.019528  0.276423      0\n",
      "2580  0.354664  0.127789  0.524496  0.287858  0.160793      0\n",
      "2027  0.270370  0.300000  0.162602  0.144476  0.160793      0\n",
      "4752  0.000000  0.500768  0.032720  0.019528  0.160793      0\n",
      "4160  0.354664  0.127789  0.437401  0.019528  0.160793      0\n",
      "...        ...       ...       ...       ...       ...    ...\n",
      "4770  0.000000  0.500768  0.032720  0.019528  0.160793      0\n",
      "803   0.393124  0.500768  0.437401  0.500000  0.725888      0\n",
      "4563  0.000000  0.500768  0.032720  0.019528  0.160793      0\n",
      "536   0.036036  0.225806  0.162602  0.019528  0.160793      0\n",
      "3349  0.393124  0.197015  0.437401  0.616585  0.530435      1\n",
      "\n",
      "[5404 rows x 6 columns]\n",
      "DT discreizer binner dict:\n",
      "{'V1': GridSearchCV(cv=3, estimator=DecisionTreeClassifier(random_state=29),\n",
      "             param_grid={'max_depth': [3]}, scoring='accuracy'), 'V2': GridSearchCV(cv=3, estimator=DecisionTreeClassifier(random_state=29),\n",
      "             param_grid={'max_depth': [3]}, scoring='accuracy'), 'V3': GridSearchCV(cv=3, estimator=DecisionTreeClassifier(random_state=29),\n",
      "             param_grid={'max_depth': [3]}, scoring='accuracy'), 'V4': GridSearchCV(cv=3, estimator=DecisionTreeClassifier(random_state=29),\n",
      "             param_grid={'max_depth': [3]}, scoring='accuracy'), 'V5': GridSearchCV(cv=3, estimator=DecisionTreeClassifier(random_state=29),\n",
      "             param_grid={'max_depth': [3]}, scoring='accuracy')}\n",
      " \n",
      "Computation time: \n",
      "0.20368266105651855\n"
     ]
    }
   ],
   "source": [
    "#make DT discreizer\n",
    "# 'max_depth': [3] => 2^3 = 8 intervals max. \n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "treeDisc = DecisionTreeDiscretiser(cv=3,\n",
    "                                   scoring='accuracy',\n",
    "                                   variables=num_list,\n",
    "                                   regression=False,\n",
    "                                   param_grid={'max_depth': [3]},\n",
    "                                   random_state=29,\n",
    "                                   )\n",
    "\n",
    "treeDisc.fit(X_train, y_train)\n",
    "\n",
    "# transform the data\n",
    "train_t= treeDisc.transform(X_train)\n",
    "test_t= treeDisc.transform(X_test)\n",
    "\n",
    "#add on to categorical dataset again\n",
    "disc = pd.concat([train_t, test_t], axis=0)\n",
    "print(disc)\n",
    "#categorical = categorical.drop('label', axis=1)\n",
    "\n",
    "# put side by side the original variable and the transformed variable\n",
    "print('DT discreizer binner dict:')\n",
    "print(treeDisc.binner_dict_)\n",
    "print(' ')\n",
    "print('Computation time: ')\n",
    "end = time.time()\n",
    "print(end - start) # Total time execution for this sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c87b0ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of bins: V1\n",
      "8\n",
      "Entries per interval for V1\n",
      "Counter({0.3546637744034707: 2649, 0.3931240657698057: 959, 0.0: 645, 0.27037037037037037: 377, 0.036036036036036036: 312, 0.5632183908045977: 234, 0.1342281879194631: 226, 1.0: 2})\n",
      " \n",
      "No of bins: V2\n",
      "8\n",
      "Entries per interval for V2\n",
      "Counter({0.500768049155146: 1867, 0.12778904665314403: 1424, 0.22580645161290322: 937, 0.19701492537313434: 485, 0.3: 416, 0.03937007874015748: 184, 0.37037037037037035: 70, 0.5294117647058824: 21})\n",
      " \n",
      "No of bins: V3\n",
      "8\n",
      "Entries per interval for V3\n",
      "Counter({0.43740095087163233: 1775, 0.032719836400818: 1395, 0.5244956772334294: 1027, 0.16260162601626016: 527, 0.25203252032520324: 352, 0.2: 290, 0.05555555555555555: 27, 0.6: 11})\n",
      " \n",
      "No of bins: V4\n",
      "8\n",
      "Entries per interval for V4\n",
      "Counter({0.01952807160292921: 1766, 0.6165853658536585: 1463, 0.2878581173260573: 1026, 0.14447592067988668: 506, 0.41626794258373206: 324, 0.5: 238, 0.4166666666666667: 73, 0.8: 8})\n",
      " \n",
      "No of bins: V5\n",
      "8\n",
      "Entries per interval for V5\n",
      "Counter({0.16079295154185022: 3236, 0.2764227642276423: 716, 0.46919431279620855: 314, 0.7258883248730964: 283, 0.6275510204081632: 275, 0.5094339622641509: 230, 0.7746478873239436: 200, 0.5304347826086957: 150})\n",
      " \n",
      "No of bins: class\n",
      "2\n",
      "Entries per interval for class\n",
      "Counter({0: 3818, 1: 1586})\n",
      " \n"
     ]
    }
   ],
   "source": [
    "#Show number of bins for each variable\n",
    "#no of bins\n",
    "for i in disc:\n",
    "    print('No of bins: ' + i)\n",
    "    print(disc[i].nunique())\n",
    "    #show start of intervals of each bin\n",
    "    print('Entries per interval for ' + i)\n",
    "    print(Counter(disc[i]))\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "195eecf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            V1        V2        V3        V4        V5  class\n",
      "3974  0.354664  0.127789  0.032720  0.019528  0.276423      0\n",
      "2580  0.354664  0.127789  0.524496  0.287858  0.160793      0\n",
      "2027  0.270370  0.300000  0.162602  0.144476  0.160793      0\n",
      "4752  0.000000  0.500768  0.032720  0.019528  0.160793      0\n",
      "4160  0.354664  0.127789  0.437401  0.019528  0.160793      0\n",
      "...        ...       ...       ...       ...       ...    ...\n",
      "4770  0.000000  0.500768  0.032720  0.019528  0.160793      0\n",
      "803   0.393124  0.500768  0.437401  0.500000  0.725888      0\n",
      "4563  0.000000  0.500768  0.032720  0.019528  0.160793      0\n",
      "536   0.036036  0.225806  0.162602  0.019528  0.160793      0\n",
      "3349  0.393124  0.197015  0.437401  0.616585  0.530435      1\n",
      "\n",
      "[5404 rows x 6 columns]\n",
      "      V1  V2  V3  V4  V5  class\n",
      "0      4   1   0   0   1      0\n",
      "1      4   1   6   2   0      0\n",
      "2      3   4   2   1   0      0\n",
      "3      0   6   0   0   0      0\n",
      "4      4   1   5   0   0      0\n",
      "...   ..  ..  ..  ..  ..    ...\n",
      "5399   0   6   0   0   0      0\n",
      "5400   5   6   5   5   6      0\n",
      "5401   0   6   0   0   0      0\n",
      "5402   1   3   2   0   0      0\n",
      "5403   5   2   5   6   4      1\n",
      "\n",
      "[5404 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "#ordinal encoding\n",
    "from numpy import asarray\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "# define data\n",
    "data1 = asarray(disc)\n",
    "print(disc)\n",
    "# define ordinal encoding\n",
    "encoder = OrdinalEncoder()\n",
    "# transform data\n",
    "result = pd.DataFrame(encoder.fit_transform(disc))\n",
    "#print(result)\n",
    "disc_ord = pd.DataFrame(result).astype(int)\n",
    "tmp_col = phoneme.columns\n",
    "disc_ord.columns = tmp_col # change column name\n",
    "#print(disc_ord)\n",
    "#disc_ord = pd.concat([categorical, disc_ord], axis=1)\n",
    "print(disc_ord)\n",
    "disc_ord.isna().sum()\n",
    "# Export this dataset for discretization\n",
    "disc_ord.to_csv('DT_medium_discretized_phoneme.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e35d0f",
   "metadata": {},
   "source": [
    "## 2.3 DT with large max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8ef04631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            V1        V2        V3        V4        V5  class\n",
      "3974  0.306649  0.142317  0.057823  0.012241  0.270492      0\n",
      "2580  0.386631  0.142317  0.571765  0.292546  0.082317      0\n",
      "2027  0.304762  0.295455  0.184466  0.142045  0.220840      0\n",
      "4752  0.000000  0.461679  0.021930  0.012241  0.082317      0\n",
      "4160  0.306649  0.142317  0.453789  0.012241  0.220840      0\n",
      "...        ...       ...       ...       ...       ...    ...\n",
      "4770  0.000000  0.461679  0.021930  0.012241  0.082317      0\n",
      "803   0.406349  0.529178  0.453789  0.458904  0.770642      0\n",
      "4563  0.000000  0.529178  0.021930  0.012241  0.220840      0\n",
      "536   0.031674  0.166667  0.184466  0.012241  0.220840      0\n",
      "3349  0.406349  0.237903  0.453789  0.612426  0.544643      1\n",
      "\n",
      "[5404 rows x 6 columns]\n",
      "DT discreizer binner dict:\n",
      "{'V1': GridSearchCV(cv=3, estimator=DecisionTreeClassifier(random_state=29),\n",
      "             param_grid={'max_depth': [4]}, scoring='accuracy'), 'V2': GridSearchCV(cv=3, estimator=DecisionTreeClassifier(random_state=29),\n",
      "             param_grid={'max_depth': [4]}, scoring='accuracy'), 'V3': GridSearchCV(cv=3, estimator=DecisionTreeClassifier(random_state=29),\n",
      "             param_grid={'max_depth': [4]}, scoring='accuracy'), 'V4': GridSearchCV(cv=3, estimator=DecisionTreeClassifier(random_state=29),\n",
      "             param_grid={'max_depth': [4]}, scoring='accuracy'), 'V5': GridSearchCV(cv=3, estimator=DecisionTreeClassifier(random_state=29),\n",
      "             param_grid={'max_depth': [4]}, scoring='accuracy')}\n",
      " \n",
      "Computation time: \n",
      "0.18979358673095703\n"
     ]
    }
   ],
   "source": [
    "#make DT discreizer\n",
    "# 'max_depth': [4] => 2^4 = 16 intervals max. \n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "treeDisc = DecisionTreeDiscretiser(cv=3,\n",
    "                                   scoring='accuracy',\n",
    "                                   variables=num_list,\n",
    "                                   regression=False,\n",
    "                                   param_grid={'max_depth': [4]},\n",
    "                                   random_state=29,\n",
    "                                   )\n",
    "\n",
    "treeDisc.fit(X_train, y_train)\n",
    "\n",
    "# transform the data\n",
    "train_t= treeDisc.transform(X_train)\n",
    "test_t= treeDisc.transform(X_test)\n",
    "\n",
    "#add on to categorical dataset again\n",
    "disc = pd.concat([train_t, test_t], axis=0)\n",
    "print(disc)\n",
    "#categorical = categorical.drop('label', axis=1)\n",
    "\n",
    "# put side by side the original variable and the transformed variable\n",
    "print('DT discreizer binner dict:')\n",
    "print(treeDisc.binner_dict_)\n",
    "print(' ')\n",
    "print('Computation time: ')\n",
    "end = time.time()\n",
    "print(end - start) # Total time execution for this sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5ed1d5e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of bins: V1\n",
      "13\n",
      "Entries per interval for V1\n",
      "Counter({0.3866305329719964: 1581, 0.3066485753052917: 1068, 0.40634920634920635: 900, 0.0: 645, 0.03167420814479638: 311, 0.3047619047619048: 288, 0.5244755244755245: 192, 0.16666666666666666: 149, 0.15: 89, 0.06382978723404255: 77, 0.1794871794871795: 59, 0.7419354838709677: 42, 1.0: 3})\n",
      " \n",
      "No of bins: V2\n",
      "16\n",
      "Entries per interval for V2\n",
      "Counter({0.14231738035264482: 1158, 0.5291777188328912: 1089, 0.46167883211678834: 778, 0.2631578947368421: 578, 0.29545454545454547: 414, 0.23790322580645162: 367, 0.16666666666666666: 359, 0.06770833333333333: 266, 0.08045977011494253: 118, 0.0: 112, 0.10416666666666667: 72, 0.47058823529411764: 47, 0.2: 23, 0.75: 11, 0.3333333333333333: 10, 1.0: 2})\n",
      " \n",
      "No of bins: V3\n",
      "16\n",
      "Entries per interval for V3\n",
      "Counter({0.4537892791127542: 1518, 0.021929824561403508: 977, 0.571764705882353: 629, 0.18446601941747573: 442, 0.05782312925170068: 418, 0.44981412639405205: 398, 0.24279835390946503: 349, 0.3388888888888889: 257, 0.1638418079096045: 249, 0.05: 85, 0.42857142857142855: 41, 0.1111111111111111: 14, 0.0: 13, 0.8: 6, 0.4: 5, 1.0: 3})\n",
      " \n",
      "No of bins: V4\n",
      "13\n",
      "Entries per interval for V4\n",
      "Counter({0.01224105461393597: 1529, 0.6124260355029586: 1444, 0.29254571026722925: 1000, 0.14204545454545456: 504, 0.391304347826087: 247, 0.0658682634730539: 237, 0.4589041095890411: 208, 0.5: 77, 0.375: 68, 0.7727272727272727: 30, 1.0: 29, 0.13636363636363635: 26, 0.6666666666666666: 5})\n",
      " \n",
      "No of bins: V5\n",
      "15\n",
      "Entries per interval for V5\n",
      "Counter({0.2208398133748056: 1823, 0.08231707317073171: 1413, 0.27049180327868855: 709, 0.48514851485148514: 302, 0.5510204081632653: 213, 0.5827814569536424: 212, 0.7706422018348624: 161, 0.5446428571428571: 147, 0.6704545454545454: 122, 0.7073170731707317: 113, 0.8666666666666667: 87, 0.7777777777777778: 63, 0.0: 20, 0.1111111111111111: 12, 1.0: 7})\n",
      " \n",
      "No of bins: class\n",
      "2\n",
      "Entries per interval for class\n",
      "Counter({0: 3818, 1: 1586})\n",
      " \n"
     ]
    }
   ],
   "source": [
    "#Show number of bins for each variable\n",
    "#no of bins\n",
    "for i in disc:\n",
    "    print('No of bins: ' + i)\n",
    "    print(disc[i].nunique())\n",
    "    #show start of intervals of each bin\n",
    "    print('Entries per interval for ' + i)\n",
    "    print(Counter(disc[i]))\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6529c9f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            V1        V2        V3        V4        V5  class\n",
      "3974  0.306649  0.142317  0.057823  0.012241  0.270492      0\n",
      "2580  0.386631  0.142317  0.571765  0.292546  0.082317      0\n",
      "2027  0.304762  0.295455  0.184466  0.142045  0.220840      0\n",
      "4752  0.000000  0.461679  0.021930  0.012241  0.082317      0\n",
      "4160  0.306649  0.142317  0.453789  0.012241  0.220840      0\n",
      "...        ...       ...       ...       ...       ...    ...\n",
      "4770  0.000000  0.461679  0.021930  0.012241  0.082317      0\n",
      "803   0.406349  0.529178  0.453789  0.458904  0.770642      0\n",
      "4563  0.000000  0.529178  0.021930  0.012241  0.220840      0\n",
      "536   0.031674  0.166667  0.184466  0.012241  0.220840      0\n",
      "3349  0.406349  0.237903  0.453789  0.612426  0.544643      1\n",
      "\n",
      "[5404 rows x 6 columns]\n",
      "      V1  V2  V3  V4  V5  class\n",
      "0      7   4   3   0   4      0\n",
      "1      8   4  13   4   1      0\n",
      "2      6   9   6   3   3      0\n",
      "3      0  11   1   0   1      0\n",
      "4      7   4  12   0   3      0\n",
      "...   ..  ..  ..  ..  ..    ...\n",
      "5399   0  11   1   0   1      0\n",
      "5400   9  13  12   7  11      0\n",
      "5401   0  13   1   0   3      0\n",
      "5402   1   5   6   0   3      0\n",
      "5403   9   7  12   9   6      1\n",
      "\n",
      "[5404 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "#ordinal encoding\n",
    "from numpy import asarray\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "# define data\n",
    "data1 = asarray(disc)\n",
    "print(disc)\n",
    "# define ordinal encoding\n",
    "encoder = OrdinalEncoder()\n",
    "# transform data\n",
    "result = pd.DataFrame(encoder.fit_transform(disc))\n",
    "#print(result)\n",
    "disc_ord = pd.DataFrame(result).astype(int)\n",
    "tmp_col = phoneme.columns\n",
    "disc_ord.columns = tmp_col # change column name\n",
    "#print(disc_ord)\n",
    "#disc_ord = pd.concat([categorical, disc_ord], axis=1)\n",
    "print(disc_ord)\n",
    "disc_ord.isna().sum()\n",
    "# Export this dataset for discretization\n",
    "disc_ord.to_csv('DT_large_discretized_phoneme.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e006c24",
   "metadata": {},
   "source": [
    "## 2.4 DT with extra large max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6dabb3e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            V1        V2        V3        V4        V5  class\n",
      "3974  0.309166  0.141236  0.051546  0.001647  0.222222      0\n",
      "2580  0.383288  0.141236  0.556728  0.291549  0.164319      0\n",
      "2027  0.252427  0.251613  0.179153  0.127451  0.119403      0\n",
      "4752  0.000000  0.467652  0.092308  0.026374  0.019713      0\n",
      "4160  0.309166  0.141236  0.482801  0.001647  0.119403      0\n",
      "...        ...       ...       ...       ...       ...    ...\n",
      "4770  0.000000  0.467652  0.092308  0.001647  0.019713      0\n",
      "803   0.413570  0.442553  0.482801  0.475177  0.742268      0\n",
      "4563  0.000000  0.442553  0.014540  0.001647  0.119403      0\n",
      "536   0.019868  0.172840  0.179153  0.026374  0.119403      0\n",
      "3349  0.413570  0.212500  0.365672  0.606122  0.519608      1\n",
      "\n",
      "[5404 rows x 6 columns]\n",
      "DT discreizer binner dict:\n",
      "{'V1': GridSearchCV(cv=3, estimator=DecisionTreeClassifier(random_state=29),\n",
      "             param_grid={'max_depth': [5]}, scoring='accuracy'), 'V2': GridSearchCV(cv=3, estimator=DecisionTreeClassifier(random_state=29),\n",
      "             param_grid={'max_depth': [5]}, scoring='accuracy'), 'V3': GridSearchCV(cv=3, estimator=DecisionTreeClassifier(random_state=29),\n",
      "             param_grid={'max_depth': [5]}, scoring='accuracy'), 'V4': GridSearchCV(cv=3, estimator=DecisionTreeClassifier(random_state=29),\n",
      "             param_grid={'max_depth': [5]}, scoring='accuracy'), 'V5': GridSearchCV(cv=3, estimator=DecisionTreeClassifier(random_state=29),\n",
      "             param_grid={'max_depth': [5]}, scoring='accuracy')}\n",
      " \n",
      "Computation time: \n",
      "0.19831585884094238\n"
     ]
    }
   ],
   "source": [
    "#make DT discreizer\n",
    "# 'max_depth': [5] => 2^5 = 32 intervals max. \n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "treeDisc = DecisionTreeDiscretiser(cv=3,\n",
    "                                   scoring='accuracy',\n",
    "                                   variables=num_list,\n",
    "                                   regression=False,\n",
    "                                   param_grid={'max_depth': [5]},\n",
    "                                   random_state=29,\n",
    "                                   )\n",
    "\n",
    "treeDisc.fit(X_train, y_train)\n",
    "\n",
    "# transform the data\n",
    "train_t= treeDisc.transform(X_train)\n",
    "test_t= treeDisc.transform(X_test)\n",
    "\n",
    "#add on to categorical dataset again\n",
    "disc = pd.concat([train_t, test_t], axis=0)\n",
    "print(disc)\n",
    "#categorical = categorical.drop('label', axis=1)\n",
    "\n",
    "# put side by side the original variable and the transformed variable\n",
    "print('DT discreizer binner dict:')\n",
    "print(treeDisc.binner_dict_)\n",
    "print(' ')\n",
    "print('Computation time: ')\n",
    "end = time.time()\n",
    "print(end - start) # Total time execution for this sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7cc35163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of bins: V1\n",
      "16\n",
      "Entries per interval for V1\n",
      "Counter({0.3832879200726612: 1572, 0.3091655266757866: 1060, 0.4135702746365105: 884, 0.0: 732, 0.019867549668874173: 215, 0.35514018691588783: 148, 0.15: 147, 0.5849056603773585: 146, 0.2524271844660194: 140, 0.05714285714285714: 96, 0.1836734693877551: 70, 0.23333333333333334: 50, 0.35135135135135137: 46, 0.125: 42, 0.7142857142857143: 36, 1.0: 20})\n",
      " \n",
      "No of bins: V2\n",
      "18\n",
      "Entries per interval for V2\n",
      "Counter({0.14123581336696092: 1157, 0.4676524953789279: 760, 0.5684007707129094: 759, 0.25757575757575757: 574, 0.2125: 353, 0.1728395061728395: 344, 0.4425531914893617: 330, 0.33986928104575165: 224, 0.0: 223, 0.08024691358024691: 222, 0.25161290322580643: 190, 0.1076923076923077: 84, 0.0851063829787234: 70, 0.4375: 44, 1.0: 33, 0.15789473684210525: 21, 0.14285714285714285: 8, 0.6666666666666666: 8})\n",
      " \n",
      "No of bins: V3\n",
      "22\n",
      "Entries per interval for V3\n",
      "Counter({0.4828009828009828: 1129, 0.014539579967689823: 891, 0.5567282321899736: 561, 0.1791530944625407: 439, 0.05154639175257732: 415, 0.3656716417910448: 389, 0.2590909090909091: 318, 0.48633879781420764: 271, 0.1590909090909091: 248, 0.3508771929824561: 244, 0.37209302325581395: 127, 0.09230769230769231: 86, 0.03571428571428571: 80, 0.6956521739130435: 68, 0.08695652173913043: 31, 0.0: 27, 0.6428571428571429: 23, 0.21428571428571427: 18, 1.0: 15, 0.1111111111111111: 13, 0.6666666666666666: 6, 0.25: 5})\n",
      " \n",
      "No of bins: V4\n",
      "19\n",
      "Entries per interval for V4\n",
      "Counter({0.6061224489795919: 1394, 0.2915492957746479: 999, 0.0016474464579901153: 878, 0.026373626373626374: 651, 0.12745098039215685: 440, 0.060240963855421686: 236, 0.475177304964539: 198, 0.4409448818897638: 196, 0.2391304347826087: 64, 0.40816326530612246: 61, 0.20588235294117646: 51, 0.7941176470588235: 50, 0.3103448275862069: 45, 1.0: 45, 0.7894736842105263: 32, 0.0: 23, 0.6875: 20, 0.25: 14, 0.14285714285714285: 7})\n",
      " \n",
      "No of bins: V5\n",
      "24\n",
      "Entries per interval for V5\n",
      "Counter({0.11940298507462686: 968, 0.33116883116883117: 855, 0.01971326164874552: 790, 0.1643192488262911: 623, 0.311787072243346: 397, 0.2222222222222222: 312, 0.4627659574468085: 283, 0.5151515151515151: 195, 0.628099173553719: 170, 0.7422680412371134: 145, 0.5196078431372549: 133, 0.7341772151898734: 109, 0.7162162162162162: 105, 0.8490566037735849: 74, 0.4: 42, 1.0: 36, 0.88: 35, 0.0: 29, 0.65: 28, 0.7857142857142857: 19, 0.8666666666666667: 18, 0.42857142857142855: 17, 0.8: 14, 0.25: 7})\n",
      " \n",
      "No of bins: class\n",
      "2\n",
      "Entries per interval for class\n",
      "Counter({0: 3818, 1: 1586})\n",
      " \n"
     ]
    }
   ],
   "source": [
    "#Show number of bins for each variable\n",
    "#no of bins\n",
    "for i in disc:\n",
    "    print('No of bins: ' + i)\n",
    "    print(disc[i].nunique())\n",
    "    #show start of intervals of each bin\n",
    "    print('Entries per interval for ' + i)\n",
    "    print(Counter(disc[i]))\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "32efc843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            V1        V2        V3        V4        V5  class\n",
      "3974  0.309166  0.141236  0.051546  0.001647  0.222222      0\n",
      "2580  0.383288  0.141236  0.556728  0.291549  0.164319      0\n",
      "2027  0.252427  0.251613  0.179153  0.127451  0.119403      0\n",
      "4752  0.000000  0.467652  0.092308  0.026374  0.019713      0\n",
      "4160  0.309166  0.141236  0.482801  0.001647  0.119403      0\n",
      "...        ...       ...       ...       ...       ...    ...\n",
      "4770  0.000000  0.467652  0.092308  0.001647  0.019713      0\n",
      "803   0.413570  0.442553  0.482801  0.475177  0.742268      0\n",
      "4563  0.000000  0.442553  0.014540  0.001647  0.119403      0\n",
      "536   0.019868  0.172840  0.179153  0.026374  0.119403      0\n",
      "3349  0.413570  0.212500  0.365672  0.606122  0.519608      1\n",
      "\n",
      "[5404 rows x 6 columns]\n",
      "      V1  V2  V3  V4  V5  class\n",
      "0      8   4   3   1   4      0\n",
      "1     11   4  17   9   3      0\n",
      "2      7   9   8   4   2      0\n",
      "3      0  14   5   2   1      0\n",
      "4      8   4  15   1   2      0\n",
      "...   ..  ..  ..  ..  ..    ...\n",
      "5399   0  14   5   1   1      0\n",
      "5400  12  13  15  13  17      0\n",
      "5401   0  13   1   1   2      0\n",
      "5402   1   7   8   2   2      0\n",
      "5403  12   8  13  14  12      1\n",
      "\n",
      "[5404 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "#ordinal encoding\n",
    "from numpy import asarray\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "# define data\n",
    "data1 = asarray(disc)\n",
    "print(disc)\n",
    "# define ordinal encoding\n",
    "encoder = OrdinalEncoder()\n",
    "# transform data\n",
    "result = pd.DataFrame(encoder.fit_transform(disc))\n",
    "#print(result)\n",
    "disc_ord = pd.DataFrame(result).astype(int)\n",
    "tmp_col = phoneme.columns\n",
    "disc_ord.columns = tmp_col # change column name\n",
    "#print(disc_ord)\n",
    "#disc_ord = pd.concat([categorical, disc_ord], axis=1)\n",
    "print(disc_ord)\n",
    "disc_ord.isna().sum()\n",
    "# Export this dataset for discretization\n",
    "disc_ord.to_csv('DT_verylarge_discretized_phoneme.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b95f70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecebc99-bf53-4780-90d2-aa223edca28f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
