{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25f531ad",
   "metadata": {},
   "source": [
    "# Bias - Variance Decomposition - Supervised discretizer\n",
    "\n",
    "- Dataset: satimage\n",
    "- Discretization: supervised: ChiMerge, DecisionTree\n",
    "- Model: Knn-Hamming\n",
    "- Updated: 27/04/23\n",
    "\n",
    "Process:\n",
    "- Load pre-trained model (skops)\n",
    "- Run bias-variance decomposition\n",
    "- Save result to \"satimage_evaluation_sup_knn.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41ccebb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import skops.io as sio\n",
    "import mlxtend\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b563481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For model evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import zero_one_loss\n",
    "#This library is used to decompose bias and variance in our models\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfae4107",
   "metadata": {},
   "outputs": [],
   "source": [
    "import six\n",
    "import sys\n",
    "sys.modules['sklearn.externals.six'] = six"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1506c69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import \n",
    "import skops.io as sio\n",
    "import joblib\n",
    "import mlxtend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c62f4c",
   "metadata": {},
   "source": [
    "# 1. ChiMerge data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd585fc",
   "metadata": {},
   "source": [
    "## CM, Max intervals = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb54debc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6435 entries, 0 to 6434\n",
      "Data columns (total 37 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   A1      6435 non-null   int64\n",
      " 1   A2      6435 non-null   int64\n",
      " 2   A3      6435 non-null   int64\n",
      " 3   A4      6435 non-null   int64\n",
      " 4   A5      6435 non-null   int64\n",
      " 5   A6      6435 non-null   int64\n",
      " 6   A7      6435 non-null   int64\n",
      " 7   A8      6435 non-null   int64\n",
      " 8   A9      6435 non-null   int64\n",
      " 9   A10     6435 non-null   int64\n",
      " 10  A11     6435 non-null   int64\n",
      " 11  A12     6435 non-null   int64\n",
      " 12  A13     6435 non-null   int64\n",
      " 13  A14     6435 non-null   int64\n",
      " 14  A15     6435 non-null   int64\n",
      " 15  A16     6435 non-null   int64\n",
      " 16  A17     6435 non-null   int64\n",
      " 17  A18     6435 non-null   int64\n",
      " 18  A19     6435 non-null   int64\n",
      " 19  A20     6435 non-null   int64\n",
      " 20  A21     6435 non-null   int64\n",
      " 21  A22     6435 non-null   int64\n",
      " 22  A23     6435 non-null   int64\n",
      " 23  A24     6435 non-null   int64\n",
      " 24  A25     6435 non-null   int64\n",
      " 25  A26     6435 non-null   int64\n",
      " 26  A27     6435 non-null   int64\n",
      " 27  A28     6435 non-null   int64\n",
      " 28  A29     6435 non-null   int64\n",
      " 29  A30     6435 non-null   int64\n",
      " 30  A31     6435 non-null   int64\n",
      " 31  A32     6435 non-null   int64\n",
      " 32  A33     6435 non-null   int64\n",
      " 33  A34     6435 non-null   int64\n",
      " 34  A35     6435 non-null   int64\n",
      " 35  A36     6435 non-null   int64\n",
      " 36  label   6435 non-null   int64\n",
      "dtypes: int64(37)\n",
      "memory usage: 1.8 MB\n",
      "(6435, 36) (6435,)\n",
      "(4435, 36)\n",
      "(2000, 36)\n",
      "=================\n",
      "Class representation - original:  Counter({0: 1533, 5: 1508, 2: 1358, 4: 707, 1: 703, 3: 626})\n",
      "Class representation - training data:  Counter({0: 1072, 5: 1038, 2: 961, 1: 479, 4: 470, 3: 415})\n",
      "Class representation - testing data:  Counter({5: 470, 0: 461, 2: 397, 4: 237, 1: 224, 3: 211})\n"
     ]
    }
   ],
   "source": [
    "# Complete code for data preperation\n",
    "# Read data\n",
    "df_cm1 = pd.read_csv('cm_satimage_6int.csv')\n",
    "df_cm1.rename(columns={'class':'label'}, inplace=True)\n",
    "disc = 'CM'\n",
    "k = 6\n",
    "\n",
    "df_cm1.info()\n",
    "data = df_cm1.values\n",
    "data.shape\n",
    "\n",
    "features = df_cm1.drop('label', axis = 1).columns\n",
    "\n",
    "# separate the data into X and y\n",
    "X = data[:, : len(features)]\n",
    "Y = data[:,-1]\n",
    "#X = df_cm1[features]\n",
    "#Y = df_cm1['label']\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "# Split train test\n",
    "x_train = X[:4435, :]\n",
    "y_train = Y[:4435]\n",
    "x_test= X[4435:, :]\n",
    "y_test= Y[4435:]\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print('=================')\n",
    "\n",
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(Y)) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test)) \n",
    "\n",
    "# Check number of categories for features\n",
    "n_categories = df_cm1[features].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2842186d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "satimage_Knn-Hamming_CM_6.skops\n"
     ]
    }
   ],
   "source": [
    "# Load models\n",
    "model = 'Knn-Hamming'\n",
    "dataset = 'satimage'\n",
    "discretizer = 'CM'\n",
    "disc_param = 'k = 6'\n",
    "model_name = f\"{dataset}_{model}_{discretizer}_{k}.skops\"\n",
    "print(model_name)\n",
    "loaded_knn = sio.load(model_name, trusted=True)\n",
    "y_pred_knn = loaded_knn.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8474592a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decomposition\n",
    "f = open(\"satimage_evaluation_sup_knn.txt\", \"a\")\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "loaded_knn, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "\n",
    "print(f'Evaluation result: {model}, {discretizer}, {disc_param}', file = f)\n",
    "print('Average expected loss: %.3f' % avg_expected_loss, file = f)\n",
    "print('Average bias: %.3f' % avg_bias, file = f)\n",
    "print('Average variance: %.3f' % avg_var, file = f)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_knn), file = f)\n",
    "\n",
    "end = time.time()\n",
    "print(f'Execution time {model}- default, {disc}, k = {k} is: {end - start}.', file = f) # Total time execution\n",
    "print('=='*20, file = f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067d47b0",
   "metadata": {},
   "source": [
    "## CM, Max intervals = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecf38b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6435 entries, 0 to 6434\n",
      "Data columns (total 37 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   A1      6435 non-null   int64\n",
      " 1   A2      6435 non-null   int64\n",
      " 2   A3      6435 non-null   int64\n",
      " 3   A4      6435 non-null   int64\n",
      " 4   A5      6435 non-null   int64\n",
      " 5   A6      6435 non-null   int64\n",
      " 6   A7      6435 non-null   int64\n",
      " 7   A8      6435 non-null   int64\n",
      " 8   A9      6435 non-null   int64\n",
      " 9   A10     6435 non-null   int64\n",
      " 10  A11     6435 non-null   int64\n",
      " 11  A12     6435 non-null   int64\n",
      " 12  A13     6435 non-null   int64\n",
      " 13  A14     6435 non-null   int64\n",
      " 14  A15     6435 non-null   int64\n",
      " 15  A16     6435 non-null   int64\n",
      " 16  A17     6435 non-null   int64\n",
      " 17  A18     6435 non-null   int64\n",
      " 18  A19     6435 non-null   int64\n",
      " 19  A20     6435 non-null   int64\n",
      " 20  A21     6435 non-null   int64\n",
      " 21  A22     6435 non-null   int64\n",
      " 22  A23     6435 non-null   int64\n",
      " 23  A24     6435 non-null   int64\n",
      " 24  A25     6435 non-null   int64\n",
      " 25  A26     6435 non-null   int64\n",
      " 26  A27     6435 non-null   int64\n",
      " 27  A28     6435 non-null   int64\n",
      " 28  A29     6435 non-null   int64\n",
      " 29  A30     6435 non-null   int64\n",
      " 30  A31     6435 non-null   int64\n",
      " 31  A32     6435 non-null   int64\n",
      " 32  A33     6435 non-null   int64\n",
      " 33  A34     6435 non-null   int64\n",
      " 34  A35     6435 non-null   int64\n",
      " 35  A36     6435 non-null   int64\n",
      " 36  label   6435 non-null   int64\n",
      "dtypes: int64(37)\n",
      "memory usage: 1.8 MB\n",
      "(6435, 36) (6435,)\n",
      "(4435, 36)\n",
      "(2000, 36)\n",
      "=================\n",
      "Class representation - original:  Counter({0: 1533, 5: 1508, 2: 1358, 4: 707, 1: 703, 3: 626})\n",
      "Class representation - training data:  Counter({0: 1072, 5: 1038, 2: 961, 1: 479, 4: 470, 3: 415})\n",
      "Class representation - testing data:  Counter({5: 470, 0: 461, 2: 397, 4: 237, 1: 224, 3: 211})\n"
     ]
    }
   ],
   "source": [
    "# Complete code for data preperation\n",
    "# Read data\n",
    "df_cm2 = pd.read_csv('cm_satimage_8int.csv')\n",
    "df_cm2.rename(columns={'class':'label'}, inplace=True)\n",
    "disc = 'CM'\n",
    "k = 8\n",
    "\n",
    "df_cm2.info()\n",
    "data = df_cm2.values\n",
    "data.shape\n",
    "\n",
    "features = df_cm2.drop('label', axis = 1).columns\n",
    "\n",
    "# separate the data into X and y\n",
    "X = data[:, : len(features)]\n",
    "Y = data[:,-1]\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "# Split train test\n",
    "x_train = X[:4435, :]\n",
    "y_train = Y[:4435]\n",
    "x_test= X[4435:, :]\n",
    "y_test= Y[4435:]\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print('=================')\n",
    "\n",
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(Y)) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test)) \n",
    "\n",
    "# Check number of categories for features\n",
    "n_categories = df_cm2[features].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59a87fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "satimage_Knn-Hamming_CM_8.skops\n"
     ]
    }
   ],
   "source": [
    "# Load models\n",
    "model = 'Knn-Hamming'\n",
    "dataset = 'satimage'\n",
    "discretizer = 'CM'\n",
    "disc_param = 'k = 8'\n",
    "model_name = f\"{dataset}_{model}_{discretizer}_{k}.skops\"\n",
    "print(model_name)\n",
    "loaded_knn = sio.load(model_name, trusted=True)\n",
    "y_pred_knn = loaded_knn.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68aab87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decomposition\n",
    "f = open(\"satimage_evaluation_sup_knn.txt\", \"a\")\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "loaded_knn, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "\n",
    "print(f'Evaluation result: {model}, {discretizer}, {disc_param}', file = f)\n",
    "print('Average expected loss: %.3f' % avg_expected_loss, file = f)\n",
    "print('Average bias: %.3f' % avg_bias, file = f)\n",
    "print('Average variance: %.3f' % avg_var, file = f)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_knn), file = f)\n",
    "\n",
    "end = time.time()\n",
    "print(f'Execution time {model}- default, {disc}, k = {k} is: {end - start}.', file = f) # Total time execution\n",
    "print('=='*20, file = f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410ee7c1",
   "metadata": {},
   "source": [
    "## ChiMerge, max_intervals = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92c7e4ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6435 entries, 0 to 6434\n",
      "Data columns (total 37 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   A1      6435 non-null   int64\n",
      " 1   A2      6435 non-null   int64\n",
      " 2   A3      6435 non-null   int64\n",
      " 3   A4      6435 non-null   int64\n",
      " 4   A5      6435 non-null   int64\n",
      " 5   A6      6435 non-null   int64\n",
      " 6   A7      6435 non-null   int64\n",
      " 7   A8      6435 non-null   int64\n",
      " 8   A9      6435 non-null   int64\n",
      " 9   A10     6435 non-null   int64\n",
      " 10  A11     6435 non-null   int64\n",
      " 11  A12     6435 non-null   int64\n",
      " 12  A13     6435 non-null   int64\n",
      " 13  A14     6435 non-null   int64\n",
      " 14  A15     6435 non-null   int64\n",
      " 15  A16     6435 non-null   int64\n",
      " 16  A17     6435 non-null   int64\n",
      " 17  A18     6435 non-null   int64\n",
      " 18  A19     6435 non-null   int64\n",
      " 19  A20     6435 non-null   int64\n",
      " 20  A21     6435 non-null   int64\n",
      " 21  A22     6435 non-null   int64\n",
      " 22  A23     6435 non-null   int64\n",
      " 23  A24     6435 non-null   int64\n",
      " 24  A25     6435 non-null   int64\n",
      " 25  A26     6435 non-null   int64\n",
      " 26  A27     6435 non-null   int64\n",
      " 27  A28     6435 non-null   int64\n",
      " 28  A29     6435 non-null   int64\n",
      " 29  A30     6435 non-null   int64\n",
      " 30  A31     6435 non-null   int64\n",
      " 31  A32     6435 non-null   int64\n",
      " 32  A33     6435 non-null   int64\n",
      " 33  A34     6435 non-null   int64\n",
      " 34  A35     6435 non-null   int64\n",
      " 35  A36     6435 non-null   int64\n",
      " 36  label   6435 non-null   int64\n",
      "dtypes: int64(37)\n",
      "memory usage: 1.8 MB\n",
      "(6435, 36) (6435,)\n",
      "(4435, 36)\n",
      "(2000, 36)\n",
      "=================\n",
      "Class representation - original:  Counter({0: 1533, 5: 1508, 2: 1358, 4: 707, 1: 703, 3: 626})\n",
      "Class representation - training data:  Counter({0: 1072, 5: 1038, 2: 961, 1: 479, 4: 470, 3: 415})\n",
      "Class representation - testing data:  Counter({5: 470, 0: 461, 2: 397, 4: 237, 1: 224, 3: 211})\n"
     ]
    }
   ],
   "source": [
    "# Complete code for data preperation\n",
    "# Read data\n",
    "df_cm3 = pd.read_csv('cm_satimage_10int.csv')\n",
    "df_cm3.rename(columns={'class':'label'}, inplace=True)\n",
    "disc = 'cm'\n",
    "k = 10\n",
    "\n",
    "df_cm3.info()\n",
    "data = df_cm3.values\n",
    "data.shape\n",
    "\n",
    "features = df_cm3.drop('label', axis = 1).columns\n",
    "\n",
    "# separate the data into X and y\n",
    "X = data[:, : len(features)]\n",
    "Y = data[:,-1]\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "# Split train test\n",
    "x_train = X[:4435, :]\n",
    "y_train = Y[:4435]\n",
    "x_test= X[4435:, :]\n",
    "y_test= Y[4435:]\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print('=================')\n",
    "\n",
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(Y)) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test)) \n",
    "\n",
    "# Check number of categories for features\n",
    "n_categories = df_cm3[features].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64277f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "satimage_Knn-Hamming_CM_10.skops\n"
     ]
    }
   ],
   "source": [
    "# Load models\n",
    "model = 'Knn-Hamming'\n",
    "dataset = 'satimage'\n",
    "discretizer = 'CM'\n",
    "disc_param = 'k = 10'\n",
    "model_name = f\"{dataset}_{model}_{discretizer}_{k}.skops\"\n",
    "print(model_name)\n",
    "loaded_knn = sio.load(model_name, trusted=True)\n",
    "y_pred_knn = loaded_knn.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a672e659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decomposition\n",
    "f = open(\"satimage_evaluation_sup_knn.txt\", \"a\")\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "loaded_knn, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "\n",
    "print(f'Evaluation result: {model}, {discretizer}, {disc_param}', file = f)\n",
    "print('Average expected loss: %.3f' % avg_expected_loss, file = f)\n",
    "print('Average bias: %.3f' % avg_bias, file = f)\n",
    "print('Average variance: %.3f' % avg_var, file = f)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_knn), file = f)\n",
    "\n",
    "end = time.time()\n",
    "print(f'Execution time {model}- default, {disc}, k = {k} is: {end - start}.', file = f) # Total time execution\n",
    "print('=='*20, file = f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780c5d70",
   "metadata": {},
   "source": [
    "## ChiMerge, max_intervals = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70add600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6435 entries, 0 to 6434\n",
      "Data columns (total 37 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   A1      6435 non-null   int64\n",
      " 1   A2      6435 non-null   int64\n",
      " 2   A3      6435 non-null   int64\n",
      " 3   A4      6435 non-null   int64\n",
      " 4   A5      6435 non-null   int64\n",
      " 5   A6      6435 non-null   int64\n",
      " 6   A7      6435 non-null   int64\n",
      " 7   A8      6435 non-null   int64\n",
      " 8   A9      6435 non-null   int64\n",
      " 9   A10     6435 non-null   int64\n",
      " 10  A11     6435 non-null   int64\n",
      " 11  A12     6435 non-null   int64\n",
      " 12  A13     6435 non-null   int64\n",
      " 13  A14     6435 non-null   int64\n",
      " 14  A15     6435 non-null   int64\n",
      " 15  A16     6435 non-null   int64\n",
      " 16  A17     6435 non-null   int64\n",
      " 17  A18     6435 non-null   int64\n",
      " 18  A19     6435 non-null   int64\n",
      " 19  A20     6435 non-null   int64\n",
      " 20  A21     6435 non-null   int64\n",
      " 21  A22     6435 non-null   int64\n",
      " 22  A23     6435 non-null   int64\n",
      " 23  A24     6435 non-null   int64\n",
      " 24  A25     6435 non-null   int64\n",
      " 25  A26     6435 non-null   int64\n",
      " 26  A27     6435 non-null   int64\n",
      " 27  A28     6435 non-null   int64\n",
      " 28  A29     6435 non-null   int64\n",
      " 29  A30     6435 non-null   int64\n",
      " 30  A31     6435 non-null   int64\n",
      " 31  A32     6435 non-null   int64\n",
      " 32  A33     6435 non-null   int64\n",
      " 33  A34     6435 non-null   int64\n",
      " 34  A35     6435 non-null   int64\n",
      " 35  A36     6435 non-null   int64\n",
      " 36  label   6435 non-null   int64\n",
      "dtypes: int64(37)\n",
      "memory usage: 1.8 MB\n",
      "(6435, 36) (6435,)\n",
      "(4435, 36)\n",
      "(2000, 36)\n",
      "=================\n",
      "Class representation - original:  Counter({0: 1533, 5: 1508, 2: 1358, 4: 707, 1: 703, 3: 626})\n",
      "Class representation - training data:  Counter({0: 1072, 5: 1038, 2: 961, 1: 479, 4: 470, 3: 415})\n",
      "Class representation - testing data:  Counter({5: 470, 0: 461, 2: 397, 4: 237, 1: 224, 3: 211})\n"
     ]
    }
   ],
   "source": [
    "# Complete code for data preperation\n",
    "# Read data\n",
    "df_cm4 = pd.read_csv('cm_satimage_15int.csv')\n",
    "df_cm4.rename(columns={'class':'label'}, inplace=True)\n",
    "disc = 'cm'\n",
    "k = 15\n",
    "\n",
    "df_cm4.info()\n",
    "data = df_cm4.values\n",
    "data.shape\n",
    "\n",
    "features = df_cm4.drop('label', axis = 1).columns\n",
    "\n",
    "# separate the data into X and y\n",
    "X = data[:, : len(features)]\n",
    "Y = data[:,-1]\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "# Split train test\n",
    "x_train = X[:4435, :]\n",
    "y_train = Y[:4435]\n",
    "x_test= X[4435:, :]\n",
    "y_test= Y[4435:]\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print('=================')\n",
    "\n",
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(Y)) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test)) \n",
    "\n",
    "# Check number of categories for features\n",
    "n_categories = df_cm4[features].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "595baedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "satimage_Knn-Hamming_CM_15.skops\n"
     ]
    }
   ],
   "source": [
    "# Load models\n",
    "model = 'Knn-Hamming'\n",
    "dataset = 'satimage'\n",
    "discretizer = 'CM'\n",
    "disc_param = 'k = 15'\n",
    "model_name = f\"{dataset}_{model}_{discretizer}_{k}.skops\"\n",
    "print(model_name)\n",
    "loaded_knn = sio.load(model_name, trusted=True)\n",
    "y_pred_knn = loaded_knn.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47067d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decomposition\n",
    "f = open(\"satimage_evaluation_sup_knn.txt\", \"a\")\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "loaded_knn, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "\n",
    "print(f'Evaluation result: {model}, {discretizer}, {disc_param}', file = f)\n",
    "print('Average expected loss: %.3f' % avg_expected_loss, file = f)\n",
    "print('Average bias: %.3f' % avg_bias, file = f)\n",
    "print('Average variance: %.3f' % avg_var, file = f)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_knn), file = f)\n",
    "\n",
    "end = time.time()\n",
    "print(f'Execution time {model}- default, {disc}, k = {k} is: {end - start}.', file = f) # Total time execution\n",
    "print('=='*20, file = f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd32b5c6",
   "metadata": {},
   "source": [
    "# Decision Tree discretizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72dcb79",
   "metadata": {},
   "source": [
    "## DT, max_depth = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "170fa18b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6435 entries, 0 to 6434\n",
      "Data columns (total 37 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   A1      6435 non-null   int64\n",
      " 1   A2      6435 non-null   int64\n",
      " 2   A3      6435 non-null   int64\n",
      " 3   A4      6435 non-null   int64\n",
      " 4   A5      6435 non-null   int64\n",
      " 5   A6      6435 non-null   int64\n",
      " 6   A7      6435 non-null   int64\n",
      " 7   A8      6435 non-null   int64\n",
      " 8   A9      6435 non-null   int64\n",
      " 9   A10     6435 non-null   int64\n",
      " 10  A11     6435 non-null   int64\n",
      " 11  A12     6435 non-null   int64\n",
      " 12  A13     6435 non-null   int64\n",
      " 13  A14     6435 non-null   int64\n",
      " 14  A15     6435 non-null   int64\n",
      " 15  A16     6435 non-null   int64\n",
      " 16  A17     6435 non-null   int64\n",
      " 17  A18     6435 non-null   int64\n",
      " 18  A19     6435 non-null   int64\n",
      " 19  A20     6435 non-null   int64\n",
      " 20  A21     6435 non-null   int64\n",
      " 21  A22     6435 non-null   int64\n",
      " 22  A23     6435 non-null   int64\n",
      " 23  A24     6435 non-null   int64\n",
      " 24  A25     6435 non-null   int64\n",
      " 25  A26     6435 non-null   int64\n",
      " 26  A27     6435 non-null   int64\n",
      " 27  A28     6435 non-null   int64\n",
      " 28  A29     6435 non-null   int64\n",
      " 29  A30     6435 non-null   int64\n",
      " 30  A31     6435 non-null   int64\n",
      " 31  A32     6435 non-null   int64\n",
      " 32  A33     6435 non-null   int64\n",
      " 33  A34     6435 non-null   int64\n",
      " 34  A35     6435 non-null   int64\n",
      " 35  A36     6435 non-null   int64\n",
      " 36  label   6435 non-null   int64\n",
      "dtypes: int64(37)\n",
      "memory usage: 1.8 MB\n",
      "(6435, 36) (6435,)\n",
      "(4435, 36)\n",
      "(2000, 36)\n",
      "=================\n",
      "Class representation - original:  Counter({0: 1533, 5: 1508, 2: 1358, 4: 707, 1: 703, 3: 626})\n",
      "Class representation - training data:  Counter({5: 1064, 0: 1044, 2: 934, 1: 501, 4: 480, 3: 412})\n",
      "Class representation - testing data:  Counter({0: 489, 5: 444, 2: 424, 4: 227, 3: 214, 1: 202})\n"
     ]
    }
   ],
   "source": [
    "# Complete code for data preperation\n",
    "# Read data\n",
    "df_dt1 = pd.read_csv('DT_small_discretized_satimage.csv')\n",
    "df_dt1.rename(columns={'class':'label'}, inplace=True)\n",
    "disc = 'DT'\n",
    "max_depth = 2\n",
    "\n",
    "df_dt1.info()\n",
    "data = df_dt1.values\n",
    "data.shape\n",
    "\n",
    "features = df_dt1.drop('label', axis = 1).columns\n",
    "\n",
    "# separate the data into X and y\n",
    "X = data[:, : len(features)]\n",
    "Y = data[:,-1]\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "#make train test split\n",
    "x_train = X[:4435, :]\n",
    "y_train = Y[:4435]\n",
    "x_test= X[4435:, :]\n",
    "y_test= Y[4435:]\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print('=================')\n",
    "\n",
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(Y)) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test)) \n",
    "\n",
    "# Check number of categories for features\n",
    "n_categories = df_dt1[features].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9c570716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "satimage_Knn-Hamming_DT_2.skops\n"
     ]
    }
   ],
   "source": [
    "# Load models\n",
    "model = 'Knn-Hamming'\n",
    "dataset = 'satimage'\n",
    "discretizer = 'DT'\n",
    "disc_param = 'max_depth = 2'\n",
    "\n",
    "model_name = f\"{dataset}_{model}_{discretizer}_{max_depth}.skops\"\n",
    "\n",
    "print(model_name)\n",
    "loaded_knn = sio.load(model_name, trusted=True)\n",
    "y_pred_knn = loaded_knn.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "382b6786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decomposition\n",
    "f = open(\"satimage_evaluation_sup_knn.txt\", \"a\")\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "loaded_knn, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "\n",
    "print(f'Evaluation result: {model}, {discretizer}, {disc_param}', file = f)\n",
    "print('Average expected loss: %.3f' % avg_expected_loss, file = f)\n",
    "print('Average bias: %.3f' % avg_bias, file = f)\n",
    "print('Average variance: %.3f' % avg_var, file = f)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_knn), file = f)\n",
    "\n",
    "end = time.time()\n",
    "print(f'Execution time {model}- default, {disc}, max_depth = {max_depth} is: {end - start}.', file = f) # Total time execution\n",
    "print('=='*20, file = f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f193d581",
   "metadata": {},
   "source": [
    "## DT, max_depth = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90230be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6435 entries, 0 to 6434\n",
      "Data columns (total 37 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   A1      6435 non-null   int64\n",
      " 1   A2      6435 non-null   int64\n",
      " 2   A3      6435 non-null   int64\n",
      " 3   A4      6435 non-null   int64\n",
      " 4   A5      6435 non-null   int64\n",
      " 5   A6      6435 non-null   int64\n",
      " 6   A7      6435 non-null   int64\n",
      " 7   A8      6435 non-null   int64\n",
      " 8   A9      6435 non-null   int64\n",
      " 9   A10     6435 non-null   int64\n",
      " 10  A11     6435 non-null   int64\n",
      " 11  A12     6435 non-null   int64\n",
      " 12  A13     6435 non-null   int64\n",
      " 13  A14     6435 non-null   int64\n",
      " 14  A15     6435 non-null   int64\n",
      " 15  A16     6435 non-null   int64\n",
      " 16  A17     6435 non-null   int64\n",
      " 17  A18     6435 non-null   int64\n",
      " 18  A19     6435 non-null   int64\n",
      " 19  A20     6435 non-null   int64\n",
      " 20  A21     6435 non-null   int64\n",
      " 21  A22     6435 non-null   int64\n",
      " 22  A23     6435 non-null   int64\n",
      " 23  A24     6435 non-null   int64\n",
      " 24  A25     6435 non-null   int64\n",
      " 25  A26     6435 non-null   int64\n",
      " 26  A27     6435 non-null   int64\n",
      " 27  A28     6435 non-null   int64\n",
      " 28  A29     6435 non-null   int64\n",
      " 29  A30     6435 non-null   int64\n",
      " 30  A31     6435 non-null   int64\n",
      " 31  A32     6435 non-null   int64\n",
      " 32  A33     6435 non-null   int64\n",
      " 33  A34     6435 non-null   int64\n",
      " 34  A35     6435 non-null   int64\n",
      " 35  A36     6435 non-null   int64\n",
      " 36  label   6435 non-null   int64\n",
      "dtypes: int64(37)\n",
      "memory usage: 1.8 MB\n",
      "(6435, 36) (6435,)\n",
      "(4435, 36)\n",
      "(2000, 36)\n",
      "=================\n",
      "Class representation - original:  Counter({0: 1533, 5: 1508, 2: 1358, 4: 707, 1: 703, 3: 626})\n",
      "Class representation - training data:  Counter({5: 1064, 0: 1044, 2: 934, 1: 501, 4: 480, 3: 412})\n",
      "Class representation - testing data:  Counter({0: 489, 5: 444, 2: 424, 4: 227, 3: 214, 1: 202})\n"
     ]
    }
   ],
   "source": [
    "# Complete code for data preperation\n",
    "# Read data\n",
    "df_dt2 = pd.read_csv('DT_medium_discretized_satimage.csv')\n",
    "df_dt2.rename(columns={'class':'label'}, inplace=True)\n",
    "disc = 'DT'\n",
    "max_depth = 3\n",
    "\n",
    "df_dt2.info()\n",
    "data = df_dt2.values\n",
    "data.shape\n",
    "\n",
    "features = df_dt2.drop('label', axis = 1).columns\n",
    "\n",
    "# separate the data into X and y\n",
    "X = data[:, : len(features)]\n",
    "Y = data[:,-1]\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "# Split train test\n",
    "#make train test split\n",
    "x_train = X[:4435, :]\n",
    "y_train = Y[:4435]\n",
    "x_test= X[4435:, :]\n",
    "y_test= Y[4435:]\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print('=================')\n",
    "\n",
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(Y)) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test)) \n",
    "\n",
    "# Check number of categories for features\n",
    "n_categories = df_dt2[features].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ef1f941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "satimage_Knn-Hamming_DT_3.skops\n"
     ]
    }
   ],
   "source": [
    "# Load models\n",
    "model = 'Knn-Hamming'\n",
    "dataset = 'satimage'\n",
    "discretizer = 'DT'\n",
    "disc_param = 'max_depth = 3'\n",
    "\n",
    "model_name = f\"{dataset}_{model}_{discretizer}_{max_depth}.skops\"\n",
    "\n",
    "print(model_name)\n",
    "loaded_knn = sio.load(model_name, trusted=True)\n",
    "y_pred_knn = loaded_knn.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "11bc26ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decomposition\n",
    "f = open(\"satimage_evaluation_sup_knn.txt\", \"a\")\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "loaded_knn, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "\n",
    "print(f'Evaluation result: {model}, {discretizer}, {disc_param}', file = f)\n",
    "print('Average expected loss: %.3f' % avg_expected_loss, file = f)\n",
    "print('Average bias: %.3f' % avg_bias, file = f)\n",
    "print('Average variance: %.3f' % avg_var, file = f)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_knn), file = f)\n",
    "\n",
    "end = time.time()\n",
    "print(f'Execution time {model}- default, {disc}, max_depth = {max_depth} is: {end - start}.', file = f) # Total time execution\n",
    "print('=='*20, file = f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa23913b",
   "metadata": {},
   "source": [
    "## DT, max_depth = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "43bfc1e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6435 entries, 0 to 6434\n",
      "Data columns (total 37 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   A1      6435 non-null   int64\n",
      " 1   A2      6435 non-null   int64\n",
      " 2   A3      6435 non-null   int64\n",
      " 3   A4      6435 non-null   int64\n",
      " 4   A5      6435 non-null   int64\n",
      " 5   A6      6435 non-null   int64\n",
      " 6   A7      6435 non-null   int64\n",
      " 7   A8      6435 non-null   int64\n",
      " 8   A9      6435 non-null   int64\n",
      " 9   A10     6435 non-null   int64\n",
      " 10  A11     6435 non-null   int64\n",
      " 11  A12     6435 non-null   int64\n",
      " 12  A13     6435 non-null   int64\n",
      " 13  A14     6435 non-null   int64\n",
      " 14  A15     6435 non-null   int64\n",
      " 15  A16     6435 non-null   int64\n",
      " 16  A17     6435 non-null   int64\n",
      " 17  A18     6435 non-null   int64\n",
      " 18  A19     6435 non-null   int64\n",
      " 19  A20     6435 non-null   int64\n",
      " 20  A21     6435 non-null   int64\n",
      " 21  A22     6435 non-null   int64\n",
      " 22  A23     6435 non-null   int64\n",
      " 23  A24     6435 non-null   int64\n",
      " 24  A25     6435 non-null   int64\n",
      " 25  A26     6435 non-null   int64\n",
      " 26  A27     6435 non-null   int64\n",
      " 27  A28     6435 non-null   int64\n",
      " 28  A29     6435 non-null   int64\n",
      " 29  A30     6435 non-null   int64\n",
      " 30  A31     6435 non-null   int64\n",
      " 31  A32     6435 non-null   int64\n",
      " 32  A33     6435 non-null   int64\n",
      " 33  A34     6435 non-null   int64\n",
      " 34  A35     6435 non-null   int64\n",
      " 35  A36     6435 non-null   int64\n",
      " 36  label   6435 non-null   int64\n",
      "dtypes: int64(37)\n",
      "memory usage: 1.8 MB\n",
      "(6435, 36) (6435,)\n",
      "(4435, 36)\n",
      "(2000, 36)\n",
      "=================\n",
      "Class representation - original:  Counter({0: 1533, 5: 1508, 2: 1358, 4: 707, 1: 703, 3: 626})\n",
      "Class representation - training data:  Counter({5: 1064, 0: 1044, 2: 934, 1: 501, 4: 480, 3: 412})\n",
      "Class representation - testing data:  Counter({0: 489, 5: 444, 2: 424, 4: 227, 3: 214, 1: 202})\n"
     ]
    }
   ],
   "source": [
    "# Complete code for data preperation\n",
    "# Read data\n",
    "df_dt3 = pd.read_csv('DT_large_discretized_satimage.csv')\n",
    "df_dt3.rename(columns={'class':'label'}, inplace=True)\n",
    "disc = 'DT'\n",
    "max_depth = 4\n",
    "\n",
    "df_dt3.info()\n",
    "data = df_dt3.values\n",
    "data.shape\n",
    "\n",
    "features = df_dt3.drop('label', axis = 1).columns\n",
    "\n",
    "# separate the data into X and y\n",
    "X = data[:, : len(features)]\n",
    "Y = data[:,-1]\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "# Split train test\n",
    "x_train = X[:4435, :]\n",
    "y_train = Y[:4435]\n",
    "x_test= X[4435:, :]\n",
    "y_test= Y[4435:]\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print('=================')\n",
    "\n",
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(Y)) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test)) \n",
    "\n",
    "# Check number of categories for features\n",
    "n_categories = df_dt3[features].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "156ca90e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "satimage_Knn-Hamming_DT_4.skops\n"
     ]
    }
   ],
   "source": [
    "# Load models\n",
    "model = 'Knn-Hamming'\n",
    "dataset = 'satimage'\n",
    "discretizer = 'DT'\n",
    "disc_param = 'max_depth = 4'\n",
    "\n",
    "model_name = f\"{dataset}_{model}_{discretizer}_{max_depth}.skops\"\n",
    "\n",
    "print(model_name)\n",
    "loaded_knn = sio.load(model_name, trusted=True)\n",
    "y_pred_knn = loaded_knn.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c9c9fe8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decomposition\n",
    "f = open(\"satimage_evaluation_sup_knn.txt\", \"a\")\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "loaded_knn, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "\n",
    "print(f'Evaluation result: {model}, {discretizer}, {disc_param}', file = f)\n",
    "print('Average expected loss: %.3f' % avg_expected_loss, file = f)\n",
    "print('Average bias: %.3f' % avg_bias, file = f)\n",
    "print('Average variance: %.3f' % avg_var, file = f)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_knn), file = f)\n",
    "\n",
    "end = time.time()\n",
    "print(f'Execution time {model}- default, {disc}, max_depth = {max_depth} is: {end - start}.', file = f) # Total time execution\n",
    "print('=='*20, file = f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8e9fa3",
   "metadata": {},
   "source": [
    "## DT, max_depth = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "97700667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6435 entries, 0 to 6434\n",
      "Data columns (total 37 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   A1      6435 non-null   int64\n",
      " 1   A2      6435 non-null   int64\n",
      " 2   A3      6435 non-null   int64\n",
      " 3   A4      6435 non-null   int64\n",
      " 4   A5      6435 non-null   int64\n",
      " 5   A6      6435 non-null   int64\n",
      " 6   A7      6435 non-null   int64\n",
      " 7   A8      6435 non-null   int64\n",
      " 8   A9      6435 non-null   int64\n",
      " 9   A10     6435 non-null   int64\n",
      " 10  A11     6435 non-null   int64\n",
      " 11  A12     6435 non-null   int64\n",
      " 12  A13     6435 non-null   int64\n",
      " 13  A14     6435 non-null   int64\n",
      " 14  A15     6435 non-null   int64\n",
      " 15  A16     6435 non-null   int64\n",
      " 16  A17     6435 non-null   int64\n",
      " 17  A18     6435 non-null   int64\n",
      " 18  A19     6435 non-null   int64\n",
      " 19  A20     6435 non-null   int64\n",
      " 20  A21     6435 non-null   int64\n",
      " 21  A22     6435 non-null   int64\n",
      " 22  A23     6435 non-null   int64\n",
      " 23  A24     6435 non-null   int64\n",
      " 24  A25     6435 non-null   int64\n",
      " 25  A26     6435 non-null   int64\n",
      " 26  A27     6435 non-null   int64\n",
      " 27  A28     6435 non-null   int64\n",
      " 28  A29     6435 non-null   int64\n",
      " 29  A30     6435 non-null   int64\n",
      " 30  A31     6435 non-null   int64\n",
      " 31  A32     6435 non-null   int64\n",
      " 32  A33     6435 non-null   int64\n",
      " 33  A34     6435 non-null   int64\n",
      " 34  A35     6435 non-null   int64\n",
      " 35  A36     6435 non-null   int64\n",
      " 36  label   6435 non-null   int64\n",
      "dtypes: int64(37)\n",
      "memory usage: 1.8 MB\n",
      "(6435, 36) (6435,)\n",
      "(4435, 36)\n",
      "(2000, 36)\n",
      "=================\n",
      "Class representation - original:  Counter({0: 1533, 5: 1508, 2: 1358, 4: 707, 1: 703, 3: 626})\n",
      "Class representation - training data:  Counter({5: 1064, 0: 1044, 2: 934, 1: 501, 4: 480, 3: 412})\n",
      "Class representation - testing data:  Counter({0: 489, 5: 444, 2: 424, 4: 227, 3: 214, 1: 202})\n"
     ]
    }
   ],
   "source": [
    "# Complete code for data preperation\n",
    "# Read data\n",
    "df_dt4 = pd.read_csv('DT_verylarge_discretized_satimage.csv')\n",
    "df_dt4.rename(columns={'class':'label'}, inplace=True)\n",
    "disc = 'DT'\n",
    "max_depth = 5\n",
    "\n",
    "df_dt4.info()\n",
    "data = df_dt4.values\n",
    "data.shape\n",
    "\n",
    "features = df_dt4.drop('label', axis = 1).columns\n",
    "\n",
    "# separate the data into X and y\n",
    "X = data[:, : len(features)]\n",
    "Y = data[:,-1]\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "# Split train test\n",
    "#make train test split\n",
    "x_train = X[:4435, :]\n",
    "y_train = Y[:4435]\n",
    "x_test= X[4435:, :]\n",
    "y_test= Y[4435:]\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print('=================')\n",
    "\n",
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(Y)) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test)) \n",
    "\n",
    "# Check number of categories for features\n",
    "n_categories = df_dt4[features].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "06a81319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "satimage_KNN-Hamming_DT_5.skops\n"
     ]
    }
   ],
   "source": [
    "# Load models\n",
    "model = 'KNN-Hamming'\n",
    "dataset = 'satimage'\n",
    "discretizer = 'DT'\n",
    "disc_param = 'max_depth = 5'\n",
    "\n",
    "model_name = f\"{dataset}_{model}_{discretizer}_{max_depth}.skops\"\n",
    "\n",
    "print(model_name)\n",
    "loaded_knn = sio.load(model_name, trusted=True)\n",
    "y_pred_knn = loaded_knn.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5a6a0395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decomposition\n",
    "f = open(\"satimage_evaluation_sup_knn.txt\", \"a\")\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "loaded_knn, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "\n",
    "print(f'Evaluation result: {model}, {discretizer}, {disc_param}', file = f)\n",
    "print('Average expected loss: %.3f' % avg_expected_loss, file = f)\n",
    "print('Average bias: %.3f' % avg_bias, file = f)\n",
    "print('Average variance: %.3f' % avg_var, file = f)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_knn), file = f)\n",
    "\n",
    "end = time.time()\n",
    "print(f'Execution time {model}- default, {disc}, max_depth = {max_depth} is: {end - start}.', file = f) # Total time execution\n",
    "print('=='*20, file = f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6decc5f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
