{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "514e58db",
   "metadata": {},
   "source": [
    "# Classification models\n",
    "\n",
    "Dataset: PIMA\n",
    "By: Sam\n",
    "Update at: 14/10/2022\n",
    "\n",
    "===\n",
    "\n",
    "**Summary:**\n",
    "- Import unsupervised discretised datasets (already encoded categorical attributes)\n",
    "- Split dataset: 75% training, 25% testing, seed = 30\n",
    "- SMOTE oversampling for imbalance data\n",
    "- Perform 3 classification models: ID3, Categorical Naive Bayes, Knn-VDM (long time, will do this last)\n",
    "- Bias and variance decomposition for each model (knn-VDM-long time)\n",
    "- Cross validation (accuracy): 10 folds, repeats: 3\n",
    "**NOTE**\n",
    "For categorical Naive Bayes, must pass the min_categories to avoid index out of bound error\n",
    "\n",
    "===\n",
    "\n",
    "**Result:**\n",
    "Error in bias-variance decomposition of KNN-VDM models (EWD - k =7, k = 10) and CNB model (EWD, k = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bd48a5",
   "metadata": {},
   "source": [
    "### About Dataset\n",
    "Therefore, there is one target (dependent) variable and the 8 attributes (TYNECKI, 2018): \n",
    "- pregnancies, \n",
    "- OGTT(Oral Glucose Tolerance Test), \n",
    "- blood pressure, \n",
    "- skin thickness, \n",
    "- insulin, \n",
    "- BMI(Body Mass Index), \n",
    "- age, \n",
    "- pedigree diabetes function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e959660",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "from pandas import set_option\n",
    "import numpy as np\n",
    "from numpy import arange\n",
    "## EDA\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c39986bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "# Cross validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score # 1 metric\n",
    "from sklearn.model_selection import cross_validate # more than 1 metric\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76585941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # RIPPER (https://pypi.org/project/wittgenstein/) Only for binary\n",
    "# import wittgenstein as lw "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1d3237a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Naive Bayes\n",
    "from sklearn.naive_bayes import CategoricalNB # Categorical Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB # Multinominal Naive Bayes (suitable for NLP)\n",
    "#from mixed_naive_bayes import MixedNB # Mixed Naive Bayes for combination of both discrete & continuous feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6db266fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install mlrose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e9ddea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For decision tree ID3 \n",
    "# https://stackoverflow.com/questions/61867945/python-import-error-cannot-import-name-six-from-sklearn-externals\n",
    "import six\n",
    "import sys\n",
    "sys.modules['sklearn.externals.six'] = six\n",
    "import mlrose\n",
    "from id3 import Id3Estimator # ID3 Decision Tree (https://pypi.org/project/decision-tree-id3/)\n",
    "from id3 import export_graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "039c536e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Knn-VDM 3\n",
    "from vdm3 import ValueDifferenceMetric\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65fe20aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For model evaluation\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4ec1b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb53831e",
   "metadata": {},
   "source": [
    "# 1. EWD Datasets (k = 4, 7, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97777ab9",
   "metadata": {},
   "source": [
    "## 1.1 EWD, k = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "b885f1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "df_ewd1 = pd.read_csv('pima_ewd1.csv')\n",
    "disc = 'EWD'\n",
    "k = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "0cf8fac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype\n",
      "---  ------                    --------------  -----\n",
      " 0   Pregnancies               768 non-null    int64\n",
      " 1   Glucose                   768 non-null    int64\n",
      " 2   BloodPressure             768 non-null    int64\n",
      " 3   SkinThickness             768 non-null    int64\n",
      " 4   Insulin                   768 non-null    int64\n",
      " 5   BMI                       768 non-null    int64\n",
      " 6   DiabetesPedigreeFunction  768 non-null    int64\n",
      " 7   Age                       768 non-null    int64\n",
      " 8   Outcome                   768 non-null    int64\n",
      "dtypes: int64(9)\n",
      "memory usage: 54.1 KB\n"
     ]
    }
   ],
   "source": [
    "df_ewd1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "ce78b612",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df_ewd1.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "0e2865f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pregnancies Counter({0: 492, 1: 190, 2: 72, 3: 14})\n",
      "Glucose Counter({2: 428, 1: 191, 3: 143, 0: 6})\n",
      "BloodPressure Counter({2: 571, 1: 121, 0: 38, 3: 38})\n",
      "SkinThickness Counter({0: 411, 1: 345, 2: 11, 3: 1})\n",
      "Insulin Counter({0: 693, 1: 57, 2: 15, 3: 3})\n",
      "BMI Counter({1: 439, 2: 310, 0: 11, 3: 8})\n",
      "DiabetesPedigreeFunction Counter({0: 598, 1: 145, 2: 20, 3: 5})\n",
      "Age Counter({0: 514, 1: 181, 2: 64, 3: 9})\n",
      "Outcome Counter({0: 500, 1: 268})\n"
     ]
    }
   ],
   "source": [
    "for col in cols:\n",
    "    print(col, Counter(df_ewd1[col]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9338bea5",
   "metadata": {},
   "source": [
    "#### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "a6c6f7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset\n",
    "X = df_ewd1.drop(['Outcome'], axis = 1)\n",
    "Y = df_ewd1['Outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "bb21d0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train test, test size 25%, random state 30\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3, random_state = 30, stratify = Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "d7278691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class representation - original:  Counter({0: 500, 1: 268})\n",
      "Class representation - training data:  Counter({0: 350, 1: 187})\n",
      "Class representation - testing data:  Counter({0: 150, 1: 81})\n"
     ]
    }
   ],
   "source": [
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(df_ewd1['Outcome'])) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "cf5d357d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(537, 8) (231, 8)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "66a50fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTE\n",
    "#! pip install imblearn --user\n",
    "from imblearn import under_sampling, over_sampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state = 22)\n",
    "x_train, y_train = smote.fit_resample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "4de59870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check number of categories for features\n",
    "n_categories = df_ewd1.drop(['Outcome'], axis = 1).nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "8dfa61c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies                 4\n",
       "Glucose                     4\n",
       "BloodPressure               4\n",
       "SkinThickness               4\n",
       "Insulin                     4\n",
       "BMI                         4\n",
       "DiabetesPedigreeFunction    4\n",
       "Age                         4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d98f4f",
   "metadata": {},
   "source": [
    "### Models - EWD, k=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "35b6f492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.59      0.68       150\n",
      "           1       0.49      0.73      0.59        81\n",
      "\n",
      "    accuracy                           0.64       231\n",
      "   macro avg       0.65      0.66      0.63       231\n",
      "weighted avg       0.69      0.64      0.65       231\n",
      "\n",
      "Time for training model ID3 - default, EWD, k = 4 is: 0.03110790252685547.\n"
     ]
    }
   ],
   "source": [
    "# ID3 - Default\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "model_id3 = Id3Estimator()\n",
    "model_id3.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_id3 = model_id3.predict(x_test)\n",
    "print(classification_report(y_test, y_pred_id3))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model ID3 - default, {disc}, k = {k} is: {end - start}.') # Total time execution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dfa79c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.66      0.74       150\n",
      "           1       0.56      0.79      0.65        81\n",
      "\n",
      "    accuracy                           0.71       231\n",
      "   macro avg       0.70      0.73      0.70       231\n",
      "weighted avg       0.75      0.71      0.71       231\n",
      "\n",
      "Time for training model Naive Bayes - default, EWD, k = 4 is: 0.006515026092529297.\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes - Min-categories\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "model_nb = CategoricalNB(min_categories = n_categories)\n",
    "model_nb.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_nb = model_nb.predict(x_test)\n",
    "model_nb.classes_\n",
    "print(classification_report(y_test, y_pred_nb))\n",
    "end = time.time()\n",
    "print(f'Time for training model Naive Bayes - default, {disc}, k = {k} is: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "69f7cf96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.75      0.75       150\n",
      "           1       0.54      0.56      0.55        81\n",
      "\n",
      "    accuracy                           0.68       231\n",
      "   macro avg       0.65      0.65      0.65       231\n",
      "weighted avg       0.68      0.68      0.68       231\n",
      "\n",
      "Time for training model Knn-VDM, EWD, k = 4 is: 42.19520902633667.\n"
     ]
    }
   ],
   "source": [
    "# WARNING: LONG TIME\n",
    "# Knn-VDM complete code\n",
    "# DONE\n",
    "# Time for training model Knn-VDM, EWD, k = 4 is: 42.19520902633667.\n",
    "\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "# specific the continuous columns index if any\n",
    "vdm = ValueDifferenceMetric(x_train, y_train, continuous = None)\n",
    "vdm.fit()\n",
    "# Knn model, n_neigbour = 3, metrics = vdm\n",
    "knn_vdm = KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')\n",
    "## Fit model\n",
    "knn_vdm.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_knn = knn_vdm.predict(x_test)\n",
    "knn_vdm.classes_\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model Knn-VDM, {disc}, k = {k} is: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1368a8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation result, accuracy, EWD, k = 4.\n",
      "ID3: - Mean: 0.711341, Standard deviation: 0.030314\n",
      "CNB: - Mean: nan, Standard deviation: nan\n",
      "Knn-VDM: - Mean: 0.706619, Standard deviation: 0.039965\n"
     ]
    }
   ],
   "source": [
    "# CROSS VALIDATION\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# param\n",
    "num_folds = 10\n",
    "num_repeat = 3\n",
    "seed = 7\n",
    "scores = 'accuracy'\n",
    "\n",
    "print(f'Cross validation result, {scores}, {disc}, k = {k}.')\n",
    "\n",
    "# Create list of algorithms\n",
    "models = []\n",
    "models.append(('ID3', Id3Estimator()))\n",
    "#models.append(('RIPPER', lw.RIPPER()))\n",
    "models.append(('CNB', CategoricalNB()))\n",
    "models.append(('Knn-VDM', KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')))\n",
    "\n",
    "# Evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "  #kfold = KFold(n_splits=num_folds, shuffle = True, random_state=10)\n",
    "    kfold = RepeatedKFold(n_splits=num_folds, n_repeats=num_repeat, random_state=seed)\n",
    "    cv_results = cross_val_score(model, X, Y, cv=kfold, scoring=scores)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = '%s: - Mean: %f, Standard deviation: %f' % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a312bae7",
   "metadata": {},
   "source": [
    "### Evaluation, EDW, k = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c0781b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import zero_one_loss\n",
    "#This library is used to decompose bias and variance in our models\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4ed0475d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.360\n",
      "Average bias: 0.359\n",
      "Average variance: 0.187\n",
      "Sklearn 0-1 loss: 0.359\n"
     ]
    }
   ],
   "source": [
    "# ID3\n",
    "# Convert all dataframe to array\n",
    "x_train = x_train.values\n",
    "y_train = y_train.values\n",
    "x_test = x_test.values\n",
    "y_test = y_test.values\n",
    "\n",
    "# Evaluation\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "model_id3, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_id3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3d114184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.288\n",
      "Average bias: 0.294\n",
      "Average variance: 0.054\n",
      "Sklearn 0-1 loss: 0.294\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes - min_categories update\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "model_nb, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "25175fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.340\n",
      "Average bias: 0.316\n",
      "Average variance: 0.171\n",
      "Sklearn 0-1 loss: 0.320\n",
      "Computing time: 8650.40454006195.\n"
     ]
    }
   ],
   "source": [
    "# WARNING - LONG TIME\n",
    "# Knn-VDM\n",
    "# Convert all dataframe to array\n",
    "x_train = x_train.values\n",
    "y_train = y_train.values\n",
    "x_test = x_test.values\n",
    "y_test = y_test.values\n",
    "\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "knn_vdm, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_knn))\n",
    "end = time.time()\n",
    "print(f'Computing time: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c0a4f2",
   "metadata": {},
   "source": [
    "## 1.2 EWD, k = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "a7eeb251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype\n",
      "---  ------                    --------------  -----\n",
      " 0   Pregnancies               768 non-null    int64\n",
      " 1   Glucose                   768 non-null    int64\n",
      " 2   BloodPressure             768 non-null    int64\n",
      " 3   SkinThickness             768 non-null    int64\n",
      " 4   Insulin                   768 non-null    int64\n",
      " 5   BMI                       768 non-null    int64\n",
      " 6   DiabetesPedigreeFunction  768 non-null    int64\n",
      " 7   Age                       768 non-null    int64\n",
      " 8   Outcome                   768 non-null    int64\n",
      "dtypes: int64(9)\n",
      "memory usage: 54.1 KB\n",
      "Class representation - original:  Counter({0: 500, 1: 268})\n",
      "Class representation - training data:  Counter({0: 350, 1: 187})\n",
      "Class representation - testing data:  Counter({0: 150, 1: 81})\n",
      "(537, 8) (231, 8)\n",
      "=========================\n",
      "Distribution after SMOTE\n",
      "Class representation - training data:  Counter({0: 350, 1: 350})\n",
      "(700, 8) (231, 8)\n"
     ]
    }
   ],
   "source": [
    "# Read data\n",
    "df_ewd2 = pd.read_csv('pima_ewd2.csv')\n",
    "df_ewd2.info()\n",
    "disc = \"EWD\"\n",
    "k = 7\n",
    "\n",
    "## EDA\n",
    "from collections import Counter\n",
    "\n",
    "#Check class of control\n",
    "Counter(df_ewd2['Outcome'])\n",
    "\n",
    "# Split dataset\n",
    "X = df_ewd2.drop(['Outcome'], axis = 1)\n",
    "Y = df_ewd2['Outcome']\n",
    "\n",
    "# Split train test, test size 25%, random state 30\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3, random_state = 30, stratify = Y)\n",
    "\n",
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(df_ewd2['Outcome'])) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ',Counter(y_test)) \n",
    "print(x_train.shape, x_test.shape)\n",
    "\n",
    "# SMOTE\n",
    "from imblearn import under_sampling, over_sampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state = 22)\n",
    "x_train, y_train = smote.fit_resample(x_train, y_train)\n",
    "\n",
    "print('='*25)\n",
    "print('Distribution after SMOTE')\n",
    "print('Class representation - training data: ', Counter(y_train))\n",
    "print(x_train.shape, x_test.shape)\n",
    "\n",
    "# Check number of categories for features\n",
    "n_categories = df_ewd2.drop(['Outcome'], axis = 1).nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca4903d",
   "metadata": {},
   "source": [
    "### Models, EDW, k = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e54cf9a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73       150\n",
      "           1       0.53      0.69      0.60        81\n",
      "\n",
      "    accuracy                           0.68       231\n",
      "   macro avg       0.67      0.68      0.67       231\n",
      "weighted avg       0.71      0.68      0.69       231\n",
      "\n",
      "Time for training model ID3 - default, EWD, k = 7 is: 0.04917502403259277.\n"
     ]
    }
   ],
   "source": [
    "# ID3 - Default\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "model_id3 = Id3Estimator()\n",
    "model_id3.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_id3 = model_id3.predict(x_test)\n",
    "print(classification_report(y_test, y_pred_id3))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model ID3 - default, {disc}, k = {k} is: {end - start}.') # Total time execution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "46af0176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.65      0.74       150\n",
      "           1       0.55      0.79      0.65        81\n",
      "\n",
      "    accuracy                           0.70       231\n",
      "   macro avg       0.70      0.72      0.69       231\n",
      "weighted avg       0.75      0.70      0.71       231\n",
      "\n",
      "Time for training model Naive Bayes - min_categories, EWD, k = 7 is: 0.008002758026123047.\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes - Min-categories\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "model_nb = CategoricalNB(min_categories = n_categories)\n",
    "model_nb.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_nb = model_nb.predict(x_test)\n",
    "model_nb.classes_\n",
    "print(classification_report(y_test, y_pred_nb))\n",
    "end = time.time()\n",
    "print(f'Time for training model Naive Bayes - min_categories, {disc}, k = {k} is: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ddee884c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "6.0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [40]\u001b[0m, in \u001b[0;36m<cell line: 14>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m knn_vdm\u001b[38;5;241m.\u001b[39mfit(x_train, y_train)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Testing\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m y_pred_knn \u001b[38;5;241m=\u001b[39m \u001b[43mknn_vdm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m knn_vdm\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(y_test, y_pred_knn))\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:226\u001b[0m, in \u001b[0;36mKNeighborsClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;124;03m\"\"\"Predict the class labels for the provided data.\u001b[39;00m\n\u001b[0;32m    211\u001b[0m \n\u001b[0;32m    212\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;124;03m    Class labels for each data sample.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muniform\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;66;03m# In that case, we do not need the distances to perform\u001b[39;00m\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;66;03m# the weighting so we do not compute them.\u001b[39;00m\n\u001b[1;32m--> 226\u001b[0m     neigh_ind \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkneighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    227\u001b[0m     neigh_dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py:796\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    793\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    794\u001b[0m         kwds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meffective_metric_params_\n\u001b[1;32m--> 796\u001b[0m     chunked_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpairwise_distances_chunked\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    798\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_X\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    800\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreduce_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreduce_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    801\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meffective_metric_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    802\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    803\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    804\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    805\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    807\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_method \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mball_tree\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkd_tree\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m issparse(X):\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1850\u001b[0m, in \u001b[0;36mpairwise_distances_chunked\u001b[1;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1849\u001b[0m     X_chunk \u001b[38;5;241m=\u001b[39m X[sl]\n\u001b[1;32m-> 1850\u001b[0m D_chunk \u001b[38;5;241m=\u001b[39m pairwise_distances(X_chunk, Y, metric\u001b[38;5;241m=\u001b[39mmetric, n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m   1851\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (X \u001b[38;5;129;01mis\u001b[39;00m Y \u001b[38;5;129;01mor\u001b[39;00m Y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m PAIRWISE_DISTANCE_FUNCTIONS\u001b[38;5;241m.\u001b[39mget(\n\u001b[0;32m   1852\u001b[0m     metric, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1853\u001b[0m ) \u001b[38;5;129;01mis\u001b[39;00m euclidean_distances:\n\u001b[0;32m   1854\u001b[0m     \u001b[38;5;66;03m# zeroing diagonal, taking care of aliases of \"euclidean\",\u001b[39;00m\n\u001b[0;32m   1855\u001b[0m     \u001b[38;5;66;03m# i.e. \"l2\"\u001b[39;00m\n\u001b[0;32m   1856\u001b[0m     D_chunk\u001b[38;5;241m.\u001b[39mflat[sl\u001b[38;5;241m.\u001b[39mstart :: _num_samples(X) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:2022\u001b[0m, in \u001b[0;36mpairwise_distances\u001b[1;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[0;32m   2019\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m distance\u001b[38;5;241m.\u001b[39msquareform(distance\u001b[38;5;241m.\u001b[39mpdist(X, metric\u001b[38;5;241m=\u001b[39mmetric, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds))\n\u001b[0;32m   2020\u001b[0m     func \u001b[38;5;241m=\u001b[39m partial(distance\u001b[38;5;241m.\u001b[39mcdist, metric\u001b[38;5;241m=\u001b[39mmetric, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m-> 2022\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _parallel_pairwise(X, Y, func, n_jobs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1563\u001b[0m, in \u001b[0;36m_parallel_pairwise\u001b[1;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[0;32m   1560\u001b[0m X, Y, dtype \u001b[38;5;241m=\u001b[39m _return_float_dtype(X, Y)\n\u001b[0;32m   1562\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m effective_n_jobs(n_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m-> 1563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(X, Y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m   1565\u001b[0m \u001b[38;5;66;03m# enforce a threading backend to prevent data communication overhead\u001b[39;00m\n\u001b[0;32m   1566\u001b[0m fd \u001b[38;5;241m=\u001b[39m delayed(_dist_wrapper)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1607\u001b[0m, in \u001b[0;36m_pairwise_callable\u001b[1;34m(X, Y, metric, force_all_finite, **kwds)\u001b[0m\n\u001b[0;32m   1605\u001b[0m     iterator \u001b[38;5;241m=\u001b[39m itertools\u001b[38;5;241m.\u001b[39mproduct(\u001b[38;5;28mrange\u001b[39m(X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]), \u001b[38;5;28mrange\u001b[39m(Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]))\n\u001b[0;32m   1606\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, j \u001b[38;5;129;01min\u001b[39;00m iterator:\n\u001b[1;32m-> 1607\u001b[0m         out[i, j] \u001b[38;5;241m=\u001b[39m metric(X[i], Y[j], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m   1609\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\vdm3\\vdm.py:83\u001b[0m, in \u001b[0;36mValueDifferenceMetric.get_distance\u001b[1;34m(self, ins_1, ins_2, norm)\u001b[0m\n\u001b[0;32m     80\u001b[0m     ins_1_cat \u001b[38;5;241m=\u001b[39m ins_1\n\u001b[0;32m     81\u001b[0m     ins_2_cat \u001b[38;5;241m=\u001b[39m ins_2\n\u001b[1;32m---> 83\u001b[0m cat_dist \u001b[38;5;241m=\u001b[39m \u001b[43mget_delta_nd\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcond_proba\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mins_1_cat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mins_2_cat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontinuous \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     86\u001b[0m     cont_dist \u001b[38;5;241m=\u001b[39m get_cont_dist(ins_1_cont, ins_2_cont, norm)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\vdm3\\components.py:77\u001b[0m, in \u001b[0;36mget_delta_nd\u001b[1;34m(cond_proba, ins_1, ins_2, norm)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_delta_nd\u001b[39m(cond_proba, ins_1, ins_2, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m):\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;124;03m\"\"\" get deltas for vdm for multidimensional data\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    Parameters: cond_proba (dict) - a dictionary of conditional probability, extract from get_conditional_proba_nd()\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;124;03m    Returns: deltas (array) - the delta values between ins_1 and ins_2\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 77\u001b[0m     deltas \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([get_delta(cond_proba[col], ins_1[col], ins_2[col], norm) \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m cond_proba])\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m deltas\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\vdm3\\components.py:77\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_delta_nd\u001b[39m(cond_proba, ins_1, ins_2, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m):\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;124;03m\"\"\" get deltas for vdm for multidimensional data\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    Parameters: cond_proba (dict) - a dictionary of conditional probability, extract from get_conditional_proba_nd()\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;124;03m    Returns: deltas (array) - the delta values between ins_1 and ins_2\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 77\u001b[0m     deltas \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[43mget_delta\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcond_proba\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mins_1\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mins_2\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m cond_proba])\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m deltas\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\vdm3\\components.py:51\u001b[0m, in \u001b[0;36mget_delta\u001b[1;34m(cond_proba, val_1, val_2, norm)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_delta\u001b[39m(cond_proba, val_1, val_2, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m):\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;124;03m\"\"\" get delta for vdm\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \n\u001b[0;32m     44\u001b[0m \u001b[38;5;124;03m    Parameters: cond_proba (dict) - a dictionary of conditional probability, extract from get_conditional_proba()\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;124;03m    Returns: delta (float) - the delta value for this instance\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m     proba \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;28mabs\u001b[39m(cond_proba[val_1][uni_x] \u001b[38;5;241m-\u001b[39m cond_proba[val_2][uni_x]) \u001b[38;5;28;01mfor\u001b[39;00m uni_x \u001b[38;5;129;01min\u001b[39;00m \u001b[43mcond_proba\u001b[49m\u001b[43m[\u001b[49m\u001b[43mval_1\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mindex])\n\u001b[0;32m     52\u001b[0m     delta \u001b[38;5;241m=\u001b[39m (proba\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnorm)\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m delta\n",
      "\u001b[1;31mKeyError\u001b[0m: 6.0"
     ]
    }
   ],
   "source": [
    "# WARNING: LONG TIME\n",
    "# Knn-VDM complete code\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "# specific the continuous columns index if any\n",
    "vdm = ValueDifferenceMetric(x_train, y_train, continuous = None)\n",
    "vdm.fit()\n",
    "# Knn model, n_neigbour = 3, metrics = vdm\n",
    "knn_vdm = KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')\n",
    "## Fit model\n",
    "knn_vdm.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_knn = knn_vdm.predict(x_test)\n",
    "knn_vdm.classes_\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model Knn-VDM, {disc}, k = {k} is: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7a91a181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation result, accuracy, EWD, k = 7.\n",
      "ID3: - Mean: 0.720466, Standard deviation: 0.046353\n",
      "CNB: - Mean: nan, Standard deviation: nan\n",
      "Knn-VDM: - Mean: nan, Standard deviation: nan\n"
     ]
    }
   ],
   "source": [
    "# CROSS VALIDATION\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# param\n",
    "num_folds = 10\n",
    "num_repeat = 3\n",
    "seed = 7\n",
    "scores = 'accuracy'\n",
    "\n",
    "print(f'Cross validation result, {scores}, {disc}, k = {k}.')\n",
    "\n",
    "# Create list of algorithms\n",
    "models = []\n",
    "models.append(('ID3', Id3Estimator()))\n",
    "#models.append(('RIPPER', lw.RIPPER()))\n",
    "models.append(('CNB', CategoricalNB()))\n",
    "models.append(('Knn-VDM', KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')))\n",
    "\n",
    "# Evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "  #kfold = KFold(n_splits=num_folds, shuffle = True, random_state=10)\n",
    "    kfold = RepeatedKFold(n_splits=num_folds, n_repeats=num_repeat, random_state=seed)\n",
    "    cv_results = cross_val_score(model, X, Y, cv=kfold, scoring=scores)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = '%s: - Mean: %f, Standard deviation: %f' % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c23320d",
   "metadata": {},
   "source": [
    "### Evaluation, EDW, k = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "71af30e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import zero_one_loss\n",
    "#This library is used to decompose bias and variance in our models\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8e64f104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.343\n",
      "Average bias: 0.303\n",
      "Average variance: 0.200\n",
      "Sklearn 0-1 loss: 0.320\n"
     ]
    }
   ],
   "source": [
    "# ID3\n",
    "# Convert all dataframe to array\n",
    "x_train = x_train.values\n",
    "y_train = y_train.values\n",
    "x_test = x_test.values\n",
    "y_test = y_test.values\n",
    "\n",
    "# Evaluation\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "model_id3, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_id3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "22f5104d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.302\n",
      "Average bias: 0.303\n",
      "Average variance: 0.063\n",
      "Sklearn 0-1 loss: 0.299\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes - min_categories update\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "model_nb, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "214dfacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # WARNING - LONG TIME\n",
    "# # Knn-VDM\n",
    "# import time\n",
    "# start = time.time() # For measuring time execution\n",
    "# avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "# knn_vdm, x_train, y_train, x_test, y_test,\n",
    "# loss='0-1_loss',\n",
    "# random_seed=123)\n",
    "# #---\n",
    "# print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "# print('Average bias: %.3f' % avg_bias)\n",
    "# print('Average variance: %.3f' % avg_var)\n",
    "# print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_knn))\n",
    "# end = time.time()\n",
    "# print(f'Computing time: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa5bbd8",
   "metadata": {},
   "source": [
    "## 1.3 EWD, k = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "7021ad30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype\n",
      "---  ------                    --------------  -----\n",
      " 0   Pregnancies               768 non-null    int64\n",
      " 1   Glucose                   768 non-null    int64\n",
      " 2   BloodPressure             768 non-null    int64\n",
      " 3   SkinThickness             768 non-null    int64\n",
      " 4   Insulin                   768 non-null    int64\n",
      " 5   BMI                       768 non-null    int64\n",
      " 6   DiabetesPedigreeFunction  768 non-null    int64\n",
      " 7   Age                       768 non-null    int64\n",
      " 8   Outcome                   768 non-null    int64\n",
      "dtypes: int64(9)\n",
      "memory usage: 54.1 KB\n",
      "Class representation - original:  Counter({0: 500, 1: 268})\n",
      "Class representation - training data:  Counter({0: 350, 1: 187})\n",
      "Class representation - testing data:  Counter({0: 150, 1: 81})\n",
      "(537, 8) (231, 8)\n",
      "=========================\n",
      "Distribution after SMOTE\n",
      "Class representation - training data:  Counter({0: 350, 1: 350})\n",
      "(700, 8) (231, 8)\n"
     ]
    }
   ],
   "source": [
    "# Read data\n",
    "df_ewd3 = pd.read_csv('pima_ewd3.csv')\n",
    "df_ewd3.info()\n",
    "disc = \"EWD\"\n",
    "k = 10\n",
    "\n",
    "## EDA\n",
    "from collections import Counter\n",
    "\n",
    "# Check class of control\n",
    "Counter(df_ewd3['Outcome'])\n",
    "\n",
    "# Split dataset\n",
    "X = df_ewd3.drop(['Outcome'], axis = 1)\n",
    "Y = df_ewd3['Outcome']\n",
    "\n",
    "# Split train test, test size 25%, random state 30\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3, random_state = 30, stratify = Y)\n",
    "\n",
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(df_ewd2['Outcome'])) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ',Counter(y_test)) \n",
    "print(x_train.shape, x_test.shape)\n",
    "\n",
    "# SMOTE\n",
    "from imblearn import under_sampling, over_sampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state = 22)\n",
    "x_train, y_train = smote.fit_resample(x_train, y_train)\n",
    "\n",
    "print('='*25)\n",
    "print('Distribution after SMOTE')\n",
    "print('Class representation - training data: ', Counter(y_train))\n",
    "print(x_train.shape, x_test.shape)\n",
    "\n",
    "# Check number of categories for features\n",
    "n_categories = df_ewd3.drop(['Outcome'], axis = 1).nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0678a54c",
   "metadata": {},
   "source": [
    "### Models, EDW, k = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c7fa104c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.63      0.72       150\n",
      "           1       0.53      0.79      0.64        81\n",
      "\n",
      "    accuracy                           0.68       231\n",
      "   macro avg       0.69      0.71      0.68       231\n",
      "weighted avg       0.74      0.68      0.69       231\n",
      "\n",
      "Time for training model ID3 - default, EWD, k = 10 is: 0.050779104232788086.\n"
     ]
    }
   ],
   "source": [
    "# ID3 - Default\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "model_id3 = Id3Estimator()\n",
    "model_id3.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_id3 = model_id3.predict(x_test)\n",
    "print(classification_report(y_test, y_pred_id3))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model ID3 - default, {disc}, k = {k} is: {end - start}.') # Total time execution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "20f67040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies                 10\n",
       "Glucose                      9\n",
       "BloodPressure               10\n",
       "SkinThickness                8\n",
       "Insulin                     10\n",
       "BMI                          9\n",
       "DiabetesPedigreeFunction    10\n",
       "Age                         10\n",
       "dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ff382cfd",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 9 is out of bounds for axis 1 with size 9",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [61]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m model_nb\u001b[38;5;241m.\u001b[39mfit(x_train, y_train)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Testing\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m y_pred_nb \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_nb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m model_nb\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(y_test, y_pred_nb))\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py:81\u001b[0m, in \u001b[0;36m_BaseNB.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     79\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m     80\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_X(X)\n\u001b[1;32m---> 81\u001b[0m jll \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_joint_log_likelihood\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_[np\u001b[38;5;241m.\u001b[39margmax(jll, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)]\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py:1425\u001b[0m, in \u001b[0;36mCategoricalNB._joint_log_likelihood\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1423\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_):\n\u001b[0;32m   1424\u001b[0m     indices \u001b[38;5;241m=\u001b[39m X[:, i]\n\u001b[1;32m-> 1425\u001b[0m     jll \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_log_prob_\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m   1426\u001b[0m total_ll \u001b[38;5;241m=\u001b[39m jll \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_log_prior_\n\u001b[0;32m   1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m total_ll\n",
      "\u001b[1;31mIndexError\u001b[0m: index 9 is out of bounds for axis 1 with size 9"
     ]
    }
   ],
   "source": [
    "# Naive Bayes - Min categories\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "model_nb = CategoricalNB(min_categories = n_categories)\n",
    "model_nb.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_nb = model_nb.predict(x_test)\n",
    "model_nb.classes_\n",
    "print(classification_report(y_test, y_pred_nb))\n",
    "end = time.time()\n",
    "print(f'Time for training model Naive Bayes - min_categories, {disc}, k = {k} is: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "53401c7b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "9.0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [62]\u001b[0m, in \u001b[0;36m<cell line: 14>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m knn_vdm\u001b[38;5;241m.\u001b[39mfit(x_train, y_train)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Testing\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m y_pred_knn \u001b[38;5;241m=\u001b[39m \u001b[43mknn_vdm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m knn_vdm\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(y_test, y_pred_knn))\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:226\u001b[0m, in \u001b[0;36mKNeighborsClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;124;03m\"\"\"Predict the class labels for the provided data.\u001b[39;00m\n\u001b[0;32m    211\u001b[0m \n\u001b[0;32m    212\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;124;03m    Class labels for each data sample.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muniform\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;66;03m# In that case, we do not need the distances to perform\u001b[39;00m\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;66;03m# the weighting so we do not compute them.\u001b[39;00m\n\u001b[1;32m--> 226\u001b[0m     neigh_ind \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkneighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    227\u001b[0m     neigh_dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py:796\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    793\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    794\u001b[0m         kwds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meffective_metric_params_\n\u001b[1;32m--> 796\u001b[0m     chunked_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpairwise_distances_chunked\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    798\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_X\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    800\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreduce_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreduce_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    801\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meffective_metric_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    802\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    803\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    804\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    805\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    807\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_method \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mball_tree\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkd_tree\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m issparse(X):\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1850\u001b[0m, in \u001b[0;36mpairwise_distances_chunked\u001b[1;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1849\u001b[0m     X_chunk \u001b[38;5;241m=\u001b[39m X[sl]\n\u001b[1;32m-> 1850\u001b[0m D_chunk \u001b[38;5;241m=\u001b[39m pairwise_distances(X_chunk, Y, metric\u001b[38;5;241m=\u001b[39mmetric, n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m   1851\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (X \u001b[38;5;129;01mis\u001b[39;00m Y \u001b[38;5;129;01mor\u001b[39;00m Y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m PAIRWISE_DISTANCE_FUNCTIONS\u001b[38;5;241m.\u001b[39mget(\n\u001b[0;32m   1852\u001b[0m     metric, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1853\u001b[0m ) \u001b[38;5;129;01mis\u001b[39;00m euclidean_distances:\n\u001b[0;32m   1854\u001b[0m     \u001b[38;5;66;03m# zeroing diagonal, taking care of aliases of \"euclidean\",\u001b[39;00m\n\u001b[0;32m   1855\u001b[0m     \u001b[38;5;66;03m# i.e. \"l2\"\u001b[39;00m\n\u001b[0;32m   1856\u001b[0m     D_chunk\u001b[38;5;241m.\u001b[39mflat[sl\u001b[38;5;241m.\u001b[39mstart :: _num_samples(X) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:2022\u001b[0m, in \u001b[0;36mpairwise_distances\u001b[1;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[0;32m   2019\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m distance\u001b[38;5;241m.\u001b[39msquareform(distance\u001b[38;5;241m.\u001b[39mpdist(X, metric\u001b[38;5;241m=\u001b[39mmetric, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds))\n\u001b[0;32m   2020\u001b[0m     func \u001b[38;5;241m=\u001b[39m partial(distance\u001b[38;5;241m.\u001b[39mcdist, metric\u001b[38;5;241m=\u001b[39mmetric, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m-> 2022\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _parallel_pairwise(X, Y, func, n_jobs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1563\u001b[0m, in \u001b[0;36m_parallel_pairwise\u001b[1;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[0;32m   1560\u001b[0m X, Y, dtype \u001b[38;5;241m=\u001b[39m _return_float_dtype(X, Y)\n\u001b[0;32m   1562\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m effective_n_jobs(n_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m-> 1563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(X, Y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m   1565\u001b[0m \u001b[38;5;66;03m# enforce a threading backend to prevent data communication overhead\u001b[39;00m\n\u001b[0;32m   1566\u001b[0m fd \u001b[38;5;241m=\u001b[39m delayed(_dist_wrapper)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1607\u001b[0m, in \u001b[0;36m_pairwise_callable\u001b[1;34m(X, Y, metric, force_all_finite, **kwds)\u001b[0m\n\u001b[0;32m   1605\u001b[0m     iterator \u001b[38;5;241m=\u001b[39m itertools\u001b[38;5;241m.\u001b[39mproduct(\u001b[38;5;28mrange\u001b[39m(X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]), \u001b[38;5;28mrange\u001b[39m(Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]))\n\u001b[0;32m   1606\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, j \u001b[38;5;129;01min\u001b[39;00m iterator:\n\u001b[1;32m-> 1607\u001b[0m         out[i, j] \u001b[38;5;241m=\u001b[39m metric(X[i], Y[j], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m   1609\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\vdm3\\vdm.py:83\u001b[0m, in \u001b[0;36mValueDifferenceMetric.get_distance\u001b[1;34m(self, ins_1, ins_2, norm)\u001b[0m\n\u001b[0;32m     80\u001b[0m     ins_1_cat \u001b[38;5;241m=\u001b[39m ins_1\n\u001b[0;32m     81\u001b[0m     ins_2_cat \u001b[38;5;241m=\u001b[39m ins_2\n\u001b[1;32m---> 83\u001b[0m cat_dist \u001b[38;5;241m=\u001b[39m \u001b[43mget_delta_nd\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcond_proba\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mins_1_cat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mins_2_cat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontinuous \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     86\u001b[0m     cont_dist \u001b[38;5;241m=\u001b[39m get_cont_dist(ins_1_cont, ins_2_cont, norm)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\vdm3\\components.py:77\u001b[0m, in \u001b[0;36mget_delta_nd\u001b[1;34m(cond_proba, ins_1, ins_2, norm)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_delta_nd\u001b[39m(cond_proba, ins_1, ins_2, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m):\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;124;03m\"\"\" get deltas for vdm for multidimensional data\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    Parameters: cond_proba (dict) - a dictionary of conditional probability, extract from get_conditional_proba_nd()\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;124;03m    Returns: deltas (array) - the delta values between ins_1 and ins_2\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 77\u001b[0m     deltas \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([get_delta(cond_proba[col], ins_1[col], ins_2[col], norm) \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m cond_proba])\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m deltas\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\vdm3\\components.py:77\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_delta_nd\u001b[39m(cond_proba, ins_1, ins_2, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m):\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;124;03m\"\"\" get deltas for vdm for multidimensional data\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    Parameters: cond_proba (dict) - a dictionary of conditional probability, extract from get_conditional_proba_nd()\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;124;03m    Returns: deltas (array) - the delta values between ins_1 and ins_2\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 77\u001b[0m     deltas \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[43mget_delta\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcond_proba\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mins_1\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mins_2\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m cond_proba])\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m deltas\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\vdm3\\components.py:51\u001b[0m, in \u001b[0;36mget_delta\u001b[1;34m(cond_proba, val_1, val_2, norm)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_delta\u001b[39m(cond_proba, val_1, val_2, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m):\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;124;03m\"\"\" get delta for vdm\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \n\u001b[0;32m     44\u001b[0m \u001b[38;5;124;03m    Parameters: cond_proba (dict) - a dictionary of conditional probability, extract from get_conditional_proba()\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;124;03m    Returns: delta (float) - the delta value for this instance\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m     proba \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;28mabs\u001b[39m(cond_proba[val_1][uni_x] \u001b[38;5;241m-\u001b[39m cond_proba[val_2][uni_x]) \u001b[38;5;28;01mfor\u001b[39;00m uni_x \u001b[38;5;129;01min\u001b[39;00m \u001b[43mcond_proba\u001b[49m\u001b[43m[\u001b[49m\u001b[43mval_1\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mindex])\n\u001b[0;32m     52\u001b[0m     delta \u001b[38;5;241m=\u001b[39m (proba\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnorm)\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m delta\n",
      "\u001b[1;31mKeyError\u001b[0m: 9.0"
     ]
    }
   ],
   "source": [
    "# WARNING: LONG TIME\n",
    "# Knn-VDM complete code\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "# specific the continuous columns index if any\n",
    "vdm = ValueDifferenceMetric(x_train, y_train, continuous = None)\n",
    "vdm.fit()\n",
    "# Knn model, n_neigbour = 3, metrics = vdm\n",
    "knn_vdm = KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')\n",
    "## Fit model\n",
    "knn_vdm.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_knn = knn_vdm.predict(x_test)\n",
    "knn_vdm.classes_\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model Knn-VDM, {disc}, k = {k} is: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d8637b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation result, accuracy, EWD, k = 10.\n",
      "ID3: - Mean: 0.728788, Standard deviation: 0.039028\n",
      "CNB: - Mean: nan, Standard deviation: nan\n",
      "Knn-VDM: - Mean: nan, Standard deviation: nan\n"
     ]
    }
   ],
   "source": [
    "# CROSS VALIDATION\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# param\n",
    "num_folds = 10\n",
    "num_repeat = 3\n",
    "seed = 7\n",
    "scores = 'accuracy'\n",
    "\n",
    "print(f'Cross validation result, {scores}, {disc}, k = {k}.')\n",
    "\n",
    "# Create list of algorithms\n",
    "models = []\n",
    "models.append(('ID3', Id3Estimator()))\n",
    "#models.append(('RIPPER', lw.RIPPER()))\n",
    "models.append(('CNB', CategoricalNB()))\n",
    "models.append(('Knn-VDM', KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')))\n",
    "\n",
    "# Evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "  #kfold = KFold(n_splits=num_folds, shuffle = True, random_state=10)\n",
    "    kfold = RepeatedKFold(n_splits=num_folds, n_repeats=num_repeat, random_state=seed)\n",
    "    cv_results = cross_val_score(model, X, Y, cv=kfold, scoring=scores)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = '%s: - Mean: %f, Standard deviation: %f' % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4e5585",
   "metadata": {},
   "source": [
    "### Evaluation, EDW, k = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6c9b52c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import zero_one_loss\n",
    "#This library is used to decompose bias and variance in our models\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4a0df578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.337\n",
      "Average bias: 0.312\n",
      "Average variance: 0.176\n",
      "Sklearn 0-1 loss: 0.316\n"
     ]
    }
   ],
   "source": [
    "# ID3\n",
    "# Convert all dataframe to array\n",
    "x_train = x_train.values\n",
    "y_train = y_train.values\n",
    "x_test = x_test.values\n",
    "y_test = y_test.values\n",
    "\n",
    "# Evaluation\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "model_id3, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_id3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c24f9dd0",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 9 is out of bounds for axis 1 with size 9",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [66]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Naive Bayes - min_categories update\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m avg_expected_loss, avg_bias, avg_var \u001b[38;5;241m=\u001b[39m \u001b[43mbias_variance_decomp\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43mmodel_nb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m0-1_loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m123\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#---\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAverage expected loss: \u001b[39m\u001b[38;5;132;01m%.3f\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m avg_expected_loss)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\mlxtend\\evaluate\\bias_variance_decomp.py:131\u001b[0m, in \u001b[0;36mbias_variance_decomp\u001b[1;34m(estimator, X_train, y_train, X_test, y_test, loss, num_rounds, random_seed, **fit_params)\u001b[0m\n\u001b[0;32m    129\u001b[0m         pred \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mpredict(X_test)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 131\u001b[0m         pred \u001b[38;5;241m=\u001b[39m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_boot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_boot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    132\u001b[0m     all_pred[i] \u001b[38;5;241m=\u001b[39m pred\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loss \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0-1_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py:81\u001b[0m, in \u001b[0;36m_BaseNB.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     79\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m     80\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_X(X)\n\u001b[1;32m---> 81\u001b[0m jll \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_joint_log_likelihood\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_[np\u001b[38;5;241m.\u001b[39margmax(jll, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)]\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py:1425\u001b[0m, in \u001b[0;36mCategoricalNB._joint_log_likelihood\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1423\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_):\n\u001b[0;32m   1424\u001b[0m     indices \u001b[38;5;241m=\u001b[39m X[:, i]\n\u001b[1;32m-> 1425\u001b[0m     jll \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_log_prob_\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m   1426\u001b[0m total_ll \u001b[38;5;241m=\u001b[39m jll \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_log_prior_\n\u001b[0;32m   1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m total_ll\n",
      "\u001b[1;31mIndexError\u001b[0m: index 9 is out of bounds for axis 1 with size 9"
     ]
    }
   ],
   "source": [
    "# Naive Bayes - min_categories update\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "model_nb, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9bca0eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # WARNING - LONG TIME\n",
    "# # Knn-VDM\n",
    "# import time\n",
    "# start = time.time() # For measuring time execution\n",
    "# avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "# knn_vdm, x_train, y_train, x_test, y_test,\n",
    "# loss='0-1_loss',\n",
    "# random_seed=123)\n",
    "# #---\n",
    "# print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "# print('Average bias: %.3f' % avg_bias)\n",
    "# print('Average variance: %.3f' % avg_var)\n",
    "# print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_knn))\n",
    "# end = time.time()\n",
    "# print(f'Computing time: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc73dbb8",
   "metadata": {},
   "source": [
    "# 2. EFD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e0ab18",
   "metadata": {},
   "source": [
    "## 2.1 EFD, k = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "a605fdbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype\n",
      "---  ------                    --------------  -----\n",
      " 0   Pregnancies               768 non-null    int64\n",
      " 1   Glucose                   768 non-null    int64\n",
      " 2   BloodPressure             768 non-null    int64\n",
      " 3   SkinThickness             768 non-null    int64\n",
      " 4   Insulin                   768 non-null    int64\n",
      " 5   BMI                       768 non-null    int64\n",
      " 6   DiabetesPedigreeFunction  768 non-null    int64\n",
      " 7   Age                       768 non-null    int64\n",
      " 8   Outcome                   768 non-null    int64\n",
      "dtypes: int64(9)\n",
      "memory usage: 54.1 KB\n",
      "Class representation - original:  Counter({0: 500, 1: 268})\n",
      "Class representation - training data:  Counter({0: 350, 1: 187})\n",
      "Class representation - testing data:  Counter({0: 150, 1: 81})\n",
      "(537, 8) (231, 8)\n",
      "=========================\n",
      "Distribution after SMOTE\n",
      "Class representation - training data:  Counter({0: 350, 1: 350})\n",
      "(700, 8) (231, 8)\n"
     ]
    }
   ],
   "source": [
    "# Read data\n",
    "df_efd1 = pd.read_csv('pima_efd1.csv')\n",
    "df_efd1.info()\n",
    "disc = \"EFD\"\n",
    "k = 4\n",
    "\n",
    "## EDA\n",
    "from collections import Counter\n",
    "\n",
    "# Check class of control\n",
    "Counter(df_efd1['Outcome'])\n",
    "\n",
    "# Split dataset\n",
    "X = df_efd1.drop(['Outcome'], axis = 1)\n",
    "Y = df_efd1['Outcome']\n",
    "\n",
    "# Split train test, test size 25%, random state 30\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3, random_state = 30, stratify = Y)\n",
    "\n",
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(df_ewd2['Outcome'])) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ',Counter(y_test)) \n",
    "print(x_train.shape, x_test.shape)\n",
    "\n",
    "# SMOTE\n",
    "from imblearn import under_sampling, over_sampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state = 22)\n",
    "x_train, y_train = smote.fit_resample(x_train, y_train)\n",
    "\n",
    "print('='*25)\n",
    "print('Distribution after SMOTE')\n",
    "print('Class representation - training data: ', Counter(y_train))\n",
    "print(x_train.shape, x_test.shape)\n",
    "\n",
    "# Check number of categories for features\n",
    "n_categories = df_efd1.drop(['Outcome'], axis = 1).nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83857d2b",
   "metadata": {},
   "source": [
    "### Models, EFD, k = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7ed63023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.67      0.71       150\n",
      "           1       0.50      0.63      0.56        81\n",
      "\n",
      "    accuracy                           0.65       231\n",
      "   macro avg       0.64      0.65      0.64       231\n",
      "weighted avg       0.68      0.65      0.66       231\n",
      "\n",
      "Time for training model ID3 - default, EFD, k = 4 is: 0.04825234413146973.\n"
     ]
    }
   ],
   "source": [
    "# ID3 - Default\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "model_id3 = Id3Estimator()\n",
    "model_id3.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_id3 = model_id3.predict(x_test)\n",
    "print(classification_report(y_test, y_pred_id3))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model ID3 - default, {disc}, k = {k} is: {end - start}.') # Total time execution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e0b3927d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.63      0.73       150\n",
      "           1       0.54      0.79      0.64        81\n",
      "\n",
      "    accuracy                           0.69       231\n",
      "   macro avg       0.69      0.71      0.68       231\n",
      "weighted avg       0.74      0.69      0.70       231\n",
      "\n",
      "Time for training model Naive Bayes - min_categories, EFD, k = 4 is: 0.00800013542175293.\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes - min_categories\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "model_nb = CategoricalNB(min_categories = n_categories)\n",
    "model_nb.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_nb = model_nb.predict(x_test)\n",
    "model_nb.classes_\n",
    "print(classification_report(y_test, y_pred_nb))\n",
    "end = time.time()\n",
    "print(f'Time for training model Naive Bayes - min_categories, {disc}, k = {k} is: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "a4b3c48d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.69      0.74       150\n",
      "           1       0.54      0.68      0.60        81\n",
      "\n",
      "    accuracy                           0.68       231\n",
      "   macro avg       0.67      0.68      0.67       231\n",
      "weighted avg       0.71      0.68      0.69       231\n",
      "\n",
      "Time for training model Knn-VDM, EFD, k = 4 is: 42.62577247619629.\n"
     ]
    }
   ],
   "source": [
    "# WARNING: LONG TIME\n",
    "# Knn-VDM complete code\n",
    "# Time for training model Knn-VDM, EFD, k = 4 is: 43.78280520439148.\n",
    "# Acc: 0.68\n",
    "\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "# specific the continuous columns index if any\n",
    "vdm = ValueDifferenceMetric(x_train, y_train, continuous = None)\n",
    "vdm.fit()\n",
    "# Knn model, n_neigbour = 3, metrics = vdm\n",
    "knn_vdm = KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')\n",
    "## Fit model\n",
    "knn_vdm.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_knn = knn_vdm.predict(x_test)\n",
    "knn_vdm.classes_\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model Knn-VDM, {disc}, k = {k} is: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2b829b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation result, accuracy, EFD, k = 4.\n",
      "ID3: - Mean: 0.701771, Standard deviation: 0.040627\n",
      "CNB: - Mean: 0.753890, Standard deviation: 0.050901\n",
      "Knn-VDM: - Mean: 0.720044, Standard deviation: 0.049140\n"
     ]
    }
   ],
   "source": [
    "# CROSS VALIDATION\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# param\n",
    "num_folds = 10\n",
    "num_repeat = 3\n",
    "seed = 7\n",
    "scores = 'accuracy'\n",
    "\n",
    "print(f'Cross validation result, {scores}, {disc}, k = {k}.')\n",
    "\n",
    "# Create list of algorithms\n",
    "models = []\n",
    "models.append(('ID3', Id3Estimator()))\n",
    "#models.append(('RIPPER', lw.RIPPER()))\n",
    "models.append(('CNB', CategoricalNB()))\n",
    "models.append(('Knn-VDM', KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')))\n",
    "\n",
    "# Evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "  #kfold = KFold(n_splits=num_folds, shuffle = True, random_state=10)\n",
    "    kfold = RepeatedKFold(n_splits=num_folds, n_repeats=num_repeat, random_state=seed)\n",
    "    cv_results = cross_val_score(model, X, Y, cv=kfold, scoring=scores)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = '%s: - Mean: %f, Standard deviation: %f' % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e7ea01",
   "metadata": {},
   "source": [
    "### Evaluation, EFD, k = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e60b09a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import zero_one_loss\n",
    "#This library is used to decompose bias and variance in our models\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "53a0d96d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.347\n",
      "Average bias: 0.307\n",
      "Average variance: 0.185\n",
      "Sklearn 0-1 loss: 0.346\n"
     ]
    }
   ],
   "source": [
    "# ID3\n",
    "# Convert all dataframe to array\n",
    "x_train = x_train.values\n",
    "y_train = y_train.values\n",
    "x_test = x_test.values\n",
    "y_test = y_test.values\n",
    "\n",
    "# Evaluation\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "model_id3, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_id3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2561fba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.311\n",
      "Average bias: 0.316\n",
      "Average variance: 0.064\n",
      "Sklearn 0-1 loss: 0.312\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes - min_categories update\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "model_nb, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "c2fac9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.328\n",
      "Average bias: 0.307\n",
      "Average variance: 0.155\n",
      "Sklearn 0-1 loss: 0.316\n",
      "Computing time: 8415.077355861664.\n"
     ]
    }
   ],
   "source": [
    "# WARNING - LONG TIME\n",
    "# Knn-VDM\n",
    "# Convert all dataframe to array\n",
    "x_train = x_train.values\n",
    "y_train = y_train.values\n",
    "x_test = x_test.values\n",
    "y_test = y_test.values\n",
    "\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "knn_vdm, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_knn))\n",
    "end = time.time()\n",
    "print(f'Computing time: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927b824b",
   "metadata": {},
   "source": [
    "## 2.2 EFD, k = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "7066773a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype\n",
      "---  ------                    --------------  -----\n",
      " 0   Pregnancies               768 non-null    int64\n",
      " 1   Glucose                   768 non-null    int64\n",
      " 2   BloodPressure             768 non-null    int64\n",
      " 3   SkinThickness             768 non-null    int64\n",
      " 4   Insulin                   768 non-null    int64\n",
      " 5   BMI                       768 non-null    int64\n",
      " 6   DiabetesPedigreeFunction  768 non-null    int64\n",
      " 7   Age                       768 non-null    int64\n",
      " 8   Outcome                   768 non-null    int64\n",
      "dtypes: int64(9)\n",
      "memory usage: 54.1 KB\n",
      "Class representation - original:  Counter({0: 500, 1: 268})\n",
      "Class representation - training data:  Counter({0: 350, 1: 187})\n",
      "Class representation - testing data:  Counter({0: 150, 1: 81})\n",
      "(537, 8) (231, 8)\n",
      "=========================\n",
      "Distribution after SMOTE\n",
      "Class representation - training data:  Counter({0: 350, 1: 350})\n",
      "(700, 8) (231, 8)\n"
     ]
    }
   ],
   "source": [
    "# Read data\n",
    "df_efd2 = pd.read_csv('pima_efd2.csv')\n",
    "df_efd2.info()\n",
    "disc = \"EFD\"\n",
    "k = 7\n",
    "\n",
    "## EDA\n",
    "from collections import Counter\n",
    "\n",
    "# Check class of control\n",
    "Counter(df_efd2['Outcome'])\n",
    "\n",
    "# Split dataset\n",
    "X = df_efd2.drop(['Outcome'], axis = 1)\n",
    "Y = df_efd2['Outcome']\n",
    "\n",
    "# Split train test, test size 25%, random state 30\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3, random_state = 30, stratify = Y)\n",
    "\n",
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(df_ewd2['Outcome'])) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ',Counter(y_test)) \n",
    "print(x_train.shape, x_test.shape)\n",
    "\n",
    "# SMOTE\n",
    "from imblearn import under_sampling, over_sampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state = 22)\n",
    "x_train, y_train = smote.fit_resample(x_train, y_train)\n",
    "\n",
    "print('='*25)\n",
    "print('Distribution after SMOTE')\n",
    "print('Class representation - training data: ', Counter(y_train))\n",
    "print(x_train.shape, x_test.shape)\n",
    "\n",
    "# Check number of categories for features\n",
    "n_categories = df_efd2.drop(['Outcome'], axis = 1).nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb03789",
   "metadata": {},
   "source": [
    "### Models, EFD, k = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "01ec1e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.67      0.72       150\n",
      "           1       0.51      0.62      0.56        81\n",
      "\n",
      "    accuracy                           0.65       231\n",
      "   macro avg       0.64      0.65      0.64       231\n",
      "weighted avg       0.67      0.65      0.66       231\n",
      "\n",
      "Time for training model ID3 - default, EFD, k = 7 is: 0.07412123680114746.\n"
     ]
    }
   ],
   "source": [
    "# ID3 - Default\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "model_id3 = Id3Estimator()\n",
    "model_id3.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_id3 = model_id3.predict(x_test)\n",
    "print(classification_report(y_test, y_pred_id3))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model ID3 - default, {disc}, k = {k} is: {end - start}.') # Total time execution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c6dea466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.65      0.75       150\n",
      "           1       0.57      0.85      0.68        81\n",
      "\n",
      "    accuracy                           0.72       231\n",
      "   macro avg       0.73      0.75      0.72       231\n",
      "weighted avg       0.78      0.72      0.73       231\n",
      "\n",
      "Time for training model Naive Bayes - min_categories, EFD, k = 7 is: 0.008295536041259766.\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes - min_categories\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "model_nb = CategoricalNB(min_categories = n_categories)\n",
    "model_nb.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_nb = model_nb.predict(x_test)\n",
    "model_nb.classes_\n",
    "print(classification_report(y_test, y_pred_nb))\n",
    "end = time.time()\n",
    "print(f'Time for training model Naive Bayes - min_categories, {disc}, k = {k} is: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "945b9e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.69      0.75       150\n",
      "           1       0.56      0.73      0.63        81\n",
      "\n",
      "    accuracy                           0.70       231\n",
      "   macro avg       0.69      0.71      0.69       231\n",
      "weighted avg       0.73      0.70      0.71       231\n",
      "\n",
      "Time for training model Knn-VDM, EFD, k = 7 is: 40.350417375564575.\n"
     ]
    }
   ],
   "source": [
    "# WARNING: LONG TIME\n",
    "# Knn-VDM complete code\n",
    "# DONE\n",
    "# Acc: 0.70\n",
    "# Time for training model Knn-VDM, EFD, k = 7 is: 47.48977565765381.\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "# specific the continuous columns index if any\n",
    "vdm = ValueDifferenceMetric(x_train, y_train, continuous = None)\n",
    "vdm.fit()\n",
    "# Knn model, n_neigbour = 3, metrics = vdm\n",
    "knn_vdm = KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')\n",
    "## Fit model\n",
    "knn_vdm.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_knn = knn_vdm.predict(x_test)\n",
    "knn_vdm.classes_\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model Knn-VDM, {disc}, k = {k} is: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fa8859d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation result, accuracy, EFD, k = 7.\n",
      "ID3: - Mean: 0.708276, Standard deviation: 0.042404\n",
      "CNB: - Mean: 0.756072, Standard deviation: 0.050855\n",
      "Knn-VDM: - Mean: 0.739907, Standard deviation: 0.049102\n"
     ]
    }
   ],
   "source": [
    "# CROSS VALIDATION\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# param\n",
    "num_folds = 10\n",
    "num_repeat = 3\n",
    "seed = 7\n",
    "scores = 'accuracy'\n",
    "\n",
    "print(f'Cross validation result, {scores}, {disc}, k = {k}.')\n",
    "\n",
    "# Create list of algorithms\n",
    "models = []\n",
    "models.append(('ID3', Id3Estimator()))\n",
    "#models.append(('RIPPER', lw.RIPPER()))\n",
    "models.append(('CNB', CategoricalNB()))\n",
    "models.append(('Knn-VDM', KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')))\n",
    "\n",
    "# Evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "  #kfold = KFold(n_splits=num_folds, shuffle = True, random_state=10)\n",
    "    kfold = RepeatedKFold(n_splits=num_folds, n_repeats=num_repeat, random_state=seed)\n",
    "    cv_results = cross_val_score(model, X, Y, cv=kfold, scoring=scores)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = '%s: - Mean: %f, Standard deviation: %f' % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a535e6",
   "metadata": {},
   "source": [
    "### Evaluation, EFD, k = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2369c1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import zero_one_loss\n",
    "#This library is used to decompose bias and variance in our models\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "727a8c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.341\n",
      "Average bias: 0.307\n",
      "Average variance: 0.194\n",
      "Sklearn 0-1 loss: 0.346\n"
     ]
    }
   ],
   "source": [
    "# ID3\n",
    "# Convert all dataframe to array\n",
    "x_train = x_train.values\n",
    "y_train = y_train.values\n",
    "x_test = x_test.values\n",
    "y_test = y_test.values\n",
    "\n",
    "# Evaluation\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "model_id3, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_id3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3a0b06b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.293\n",
      "Average bias: 0.277\n",
      "Average variance: 0.074\n",
      "Sklearn 0-1 loss: 0.277\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes - min_categories update\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "model_nb, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "89c447a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.294\n",
      "Average bias: 0.286\n",
      "Average variance: 0.134\n",
      "Sklearn 0-1 loss: 0.299\n",
      "Computing time: 8662.829064846039.\n"
     ]
    }
   ],
   "source": [
    "# WARNING - LONG TIME\n",
    "# Knn-VDM\n",
    "# Convert all dataframe to array\n",
    "x_train = x_train.values\n",
    "y_train = y_train.values\n",
    "x_test = x_test.values\n",
    "y_test = y_test.values\n",
    "\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "knn_vdm, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_knn))\n",
    "end = time.time()\n",
    "print(f'Computing time: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98edc4d0",
   "metadata": {},
   "source": [
    "## 2.3 EFD, k =10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "cdeefecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype\n",
      "---  ------                    --------------  -----\n",
      " 0   Pregnancies               768 non-null    int64\n",
      " 1   Glucose                   768 non-null    int64\n",
      " 2   BloodPressure             768 non-null    int64\n",
      " 3   SkinThickness             768 non-null    int64\n",
      " 4   Insulin                   768 non-null    int64\n",
      " 5   BMI                       768 non-null    int64\n",
      " 6   DiabetesPedigreeFunction  768 non-null    int64\n",
      " 7   Age                       768 non-null    int64\n",
      " 8   Outcome                   768 non-null    int64\n",
      "dtypes: int64(9)\n",
      "memory usage: 54.1 KB\n",
      "Class representation - original:  Counter({0: 500, 1: 268})\n",
      "Class representation - training data:  Counter({0: 350, 1: 187})\n",
      "Class representation - testing data:  Counter({0: 150, 1: 81})\n",
      "(537, 8) (231, 8)\n",
      "=========================\n",
      "Distribution after SMOTE\n",
      "Class representation - training data:  Counter({0: 350, 1: 350})\n",
      "(700, 8) (231, 8)\n"
     ]
    }
   ],
   "source": [
    "# Read data\n",
    "df_efd3 = pd.read_csv('pima_efd3.csv')\n",
    "df_efd3.info()\n",
    "disc = \"EFD\"\n",
    "k = 10\n",
    "\n",
    "## EDA\n",
    "from collections import Counter\n",
    "\n",
    "# Check class of control\n",
    "Counter(df_efd3['Outcome'])\n",
    "\n",
    "# Split dataset\n",
    "X = df_efd3.drop(['Outcome'], axis = 1)\n",
    "Y = df_efd3['Outcome']\n",
    "\n",
    "# Split train test, test size 25%, random state 30\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3, random_state = 30, stratify = Y)\n",
    "\n",
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(df_ewd2['Outcome'])) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ',Counter(y_test)) \n",
    "print(x_train.shape, x_test.shape)\n",
    "\n",
    "# SMOTE\n",
    "from imblearn import under_sampling, over_sampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state = 22)\n",
    "x_train, y_train = smote.fit_resample(x_train, y_train)\n",
    "\n",
    "print('='*25)\n",
    "print('Distribution after SMOTE')\n",
    "print('Class representation - training data: ', Counter(y_train))\n",
    "print(x_train.shape, x_test.shape)\n",
    "\n",
    "# Check number of categories for features\n",
    "n_categories = df_efd3.drop(['Outcome'], axis = 1).nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb3a6ef",
   "metadata": {},
   "source": [
    "### Models, EFD, k = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "eb962731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.63      0.70       150\n",
      "           1       0.50      0.69      0.58        81\n",
      "\n",
      "    accuracy                           0.65       231\n",
      "   macro avg       0.64      0.66      0.64       231\n",
      "weighted avg       0.69      0.65      0.66       231\n",
      "\n",
      "Time for training model ID3 - default, EFD, k = 10 is: 0.08085155487060547.\n"
     ]
    }
   ],
   "source": [
    "# ID3 - Default\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "model_id3 = Id3Estimator()\n",
    "model_id3.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_id3 = model_id3.predict(x_test)\n",
    "print(classification_report(y_test, y_pred_id3))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model ID3 - default, {disc}, k = {k} is: {end - start}.') # Total time execution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4940e501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.65      0.74       150\n",
      "           1       0.55      0.80      0.65        81\n",
      "\n",
      "    accuracy                           0.70       231\n",
      "   macro avg       0.70      0.72      0.70       231\n",
      "weighted avg       0.75      0.70      0.71       231\n",
      "\n",
      "Time for training model Naive Bayes - min_categories, EFD, k = 10 is: 0.010376214981079102.\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes - min_catgories\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "model_nb = CategoricalNB(min_categories = n_categories)\n",
    "model_nb.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_nb = model_nb.predict(x_test)\n",
    "model_nb.classes_\n",
    "print(classification_report(y_test, y_pred_nb))\n",
    "end = time.time()\n",
    "print(f'Time for training model Naive Bayes - min_categories, {disc}, k = {k} is: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "327d4d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.67      0.75       150\n",
      "           1       0.56      0.79      0.66        81\n",
      "\n",
      "    accuracy                           0.71       231\n",
      "   macro avg       0.71      0.73      0.70       231\n",
      "weighted avg       0.75      0.71      0.72       231\n",
      "\n",
      "Time for training model Knn-VDM, EFD, k = 10 is: 45.19051241874695.\n"
     ]
    }
   ],
   "source": [
    "# WARNING: LONG TIME\n",
    "# Knn-VDM complete code\n",
    "# Time for training model Knn-VDM, EFD, k = 10 is: 49.08341908454895.\n",
    "# Acc: 0.71\n",
    "\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "# specific the continuous columns index if any\n",
    "vdm = ValueDifferenceMetric(x_train, y_train, continuous = None)\n",
    "vdm.fit()\n",
    "# Knn model, n_neigbour = 3, metrics = vdm\n",
    "knn_vdm = KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')\n",
    "## Fit model\n",
    "knn_vdm.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_knn = knn_vdm.predict(x_test)\n",
    "knn_vdm.classes_\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model Knn-VDM, {disc}, k = {k} is: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3cbd2df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation result, accuracy, EFD, k = 10.\n",
      "ID3: - Mean: 0.694025, Standard deviation: 0.057013\n",
      "CNB: - Mean: 0.743467, Standard deviation: 0.044930\n",
      "Knn-VDM: - Mean: 0.747357, Standard deviation: 0.038183\n"
     ]
    }
   ],
   "source": [
    "# CROSS VALIDATION\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# param\n",
    "num_folds = 10\n",
    "num_repeat = 3\n",
    "seed = 7\n",
    "scores = 'accuracy'\n",
    "\n",
    "print(f'Cross validation result, {scores}, {disc}, k = {k}.')\n",
    "\n",
    "# Create list of algorithms\n",
    "models = []\n",
    "models.append(('ID3', Id3Estimator()))\n",
    "#models.append(('RIPPER', lw.RIPPER()))\n",
    "models.append(('CNB', CategoricalNB()))\n",
    "models.append(('Knn-VDM', KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')))\n",
    "\n",
    "# Evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "  #kfold = KFold(n_splits=num_folds, shuffle = True, random_state=10)\n",
    "    kfold = RepeatedKFold(n_splits=num_folds, n_repeats=num_repeat, random_state=seed)\n",
    "    cv_results = cross_val_score(model, X, Y, cv=kfold, scoring=scores)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = '%s: - Mean: %f, Standard deviation: %f' % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f38300d",
   "metadata": {},
   "source": [
    "### Evaluation, EFD, k = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "22a6beb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import zero_one_loss\n",
    "#This library is used to decompose bias and variance in our models\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a0ab225d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.348\n",
      "Average bias: 0.320\n",
      "Average variance: 0.204\n",
      "Sklearn 0-1 loss: 0.351\n"
     ]
    }
   ],
   "source": [
    "# ID3\n",
    "# Convert all dataframe to array\n",
    "x_train = x_train.values\n",
    "y_train = y_train.values\n",
    "x_test = x_test.values\n",
    "y_test = y_test.values\n",
    "\n",
    "# Evaluation\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "model_id3, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_id3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8af5f5e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.309\n",
      "Average bias: 0.294\n",
      "Average variance: 0.083\n",
      "Sklearn 0-1 loss: 0.299\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes - min_categories update\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "model_nb, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "805c4502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.328\n",
      "Average bias: 0.290\n",
      "Average variance: 0.128\n",
      "Sklearn 0-1 loss: 0.290\n",
      "Computing time: 8546.075377464294.\n"
     ]
    }
   ],
   "source": [
    "# WARNING - LONG TIME\n",
    "# Knn-VDM\n",
    "# Convert all dataframe to array\n",
    "x_train = x_train.values\n",
    "y_train = y_train.values\n",
    "x_test = x_test.values\n",
    "y_test = y_test.values\n",
    "\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "knn_vdm, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_knn))\n",
    "end = time.time()\n",
    "print(f'Computing time: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e44dc0",
   "metadata": {},
   "source": [
    "# 3. FFD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c05353",
   "metadata": {},
   "source": [
    "## 3.1 FFD, m =10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "5c0cc369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype\n",
      "---  ------                    --------------  -----\n",
      " 0   Pregnancies               768 non-null    int64\n",
      " 1   Glucose                   768 non-null    int64\n",
      " 2   BloodPressure             768 non-null    int64\n",
      " 3   SkinThickness             768 non-null    int64\n",
      " 4   Insulin                   768 non-null    int64\n",
      " 5   BMI                       768 non-null    int64\n",
      " 6   DiabetesPedigreeFunction  768 non-null    int64\n",
      " 7   Age                       768 non-null    int64\n",
      " 8   Outcome                   768 non-null    int64\n",
      "dtypes: int64(9)\n",
      "memory usage: 54.1 KB\n",
      "Class representation - original:  Counter({0: 500, 1: 268})\n",
      "Class representation - training data:  Counter({0: 350, 1: 187})\n",
      "Class representation - testing data:  Counter({0: 150, 1: 81})\n",
      "(537, 8) (231, 8)\n",
      "=========================\n",
      "Distribution after SMOTE\n",
      "Class representation - training data:  Counter({0: 350, 1: 350})\n",
      "(700, 8) (231, 8)\n"
     ]
    }
   ],
   "source": [
    "# Read data\n",
    "df_ffd1 = pd.read_csv('pima_efd3.csv')\n",
    "df_ffd1.info()\n",
    "disc = \"FFD\"\n",
    "m = 10\n",
    "\n",
    "## EDA\n",
    "from collections import Counter\n",
    "\n",
    "# Check class of control\n",
    "Counter(df_ffd1['Outcome'])\n",
    "\n",
    "# Split dataset\n",
    "X = df_ffd1.drop(['Outcome'], axis = 1)\n",
    "Y = df_ffd1['Outcome']\n",
    "\n",
    "# Split train test, test size 25%, random state 30\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3, random_state = 30, stratify = Y)\n",
    "\n",
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(df_ffd1['Outcome'])) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test)) \n",
    "print(x_train.shape, x_test.shape)\n",
    "\n",
    "# SMOTE\n",
    "from imblearn import under_sampling, over_sampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state = 22)\n",
    "x_train, y_train = smote.fit_resample(x_train, y_train)\n",
    "\n",
    "print('='*25)\n",
    "print('Distribution after SMOTE')\n",
    "print('Class representation - training data: ', Counter(y_train))\n",
    "print(x_train.shape, x_test.shape)\n",
    "\n",
    "# Check number of categories for features\n",
    "n_categories = df_ffd1.drop(['Outcome'], axis = 1).nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399a69fc",
   "metadata": {},
   "source": [
    "### Models, FFD, m = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "127d1dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.63      0.70       150\n",
      "           1       0.50      0.69      0.58        81\n",
      "\n",
      "    accuracy                           0.65       231\n",
      "   macro avg       0.64      0.66      0.64       231\n",
      "weighted avg       0.69      0.65      0.66       231\n",
      "\n",
      "Time for training model ID3 - default, FFD, m = 10 is: 0.07000517845153809.\n"
     ]
    }
   ],
   "source": [
    "# ID3 - Default\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "model_id3 = Id3Estimator()\n",
    "model_id3.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_id3 = model_id3.predict(x_test)\n",
    "print(classification_report(y_test, y_pred_id3))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model ID3 - default, {disc}, m = {m} is: {end - start}.') # Total time execution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f4b00a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.65      0.74       150\n",
      "           1       0.55      0.80      0.65        81\n",
      "\n",
      "    accuracy                           0.70       231\n",
      "   macro avg       0.70      0.72      0.70       231\n",
      "weighted avg       0.75      0.70      0.71       231\n",
      "\n",
      "Time for training model Naive Bayes - min_categories, FFD, m = 10 is: 0.007325649261474609.\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes - min_catgories\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "model_nb = CategoricalNB(min_categories = n_categories)\n",
    "model_nb.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_nb = model_nb.predict(x_test)\n",
    "model_nb.classes_\n",
    "print(classification_report(y_test, y_pred_nb))\n",
    "end = time.time()\n",
    "print(f'Time for training model Naive Bayes - min_categories, {disc}, m = {m} is: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "3ef733db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.67      0.75       150\n",
      "           1       0.56      0.79      0.66        81\n",
      "\n",
      "    accuracy                           0.71       231\n",
      "   macro avg       0.71      0.73      0.70       231\n",
      "weighted avg       0.75      0.71      0.72       231\n",
      "\n",
      "Time for training model Knn-VDM, FFD, m = 10 is: 39.45732259750366.\n"
     ]
    }
   ],
   "source": [
    "# WARNING: LONG TIME\n",
    "# Knn-VDM complete code\n",
    "# DONe\n",
    "# Time for training model Knn-VDM, FFD, m = 10 is: 43.479066610336304.\n",
    "# Accuracy: 0.71\n",
    "\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "# specific the continuous columns index if any\n",
    "vdm = ValueDifferenceMetric(x_train, y_train, continuous = None)\n",
    "vdm.fit()\n",
    "# Knn model, n_neigbour = 3, metrics = vdm\n",
    "knn_vdm = KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')\n",
    "## Fit model\n",
    "knn_vdm.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_knn = knn_vdm.predict(x_test)\n",
    "knn_vdm.classes_\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model Knn-VDM, {disc}, m = {m} is: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6269ddbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation result, accuracy, FFD, k = 10.\n",
      "ID3: - Mean: 0.694025, Standard deviation: 0.057013\n",
      "CNB: - Mean: 0.743467, Standard deviation: 0.044930\n",
      "Knn-VDM: - Mean: 0.747357, Standard deviation: 0.038183\n"
     ]
    }
   ],
   "source": [
    "# CROSS VALIDATION\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# param\n",
    "num_folds = 10\n",
    "num_repeat = 3\n",
    "seed = 7\n",
    "scores = 'accuracy'\n",
    "\n",
    "print(f'Cross validation result, {scores}, {disc}, k = {k}.')\n",
    "\n",
    "# Create list of algorithms\n",
    "models = []\n",
    "models.append(('ID3', Id3Estimator()))\n",
    "#models.append(('RIPPER', lw.RIPPER()))\n",
    "models.append(('CNB', CategoricalNB()))\n",
    "models.append(('Knn-VDM', KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')))\n",
    "\n",
    "# Evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "  #kfold = KFold(n_splits=num_folds, shuffle = True, random_state=10)\n",
    "    kfold = RepeatedKFold(n_splits=num_folds, n_repeats=num_repeat, random_state=seed)\n",
    "    cv_results = cross_val_score(model, X, Y, cv=kfold, scoring=scores)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = '%s: - Mean: %f, Standard deviation: %f' % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2320608a",
   "metadata": {},
   "source": [
    "### Evaluation, FFD, m = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ea95ea3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import zero_one_loss\n",
    "#This library is used to decompose bias and variance in our models\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2da83bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.348\n",
      "Average bias: 0.320\n",
      "Average variance: 0.204\n",
      "Sklearn 0-1 loss: 0.351\n"
     ]
    }
   ],
   "source": [
    "# ID3\n",
    "# Convert all dataframe to array\n",
    "x_train = x_train.values\n",
    "y_train = y_train.values\n",
    "x_test = x_test.values\n",
    "y_test = y_test.values\n",
    "\n",
    "# Evaluation\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "model_id3, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_id3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5b816f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.309\n",
      "Average bias: 0.294\n",
      "Average variance: 0.083\n",
      "Sklearn 0-1 loss: 0.299\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes - min_categories update\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "model_nb, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "f2f7dc41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.328\n",
      "Average bias: 0.290\n",
      "Average variance: 0.128\n",
      "Sklearn 0-1 loss: 0.290\n",
      "Computing time: 8650.548038959503.\n"
     ]
    }
   ],
   "source": [
    "# WARNING - LONG TIME\n",
    "# Knn-VDM\n",
    "# Convert all dataframe to array\n",
    "x_train = x_train.values\n",
    "y_train = y_train.values\n",
    "x_test = x_test.values\n",
    "y_test = y_test.values\n",
    "\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "knn_vdm, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_knn))\n",
    "end = time.time()\n",
    "print(f'Computing time: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7be02e",
   "metadata": {},
   "source": [
    "## 3.2 FFD, m = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "31589461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype\n",
      "---  ------                    --------------  -----\n",
      " 0   Pregnancies               768 non-null    int64\n",
      " 1   Glucose                   768 non-null    int64\n",
      " 2   BloodPressure             768 non-null    int64\n",
      " 3   SkinThickness             768 non-null    int64\n",
      " 4   Insulin                   768 non-null    int64\n",
      " 5   BMI                       768 non-null    int64\n",
      " 6   DiabetesPedigreeFunction  768 non-null    int64\n",
      " 7   Age                       768 non-null    int64\n",
      " 8   Outcome                   768 non-null    int64\n",
      "dtypes: int64(9)\n",
      "memory usage: 54.1 KB\n",
      "Class representation - original:  Counter({0: 500, 1: 268})\n",
      "Class representation - training data:  Counter({0: 350, 1: 187})\n",
      "Class representation - testing data:  Counter({0: 150, 1: 81})\n",
      "(537, 8) (231, 8)\n",
      "=========================\n",
      "Distribution after SMOTE\n",
      "Class representation - training data:  Counter({0: 350, 1: 350})\n",
      "(700, 8) (231, 8)\n"
     ]
    }
   ],
   "source": [
    "# Read data\n",
    "df_ffd2 = pd.read_csv('pima_ffd2.csv')\n",
    "df_ffd2.info()\n",
    "disc = \"FFD\"\n",
    "m = 30\n",
    "\n",
    "## EDA\n",
    "from collections import Counter\n",
    "\n",
    "# Check class of control\n",
    "Counter(df_ffd2['Outcome'])\n",
    "\n",
    "# Split dataset\n",
    "X = df_ffd2.drop(['Outcome'], axis = 1)\n",
    "Y = df_ffd2['Outcome']\n",
    "\n",
    "# Split train test, test size 25%, random state 30\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3, random_state = 30, stratify = Y)\n",
    "\n",
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(df_ffd2['Outcome'])) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test)) \n",
    "print(x_train.shape, x_test.shape)\n",
    "\n",
    "# SMOTE\n",
    "from imblearn import under_sampling, over_sampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state = 22)\n",
    "x_train, y_train = smote.fit_resample(x_train, y_train)\n",
    "\n",
    "print('='*25)\n",
    "print('Distribution after SMOTE')\n",
    "print('Class representation - training data: ', Counter(y_train))\n",
    "print(x_train.shape, x_test.shape)\n",
    "\n",
    "# Check number of categories for features\n",
    "n_categories = df_ffd2.drop(['Outcome'], axis = 1).nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455f72ae",
   "metadata": {},
   "source": [
    "### Models, FFD, m= 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4554d076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.65      0.72       150\n",
      "           1       0.51      0.68      0.59        81\n",
      "\n",
      "    accuracy                           0.66       231\n",
      "   macro avg       0.65      0.67      0.65       231\n",
      "weighted avg       0.69      0.66      0.67       231\n",
      "\n",
      "Time for training model ID3 - default, FFD, m = 30 is: 0.09880256652832031.\n"
     ]
    }
   ],
   "source": [
    "# ID3 - Default\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "model_id3 = Id3Estimator()\n",
    "model_id3.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_id3 = model_id3.predict(x_test)\n",
    "print(classification_report(y_test, y_pred_id3))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model ID3 - default, {disc}, m = {m} is: {end - start}.') # Total time execution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "9bdaf901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.65      0.73       150\n",
      "           1       0.54      0.77      0.64        81\n",
      "\n",
      "    accuracy                           0.69       231\n",
      "   macro avg       0.69      0.71      0.68       231\n",
      "weighted avg       0.73      0.69      0.70       231\n",
      "\n",
      "Time for training model Naive Bayes - min_categories, FFD, m = 30 is: 0.0060002803802490234.\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes - min_catgories\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "model_nb = CategoricalNB(min_categories = n_categories)\n",
    "model_nb.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_nb = model_nb.predict(x_test)\n",
    "model_nb.classes_\n",
    "print(classification_report(y_test, y_pred_nb))\n",
    "end = time.time()\n",
    "print(f'Time for training model Naive Bayes - min_categories, {disc}, m = {m} is: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "12c603eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.68      0.76       150\n",
      "           1       0.57      0.78      0.66        81\n",
      "\n",
      "    accuracy                           0.71       231\n",
      "   macro avg       0.71      0.73      0.71       231\n",
      "weighted avg       0.75      0.71      0.72       231\n",
      "\n",
      "Time for training model Knn-VDM, FFD, m = 30 is: 40.838098764419556.\n"
     ]
    }
   ],
   "source": [
    "# WARNING: LONG TIME\n",
    "# Knn-VDM complete code\n",
    "# DONE\n",
    "# Time for training model Knn-VDM, FFD, m = 30 is: 41.11604309082031.\n",
    "# Accuracy: 0.71\n",
    "\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "# specific the continuous columns index if any\n",
    "vdm = ValueDifferenceMetric(x_train, y_train, continuous = None)\n",
    "vdm.fit()\n",
    "# Knn model, n_neigbour = 3, metrics = vdm\n",
    "knn_vdm = KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')\n",
    "## Fit model\n",
    "knn_vdm.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_knn = knn_vdm.predict(x_test)\n",
    "knn_vdm.classes_\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model Knn-VDM, {disc}, m = {m} is: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7a870ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation result, accuracy, FFD, k = 10.\n",
      "ID3: - Mean: 0.718313, Standard deviation: 0.053633\n",
      "CNB: - Mean: 0.737805, Standard deviation: 0.040628\n",
      "Knn-VDM: - Mean: 0.724761, Standard deviation: 0.048285\n"
     ]
    }
   ],
   "source": [
    "# CROSS VALIDATION\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# param\n",
    "num_folds = 10\n",
    "num_repeat = 3\n",
    "seed = 7\n",
    "scores = 'accuracy'\n",
    "\n",
    "print(f'Cross validation result, {scores}, {disc}, k = {k}.')\n",
    "\n",
    "# Create list of algorithms\n",
    "models = []\n",
    "models.append(('ID3', Id3Estimator()))\n",
    "#models.append(('RIPPER', lw.RIPPER()))\n",
    "models.append(('CNB', CategoricalNB()))\n",
    "models.append(('Knn-VDM', KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')))\n",
    "\n",
    "# Evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "  #kfold = KFold(n_splits=num_folds, shuffle = True, random_state=10)\n",
    "    kfold = RepeatedKFold(n_splits=num_folds, n_repeats=num_repeat, random_state=seed)\n",
    "    cv_results = cross_val_score(model, X, Y, cv=kfold, scoring=scores)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = '%s: - Mean: %f, Standard deviation: %f' % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c236c1d",
   "metadata": {},
   "source": [
    "### Evaluation, FFD, m = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ea05017a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import zero_one_loss\n",
    "#This library is used to decompose bias and variance in our models\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "5d76688f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.342\n",
      "Average bias: 0.303\n",
      "Average variance: 0.211\n",
      "Sklearn 0-1 loss: 0.338\n"
     ]
    }
   ],
   "source": [
    "# ID3\n",
    "# Convert all dataframe to array\n",
    "x_train = x_train.values\n",
    "y_train = y_train.values\n",
    "x_test = x_test.values\n",
    "y_test = y_test.values\n",
    "\n",
    "# Evaluation\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "model_id3, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_id3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f2b9597c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.321\n",
      "Average bias: 0.312\n",
      "Average variance: 0.104\n",
      "Sklearn 0-1 loss: 0.307\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes - min_categories update\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "model_nb, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "9d90bbe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.322\n",
      "Average bias: 0.299\n",
      "Average variance: 0.138\n",
      "Sklearn 0-1 loss: 0.286\n",
      "Computing time: 8000.970769405365.\n"
     ]
    }
   ],
   "source": [
    "# WARNING - LONG TIME\n",
    "# Knn-VDM\n",
    "# Convert all dataframe to array\n",
    "x_train = x_train.values\n",
    "y_train = y_train.values\n",
    "x_test = x_test.values\n",
    "y_test = y_test.values\n",
    "\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "knn_vdm, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_knn))\n",
    "end = time.time()\n",
    "print(f'Computing time: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645c5260",
   "metadata": {},
   "source": [
    "## 3.3 FFD, m = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "bc12c299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype\n",
      "---  ------                    --------------  -----\n",
      " 0   Pregnancies               768 non-null    int64\n",
      " 1   Glucose                   768 non-null    int64\n",
      " 2   BloodPressure             768 non-null    int64\n",
      " 3   SkinThickness             768 non-null    int64\n",
      " 4   Insulin                   768 non-null    int64\n",
      " 5   BMI                       768 non-null    int64\n",
      " 6   DiabetesPedigreeFunction  768 non-null    int64\n",
      " 7   Age                       768 non-null    int64\n",
      " 8   Outcome                   768 non-null    int64\n",
      "dtypes: int64(9)\n",
      "memory usage: 54.1 KB\n",
      "Class representation - original:  Counter({0: 500, 1: 268})\n",
      "Class representation - training data:  Counter({0: 350, 1: 187})\n",
      "Class representation - testing data:  Counter({0: 150, 1: 81})\n",
      "(537, 8) (231, 8)\n",
      "=========================\n",
      "Distribution after SMOTE\n",
      "Class representation - training data:  Counter({0: 350, 1: 350})\n",
      "(700, 8) (231, 8)\n"
     ]
    }
   ],
   "source": [
    "# Read data\n",
    "df_ffd3 = pd.read_csv('pima_ffd3.csv')\n",
    "df_ffd3.info()\n",
    "disc = \"FFD\"\n",
    "m = 60\n",
    "\n",
    "## EDA\n",
    "from collections import Counter\n",
    "\n",
    "# Check class of control\n",
    "Counter(df_ffd3['Outcome'])\n",
    "\n",
    "# Split dataset\n",
    "X = df_ffd3.drop(['Outcome'], axis = 1)\n",
    "Y = df_ffd3['Outcome']\n",
    "\n",
    "# Split train test, test size 25%, random state 30\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3, random_state = 30, stratify = Y)\n",
    "\n",
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(df_ffd3['Outcome'])) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test)) \n",
    "print(x_train.shape, x_test.shape)\n",
    "\n",
    "# SMOTE\n",
    "from imblearn import under_sampling, over_sampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state = 22)\n",
    "x_train, y_train = smote.fit_resample(x_train, y_train)\n",
    "\n",
    "print('='*25)\n",
    "print('Distribution after SMOTE')\n",
    "print('Class representation - training data: ', Counter(y_train))\n",
    "print(x_train.shape, x_test.shape)\n",
    "\n",
    "# Check number of categories for features\n",
    "n_categories = df_ffd3.drop(['Outcome'], axis = 1).nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4aa729",
   "metadata": {},
   "source": [
    "### Models, FFD, m= 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a3ff16db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.68      0.73       150\n",
      "           1       0.53      0.67      0.59        81\n",
      "\n",
      "    accuracy                           0.68       231\n",
      "   macro avg       0.66      0.67      0.66       231\n",
      "weighted avg       0.70      0.68      0.68       231\n",
      "\n",
      "Time for training model ID3 - default, FFD, m = 60 is: 0.06999921798706055.\n"
     ]
    }
   ],
   "source": [
    "# ID3 - Default\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "model_id3 = Id3Estimator()\n",
    "model_id3.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_id3 = model_id3.predict(x_test)\n",
    "print(classification_report(y_test, y_pred_id3))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model ID3 - default, {disc}, m = {m} is: {end - start}.') # Total time execution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "9759b610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.65      0.73       150\n",
      "           1       0.54      0.77      0.63        81\n",
      "\n",
      "    accuracy                           0.69       231\n",
      "   macro avg       0.69      0.71      0.68       231\n",
      "weighted avg       0.73      0.69      0.70       231\n",
      "\n",
      "Time for training model Naive Bayes - min_categories, FFD, m = 60 is: 0.009998798370361328.\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes - min_catgories\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "model_nb = CategoricalNB(min_categories = n_categories)\n",
    "model_nb.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_nb = model_nb.predict(x_test)\n",
    "model_nb.classes_\n",
    "print(classification_report(y_test, y_pred_nb))\n",
    "end = time.time()\n",
    "print(f'Time for training model Naive Bayes - min_categories, {disc}, m = {m} is: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "eca5fb98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.67      0.74       150\n",
      "           1       0.55      0.73      0.62        81\n",
      "\n",
      "    accuracy                           0.69       231\n",
      "   macro avg       0.68      0.70      0.68       231\n",
      "weighted avg       0.72      0.69      0.70       231\n",
      "\n",
      "Time for training model Knn-VDM, FFD, m = 60 is: 40.311824560165405.\n"
     ]
    }
   ],
   "source": [
    "# WARNING: LONG TIME\n",
    "# Knn-VDM complete code\n",
    "# DONE, Accuracy: 0.69\n",
    "# Time for training model Knn-VDM, FFD, m = 60 is: 44.30944085121155.\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "# specific the continuous columns index if any\n",
    "vdm = ValueDifferenceMetric(x_train, y_train, continuous = None)\n",
    "vdm.fit()\n",
    "# Knn model, n_neigbour = 3, metrics = vdm\n",
    "knn_vdm = KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')\n",
    "## Fit model\n",
    "knn_vdm.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_knn = knn_vdm.predict(x_test)\n",
    "knn_vdm.classes_\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model Knn-VDM, {disc}, m = {m} is: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "415ec240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation result, accuracy, FFD, k = 10.\n",
      "ID3: - Mean: 0.709211, Standard deviation: 0.048297\n",
      "CNB: - Mean: 0.757331, Standard deviation: 0.036820\n",
      "Knn-VDM: - Mean: 0.744304, Standard deviation: 0.037072\n"
     ]
    }
   ],
   "source": [
    "# CROSS VALIDATION\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# param\n",
    "num_folds = 10\n",
    "num_repeat = 3\n",
    "seed = 7\n",
    "scores = 'accuracy'\n",
    "\n",
    "print(f'Cross validation result, {scores}, {disc}, k = {k}.')\n",
    "\n",
    "# Create list of algorithms\n",
    "models = []\n",
    "models.append(('ID3', Id3Estimator()))\n",
    "#models.append(('RIPPER', lw.RIPPER()))\n",
    "models.append(('CNB', CategoricalNB()))\n",
    "models.append(('Knn-VDM', KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')))\n",
    "\n",
    "# Evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "  #kfold = KFold(n_splits=num_folds, shuffle = True, random_state=10)\n",
    "    kfold = RepeatedKFold(n_splits=num_folds, n_repeats=num_repeat, random_state=seed)\n",
    "    cv_results = cross_val_score(model, X, Y, cv=kfold, scoring=scores)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = '%s: - Mean: %f, Standard deviation: %f' % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acdceea",
   "metadata": {},
   "source": [
    "### Evaluation, FFD, m= 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "52211811",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import zero_one_loss\n",
    "#This library is used to decompose bias and variance in our models\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "3d03f68f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.348\n",
      "Average bias: 0.312\n",
      "Average variance: 0.192\n",
      "Sklearn 0-1 loss: 0.325\n"
     ]
    }
   ],
   "source": [
    "# ID3\n",
    "# Convert all dataframe to array\n",
    "x_train = x_train.values\n",
    "y_train = y_train.values\n",
    "x_test = x_test.values\n",
    "y_test = y_test.values\n",
    "\n",
    "# Evaluation\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "model_id3, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_id3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "2be0f739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.318\n",
      "Average bias: 0.312\n",
      "Average variance: 0.088\n",
      "Sklearn 0-1 loss: 0.312\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes - min_categories update\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "model_nb, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "c89c45a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.329\n",
      "Average bias: 0.307\n",
      "Average variance: 0.121\n",
      "Sklearn 0-1 loss: 0.307\n",
      "Computing time: 54188.53180384636.\n"
     ]
    }
   ],
   "source": [
    "# WARNING - LONG TIME\n",
    "# Knn-VDM\n",
    "# Convert all dataframe to array\n",
    "x_train = x_train.values\n",
    "y_train = y_train.values\n",
    "x_test = x_test.values\n",
    "y_test = y_test.values\n",
    "\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "knn_vdm, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_knn))\n",
    "end = time.time()\n",
    "print(f'Computing time: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcae22c3",
   "metadata": {},
   "source": [
    "## 3.4 FFD, m = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae8b57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "df_ffd4 = pd.read_csv('pima_ffd4.csv')\n",
    "df_ffd4.info()\n",
    "disc = \"FFD\"\n",
    "m = 60\n",
    "\n",
    "## EDA\n",
    "from collections import Counter\n",
    "\n",
    "# Check class of control\n",
    "Counter(df_ffd4['Outcome'])\n",
    "\n",
    "# Split dataset\n",
    "X = df_ffd4.drop(['Outcome'], axis = 1)\n",
    "Y = df_ffd4['Outcome']\n",
    "\n",
    "# Split train test, test size 25%, random state 30\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3, random_state = 30, stratify = Y)\n",
    "\n",
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(df_ffd4['Outcome'])) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test)) \n",
    "print(x_train.shape, x_test.shape)\n",
    "\n",
    "# SMOTE\n",
    "from imblearn import under_sampling, over_sampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state = 22)\n",
    "x_train, y_train = smote.fit_resample(x_train, y_train)\n",
    "\n",
    "print('='*25)\n",
    "print('Distribution after SMOTE')\n",
    "print('Class representation - training data: ', Counter(y_train))\n",
    "print(x_train.shape, x_test.shape)\n",
    "\n",
    "# Check number of categories for features\n",
    "n_categories = df_ffd4.drop(['Outcome'], axis = 1).nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c021494",
   "metadata": {},
   "source": [
    "### Models, FFD, m = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "7cbf43cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.68      0.73       150\n",
      "           1       0.52      0.65      0.58        81\n",
      "\n",
      "    accuracy                           0.67       231\n",
      "   macro avg       0.65      0.67      0.66       231\n",
      "weighted avg       0.69      0.67      0.68       231\n",
      "\n",
      "Time for training model ID3 - default, FFD, m = 60 is: 0.05915355682373047.\n"
     ]
    }
   ],
   "source": [
    "# ID3 - Default\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "model_id3 = Id3Estimator()\n",
    "model_id3.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_id3 = model_id3.predict(x_test)\n",
    "print(classification_report(y_test, y_pred_id3))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model ID3 - default, {disc}, m = {m} is: {end - start}.') # Total time execution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d90e542f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.64      0.74       150\n",
      "           1       0.55      0.81      0.66        81\n",
      "\n",
      "    accuracy                           0.70       231\n",
      "   macro avg       0.71      0.73      0.70       231\n",
      "weighted avg       0.75      0.70      0.71       231\n",
      "\n",
      "Time for training model Naive Bayes - min_categories, FFD, m = 60 is: 0.0.\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes - min_catgories\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "model_nb = CategoricalNB(min_categories = n_categories)\n",
    "model_nb.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_nb = model_nb.predict(x_test)\n",
    "model_nb.classes_\n",
    "print(classification_report(y_test, y_pred_nb))\n",
    "end = time.time()\n",
    "print(f'Time for training model Naive Bayes - min_categories, {disc}, m = {m} is: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "9c8f25fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.69      0.73       150\n",
      "           1       0.53      0.65      0.59        81\n",
      "\n",
      "    accuracy                           0.68       231\n",
      "   macro avg       0.66      0.67      0.66       231\n",
      "weighted avg       0.70      0.68      0.68       231\n",
      "\n",
      "Time for training model Knn-VDM, FFD, m = 60 is: 42.83824014663696.\n"
     ]
    }
   ],
   "source": [
    "# WARNING: LONG TIME\n",
    "# Knn-VDM complete code\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "# specific the continuous columns index if any\n",
    "vdm = ValueDifferenceMetric(x_train, y_train, continuous = None)\n",
    "vdm.fit()\n",
    "# Knn model, n_neigbour = 3, metrics = vdm\n",
    "knn_vdm = KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')\n",
    "## Fit model\n",
    "knn_vdm.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_knn = knn_vdm.predict(x_test)\n",
    "knn_vdm.classes_\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model Knn-VDM, {disc}, m = {m} is: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a4dcd607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation result, accuracy, FFD, k = 10.\n",
      "ID3: - Mean: 0.703554, Standard deviation: 0.053018\n",
      "CNB: - Mean: 0.749089, Standard deviation: 0.040728\n",
      "Knn-VDM: - Mean: 0.737828, Standard deviation: 0.040830\n"
     ]
    }
   ],
   "source": [
    "# CROSS VALIDATION\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# param\n",
    "num_folds = 10\n",
    "num_repeat = 3\n",
    "seed = 7\n",
    "scores = 'accuracy'\n",
    "\n",
    "print(f'Cross validation result, {scores}, {disc}, k = {k}.')\n",
    "\n",
    "# Create list of algorithms\n",
    "models = []\n",
    "models.append(('ID3', Id3Estimator()))\n",
    "#models.append(('RIPPER', lw.RIPPER()))\n",
    "models.append(('CNB', CategoricalNB()))\n",
    "models.append(('Knn-VDM', KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')))\n",
    "\n",
    "# Evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "  #kfold = KFold(n_splits=num_folds, shuffle = True, random_state=10)\n",
    "    kfold = RepeatedKFold(n_splits=num_folds, n_repeats=num_repeat, random_state=seed)\n",
    "    cv_results = cross_val_score(model, X, Y, cv=kfold, scoring=scores)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = '%s: - Mean: %f, Standard deviation: %f' % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06116d6",
   "metadata": {},
   "source": [
    "### Evaluation, FFD, m=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "4d1c8d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import zero_one_loss\n",
    "#This library is used to decompose bias and variance in our models\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b756e877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.344\n",
      "Average bias: 0.286\n",
      "Average variance: 0.205\n",
      "Sklearn 0-1 loss: 0.329\n"
     ]
    }
   ],
   "source": [
    "# ID3\n",
    "# Convert all dataframe to array\n",
    "x_train = x_train.values\n",
    "y_train = y_train.values\n",
    "x_test = x_test.values\n",
    "y_test = y_test.values\n",
    "\n",
    "# Evaluation\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "model_id3, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_id3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "0d15a47b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.304\n",
      "Average bias: 0.299\n",
      "Average variance: 0.072\n",
      "Sklearn 0-1 loss: 0.299\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes - min_categories update\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "model_nb, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "8fa74984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.323\n",
      "Average bias: 0.316\n",
      "Average variance: 0.147\n",
      "Sklearn 0-1 loss: 0.325\n",
      "Computing time: 9363.133692979813.\n"
     ]
    }
   ],
   "source": [
    "# WARNING - LONG TIME\n",
    "# Knn-VDM\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "knn_vdm, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_knn))\n",
    "end = time.time()\n",
    "print(f'Computing time: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e596de4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
