{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "514e58db",
   "metadata": {},
   "source": [
    "# Classification models\n",
    "\n",
    "Dataset: australia\n",
    "By: Sam\n",
    "Update at: 12/10/2022\n",
    "====\n",
    "\n",
    "Summary:\n",
    "\n",
    "- Import unsupervised discretised datasets (already encoded categorical attributes)\n",
    "- Split dataset: 75% training, 25% testing, seed = 30\n",
    "- Perform 3 classification models: ID3, Naive Bayes, KNN\n",
    "- Evaluation metrics: accuracy, time for training, bias, variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8deeab93",
   "metadata": {},
   "source": [
    "### About Dataset\n",
    "*Continuous attributes:* 6\n",
    "\n",
    "- A2:\tcontinuous.\n",
    "- A3:\tcontinuous.\n",
    "- A7:\tcontinuous.\n",
    "- A10: continuous.\n",
    "- A13: continuous.\n",
    "- A14: continuous.\n",
    "\n",
    "*Categorical attributes:*\n",
    "- A1:\t0,1    CATEGORICAL a,b\n",
    "- A4:\t1,2,3         CATEGORICAL p,g,gg\n",
    "- A5:  1, 2,3,4,5, 6,7,8,9,10,11,12,13,14    CATEGORICAL ff,d,i,k,j,aa,m,c,w, e, q, r,cc, x \n",
    "- A6:\t 1, 2,3, 4,5,6,7,8,9    CATEGORICAL ff,dd,j,bb,v,n,o,h,z \n",
    "- A8:\t1, 0       CATEGORICAL t, f.\n",
    "- A9: 1, 0\t    CATEGORICAL t, f.\n",
    "- A11:  1, 0\t    CATEGORICAL t, f.\n",
    "- A12:    1, 2, 3    CATEGORICAL s, g, p \n",
    "\n",
    "*Label*\n",
    "A15:   1,2 +,- (class attribute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6e959660",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "from pandas import set_option\n",
    "import numpy as np\n",
    "from numpy import arange\n",
    "## EDA\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c39986bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "# Cross validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score # 1 metric\n",
    "from sklearn.model_selection import cross_validate # more than 1 metric\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "76585941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RIPPER (https://pypi.org/project/wittgenstein/) Only for binary\n",
    "import wittgenstein as lw "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a1d3237a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Naive Bayes\n",
    "from sklearn.naive_bayes import CategoricalNB # Categorical Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB # Multinominal Naive Bayes (suitable for NLP)\n",
    "from mixed_naive_bayes import MixedNB # Mixed Naive Bayes for combination of both discrete & continuous feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9e9ddea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For decision tree ID3 \n",
    "# https://stackoverflow.com/questions/61867945/python-import-error-cannot-import-name-six-from-sklearn-externals\n",
    "import six\n",
    "import sys\n",
    "sys.modules['sklearn.externals.six'] = six\n",
    "import mlrose\n",
    "from id3 import Id3Estimator # ID3 Decision Tree (https://pypi.org/project/decision-tree-id3/)\n",
    "from id3 import export_graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "039c536e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For model evaluation\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5ee46b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Knn using VDM metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from vdm3 import ValueDifferenceMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e4ec1b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13679f21",
   "metadata": {},
   "source": [
    "# EWD data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f773ca",
   "metadata": {},
   "source": [
    "## EWD, k = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "3f5f989d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 690 entries, 0 to 689\n",
      "Data columns (total 15 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   A2      690 non-null    int64\n",
      " 1   A3      690 non-null    int64\n",
      " 2   A7      690 non-null    int64\n",
      " 3   A10     690 non-null    int64\n",
      " 4   A13     690 non-null    int64\n",
      " 5   A14     690 non-null    int64\n",
      " 6   A1      690 non-null    int64\n",
      " 7   A11     690 non-null    int64\n",
      " 8   A12     690 non-null    int64\n",
      " 9   A4      690 non-null    int64\n",
      " 10  A5      690 non-null    int64\n",
      " 11  A6      690 non-null    int64\n",
      " 12  A8      690 non-null    int64\n",
      " 13  A9      690 non-null    int64\n",
      " 14  label   690 non-null    int64\n",
      "dtypes: int64(15)\n",
      "memory usage: 81.0 KB\n",
      "(690, 14) (690,)\n",
      "Class representation - original:  Counter({0: 383, 1: 307})\n",
      "Class representation - training data:  Counter({0: 288, 1: 229})\n",
      "Class representation - testing data:  Counter({0: 95, 1: 78})\n"
     ]
    }
   ],
   "source": [
    "# Complete code for data preperation\n",
    "# Read data\n",
    "df_ewd1 = pd.read_csv('aus_ewd1.csv')\n",
    "disc = 'EWD'\n",
    "k = 4\n",
    "\n",
    "df_ewd1.info()\n",
    "data = df_ewd1.values\n",
    "data.shape\n",
    "\n",
    "features = df_ewd1.drop('label', axis = 1).columns\n",
    "\n",
    "# separate the data into X and y\n",
    "X = data[:, : len(features)]\n",
    "Y = data[:,-1]\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "# Split train test\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state = 30)\n",
    "\n",
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(Y)) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test)) \n",
    "\n",
    "# Check number of categories for features\n",
    "n_categories = df_ewd1[features].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aae1bd4",
   "metadata": {},
   "source": [
    "### Models - EWD, k=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "35b6f492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.85      0.79        95\n",
      "           1       0.78      0.64      0.70        78\n",
      "\n",
      "    accuracy                           0.76       173\n",
      "   macro avg       0.76      0.75      0.75       173\n",
      "weighted avg       0.76      0.76      0.75       173\n",
      "\n",
      "Time for training model ID3 - default, EWD, k = 4 is: 0.06848788261413574.\n"
     ]
    }
   ],
   "source": [
    "# ID3 - Default\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "model_id3 = Id3Estimator()\n",
    "model_id3.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_id3 = model_id3.predict(x_test)\n",
    "print(classification_report(y_test, y_pred_id3))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model ID3 - default, {disc}, k = {k} is: {end - start}.') # Total time execution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dfa79c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.85      0.83        95\n",
      "           1       0.81      0.74      0.77        78\n",
      "\n",
      "    accuracy                           0.80       173\n",
      "   macro avg       0.80      0.80      0.80       173\n",
      "weighted avg       0.80      0.80      0.80       173\n",
      "\n",
      "Time for training model Naive Bayes - default, EWD, k = 4 is: 0.007742881774902344.\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes - min_categories = n_categories\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "model_nb = CategoricalNB(min_categories = n_categories)\n",
    "model_nb.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_nb = model_nb.predict(x_test)\n",
    "model_nb.classes_\n",
    "print(classification_report(y_test, y_pred_nb))\n",
    "end = time.time()\n",
    "print(f'Time for training model Naive Bayes - default, {disc}, k = {k} is: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "aa1e10f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.84      0.81        95\n",
      "           1       0.79      0.72      0.75        78\n",
      "\n",
      "    accuracy                           0.79       173\n",
      "   macro avg       0.79      0.78      0.78       173\n",
      "weighted avg       0.79      0.79      0.78       173\n",
      "\n",
      "Time for training model Knn-VDM, EWD, k = 4 is: 42.7268431186676.\n"
     ]
    }
   ],
   "source": [
    "# Knn-VDM complete code\n",
    "# DONE\n",
    "# Accuracy: 0.79\n",
    "# Time for training: (1st attempt): 42.37504291534424.\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "# specific the continuous columns index if any\n",
    "vdm = ValueDifferenceMetric(x_train, y_train, continuous = None)\n",
    "vdm.fit()\n",
    "# Knn model, n_neigbour = 3, metrics = vdm\n",
    "knn_vdm = KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')\n",
    "## Fit model\n",
    "knn_vdm.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_knn = knn_vdm.predict(x_test)\n",
    "knn_vdm.classes_\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model Knn-VDM, {disc}, k = {k} is: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4bb5f3ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation result, accuracy, EWD, k = 4.\n",
      "ID3: - Mean: 0.830918, Standard deviation: 0.038948\n",
      "CNB: - Mean: nan, Standard deviation: nan\n",
      "Knn-VDM: - Mean: 0.844928, Standard deviation: 0.037448\n"
     ]
    }
   ],
   "source": [
    "# CROSS VALIDATION\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# param\n",
    "num_folds = 10\n",
    "num_repeat = 3\n",
    "seed = 7\n",
    "scores = 'accuracy'\n",
    "\n",
    "print(f'Cross validation result, {scores}, {disc}, k = {k}.')\n",
    "\n",
    "# Create list of algorithms\n",
    "models = []\n",
    "models.append(('ID3', Id3Estimator()))\n",
    "#models.append(('RIPPER', lw.RIPPER()))\n",
    "models.append(('CNB', CategoricalNB()))\n",
    "models.append(('Knn-VDM', KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')))\n",
    "\n",
    "# Evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "  #kfold = KFold(n_splits=num_folds, shuffle = True, random_state=10)\n",
    "    kfold = RepeatedKFold(n_splits=num_folds, n_repeats=num_repeat, random_state=seed)\n",
    "    cv_results = cross_val_score(model, X, Y, cv=kfold, scoring=scores)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = '%s: - Mean: %f, Standard deviation: %f' % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae1d949",
   "metadata": {},
   "source": [
    "### Evaluation, EWD, k =4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7dde1f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import zero_one_loss\n",
    "#This library is used to decompose bias and variance in our models\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "66c7bcbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.238\n",
      "Average bias: 0.220\n",
      "Average variance: 0.106\n",
      "Sklearn 0-1 loss: 0.243\n"
     ]
    }
   ],
   "source": [
    "# ID3\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "model_id3, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_id3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "87daf531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.198\n",
      "Average bias: 0.197\n",
      "Average variance: 0.035\n",
      "Sklearn 0-1 loss: 0.197\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes - min_categories\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "model_nb, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "0e192738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.229\n",
      "Average bias: 0.220\n",
      "Average variance: 0.092\n",
      "Sklearn 0-1 loss: 0.214\n",
      "Computing time:, EWD, k = 4 is: 14917.971321105957.\n"
     ]
    }
   ],
   "source": [
    "# WARINING: LONG TIME \n",
    "# Knn-VDM\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "knn_vdm, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_knn))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Computing time:, {disc}, k = {k} is: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c0a4f2",
   "metadata": {},
   "source": [
    "## 1.2 EWD, k = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "d18d24c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 690 entries, 0 to 689\n",
      "Data columns (total 15 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   A2      690 non-null    int64\n",
      " 1   A3      690 non-null    int64\n",
      " 2   A7      690 non-null    int64\n",
      " 3   A10     690 non-null    int64\n",
      " 4   A13     690 non-null    int64\n",
      " 5   A14     690 non-null    int64\n",
      " 6   A1      690 non-null    int64\n",
      " 7   A11     690 non-null    int64\n",
      " 8   A12     690 non-null    int64\n",
      " 9   A4      690 non-null    int64\n",
      " 10  A5      690 non-null    int64\n",
      " 11  A6      690 non-null    int64\n",
      " 12  A8      690 non-null    int64\n",
      " 13  A9      690 non-null    int64\n",
      " 14  label   690 non-null    int64\n",
      "dtypes: int64(15)\n",
      "memory usage: 81.0 KB\n",
      "(690, 14) (690,)\n",
      "Class representation - original:  Counter({0: 383, 1: 307})\n",
      "Class representation - training data:  Counter({0: 288, 1: 229})\n",
      "Class representation - testing data:  Counter({0: 95, 1: 78})\n"
     ]
    }
   ],
   "source": [
    "# Complete code for data preperation\n",
    "# Read data\n",
    "df_ewd2 = pd.read_csv('aus_ewd2.csv')\n",
    "disc = 'EWD'\n",
    "k = 7\n",
    "\n",
    "df_ewd2.info()\n",
    "data = df_ewd2.values\n",
    "data.shape\n",
    "\n",
    "features = df_ewd2.drop('label', axis = 1).columns\n",
    "\n",
    "# separate the data into X and y\n",
    "X = data[:, : len(features)]\n",
    "Y = data[:,-1]\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "# Split train test\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state = 30)\n",
    "\n",
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(Y)) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test)) \n",
    "\n",
    "# Check number of categories for features\n",
    "n_categories = df_ewd2[features].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d8c2f2",
   "metadata": {},
   "source": [
    "### Models - EWD, k=7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e54cf9a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.83      0.79        95\n",
      "           1       0.76      0.67      0.71        78\n",
      "\n",
      "    accuracy                           0.76       173\n",
      "   macro avg       0.76      0.75      0.75       173\n",
      "weighted avg       0.76      0.76      0.75       173\n",
      "\n",
      "Time for training model ID3 - default, EWD, k = 7 is: 0.08396506309509277.\n"
     ]
    }
   ],
   "source": [
    "# ID3 - Default\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "model_id3 = Id3Estimator()\n",
    "model_id3.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_id3 = model_id3.predict(x_test)\n",
    "print(classification_report(y_test, y_pred_id3))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model ID3 - default, {disc}, k = {k} is: {end - start}.') # Total time execution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0658c045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.84      0.82        95\n",
      "           1       0.79      0.73      0.76        78\n",
      "\n",
      "    accuracy                           0.79       173\n",
      "   macro avg       0.79      0.79      0.79       173\n",
      "weighted avg       0.79      0.79      0.79       173\n",
      "\n",
      "Time for training model Naive Bayes - default, EWD, k = 7 is: 0.007652759552001953.\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes - min_categories\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "model_nb = CategoricalNB(min_categories = n_categories)\n",
    "model_nb.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_nb = model_nb.predict(x_test)\n",
    "model_nb.classes_\n",
    "print(classification_report(y_test, y_pred_nb))\n",
    "end = time.time()\n",
    "print(f'Time for training model Naive Bayes - default, {disc}, k = {k} is: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "835b34ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "3.0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [43]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m knn_vdm\u001b[38;5;241m.\u001b[39mfit(x_train, y_train)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Testing\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m y_pred_knn \u001b[38;5;241m=\u001b[39m \u001b[43mknn_vdm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m knn_vdm\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(y_test, y_pred_knn))\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:214\u001b[0m, in \u001b[0;36mKNeighborsClassifier.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;124;03m\"\"\"Predict the class labels for the provided data.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \n\u001b[1;32m    203\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;124;03m        Class labels for each data sample.\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 214\u001b[0m     neigh_dist, neigh_ind \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkneighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m     classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[1;32m    216\u001b[0m     _y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_y\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_base.py:752\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    749\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    750\u001b[0m         kwds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meffective_metric_params_\n\u001b[0;32m--> 752\u001b[0m     chunked_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    753\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpairwise_distances_chunked\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    754\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    755\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_X\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    756\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreduce_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreduce_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    757\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meffective_metric_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    758\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    759\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    760\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    761\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    763\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_method \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mball_tree\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkd_tree\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    764\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m issparse(X):\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/pairwise.py:1717\u001b[0m, in \u001b[0;36mpairwise_distances_chunked\u001b[0;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1716\u001b[0m     X_chunk \u001b[38;5;241m=\u001b[39m X[sl]\n\u001b[0;32m-> 1717\u001b[0m D_chunk \u001b[38;5;241m=\u001b[39m \u001b[43mpairwise_distances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1718\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (X \u001b[38;5;129;01mis\u001b[39;00m Y \u001b[38;5;129;01mor\u001b[39;00m Y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m PAIRWISE_DISTANCE_FUNCTIONS\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m   1719\u001b[0m     metric, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1720\u001b[0m ) \u001b[38;5;129;01mis\u001b[39;00m euclidean_distances:\n\u001b[1;32m   1721\u001b[0m     \u001b[38;5;66;03m# zeroing diagonal, taking care of aliases of \"euclidean\",\u001b[39;00m\n\u001b[1;32m   1722\u001b[0m     \u001b[38;5;66;03m# i.e. \"l2\"\u001b[39;00m\n\u001b[1;32m   1723\u001b[0m     D_chunk\u001b[38;5;241m.\u001b[39mflat[sl\u001b[38;5;241m.\u001b[39mstart :: _num_samples(X) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/pairwise.py:1889\u001b[0m, in \u001b[0;36mpairwise_distances\u001b[0;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[1;32m   1886\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m distance\u001b[38;5;241m.\u001b[39msquareform(distance\u001b[38;5;241m.\u001b[39mpdist(X, metric\u001b[38;5;241m=\u001b[39mmetric, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds))\n\u001b[1;32m   1887\u001b[0m     func \u001b[38;5;241m=\u001b[39m partial(distance\u001b[38;5;241m.\u001b[39mcdist, metric\u001b[38;5;241m=\u001b[39mmetric, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m-> 1889\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_parallel_pairwise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/pairwise.py:1430\u001b[0m, in \u001b[0;36m_parallel_pairwise\u001b[0;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[1;32m   1427\u001b[0m X, Y, dtype \u001b[38;5;241m=\u001b[39m _return_float_dtype(X, Y)\n\u001b[1;32m   1429\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m effective_n_jobs(n_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m-> 1430\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1432\u001b[0m \u001b[38;5;66;03m# enforce a threading backend to prevent data communication overhead\u001b[39;00m\n\u001b[1;32m   1433\u001b[0m fd \u001b[38;5;241m=\u001b[39m delayed(_dist_wrapper)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/pairwise.py:1474\u001b[0m, in \u001b[0;36m_pairwise_callable\u001b[0;34m(X, Y, metric, force_all_finite, **kwds)\u001b[0m\n\u001b[1;32m   1472\u001b[0m     iterator \u001b[38;5;241m=\u001b[39m itertools\u001b[38;5;241m.\u001b[39mproduct(\u001b[38;5;28mrange\u001b[39m(X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]), \u001b[38;5;28mrange\u001b[39m(Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]))\n\u001b[1;32m   1473\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, j \u001b[38;5;129;01min\u001b[39;00m iterator:\n\u001b[0;32m-> 1474\u001b[0m         out[i, j] \u001b[38;5;241m=\u001b[39m \u001b[43mmetric\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1476\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/vdm3/vdm.py:83\u001b[0m, in \u001b[0;36mValueDifferenceMetric.get_distance\u001b[0;34m(self, ins_1, ins_2, norm)\u001b[0m\n\u001b[1;32m     80\u001b[0m     ins_1_cat \u001b[38;5;241m=\u001b[39m ins_1\n\u001b[1;32m     81\u001b[0m     ins_2_cat \u001b[38;5;241m=\u001b[39m ins_2\n\u001b[0;32m---> 83\u001b[0m cat_dist \u001b[38;5;241m=\u001b[39m \u001b[43mget_delta_nd\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcond_proba\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mins_1_cat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mins_2_cat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontinuous \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     86\u001b[0m     cont_dist \u001b[38;5;241m=\u001b[39m get_cont_dist(ins_1_cont, ins_2_cont, norm)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/vdm3/components.py:77\u001b[0m, in \u001b[0;36mget_delta_nd\u001b[0;34m(cond_proba, ins_1, ins_2, norm)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_delta_nd\u001b[39m(cond_proba, ins_1, ins_2, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m):\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;124;03m\"\"\" get deltas for vdm for multidimensional data\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    Parameters: cond_proba (dict) - a dictionary of conditional probability, extract from get_conditional_proba_nd()\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;124;03m    Returns: deltas (array) - the delta values between ins_1 and ins_2\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m     deltas \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([get_delta(cond_proba[col], ins_1[col], ins_2[col], norm) \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m cond_proba])\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m deltas\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/vdm3/components.py:77\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_delta_nd\u001b[39m(cond_proba, ins_1, ins_2, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m):\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;124;03m\"\"\" get deltas for vdm for multidimensional data\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    Parameters: cond_proba (dict) - a dictionary of conditional probability, extract from get_conditional_proba_nd()\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;124;03m    Returns: deltas (array) - the delta values between ins_1 and ins_2\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m     deltas \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[43mget_delta\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcond_proba\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mins_1\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mins_2\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m cond_proba])\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m deltas\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/vdm3/components.py:51\u001b[0m, in \u001b[0;36mget_delta\u001b[0;34m(cond_proba, val_1, val_2, norm)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_delta\u001b[39m(cond_proba, val_1, val_2, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m):\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;124;03m\"\"\" get delta for vdm\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \n\u001b[1;32m     44\u001b[0m \u001b[38;5;124;03m    Parameters: cond_proba (dict) - a dictionary of conditional probability, extract from get_conditional_proba()\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m    Returns: delta (float) - the delta value for this instance\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m     proba \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;28mabs\u001b[39m(cond_proba[val_1][uni_x] \u001b[38;5;241m-\u001b[39m cond_proba[val_2][uni_x]) \u001b[38;5;28;01mfor\u001b[39;00m uni_x \u001b[38;5;129;01min\u001b[39;00m \u001b[43mcond_proba\u001b[49m\u001b[43m[\u001b[49m\u001b[43mval_1\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mindex])\n\u001b[1;32m     52\u001b[0m     delta \u001b[38;5;241m=\u001b[39m (proba\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnorm)\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m delta\n",
      "\u001b[0;31mKeyError\u001b[0m: 3.0"
     ]
    }
   ],
   "source": [
    "# # Knn-VDM complete code\n",
    "# import time\n",
    "# start = time.time() # For measuring time execution\n",
    "\n",
    "# # specific the continuous columns index if any\n",
    "# vdm = ValueDifferenceMetric(x_train, y_train, continuous = None)\n",
    "# vdm.fit()\n",
    "# # Knn model, n_neigbour = 3, metrics = vdm\n",
    "# knn_vdm = KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')\n",
    "# ## Fit model\n",
    "# knn_vdm.fit(x_train, y_train)\n",
    "# # Testing\n",
    "# y_pred_knn = knn_vdm.predict(x_test)\n",
    "# knn_vdm.classes_\n",
    "# print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "# end = time.time()\n",
    "# print(f'Time for training model Knn-VDM, {disc}, k = {k} is: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a622e15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation result, accuracy, EWD, k = 7.\n",
      "ID3: - Mean: 0.818841, Standard deviation: 0.041290\n",
      "CNB: - Mean: nan, Standard deviation: nan\n",
      "Knn-VDM: - Mean: nan, Standard deviation: nan\n"
     ]
    }
   ],
   "source": [
    "# CROSS VALIDATION\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# param\n",
    "num_folds = 10\n",
    "num_repeat = 3\n",
    "seed = 7\n",
    "scores = 'accuracy'\n",
    "\n",
    "print(f'Cross validation result, {scores}, {disc}, k = {k}.')\n",
    "\n",
    "# Create list of algorithms\n",
    "models = []\n",
    "models.append(('ID3', Id3Estimator()))\n",
    "#models.append(('RIPPER', lw.RIPPER()))\n",
    "models.append(('CNB', CategoricalNB()))\n",
    "models.append(('Knn-VDM', KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')))\n",
    "\n",
    "# Evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "  #kfold = KFold(n_splits=num_folds, shuffle = True, random_state=10)\n",
    "    kfold = RepeatedKFold(n_splits=num_folds, n_repeats=num_repeat, random_state=seed)\n",
    "    cv_results = cross_val_score(model, X, Y, cv=kfold, scoring=scores)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = '%s: - Mean: %f, Standard deviation: %f' % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ad5fbb",
   "metadata": {},
   "source": [
    "### Evaluation, EWD, k=7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f189c70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import zero_one_loss\n",
    "#This library is used to decompose bias and variance in our models\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "16bb870b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.248\n",
      "Average bias: 0.225\n",
      "Average variance: 0.110\n",
      "Sklearn 0-1 loss: 0.243\n"
     ]
    }
   ],
   "source": [
    "# ID3\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "model_id3, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_id3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3e5d69dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.207\n",
      "Average bias: 0.214\n",
      "Average variance: 0.036\n",
      "Sklearn 0-1 loss: 0.208\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "model_nb, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c46eae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # WARINING: LONG TIME \n",
    "# # Knn-VDM\n",
    "# import time\n",
    "# start = time.time() # For measuring time execution\n",
    "\n",
    "# avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "# knn_vdm, x_train, y_train, x_test, y_test,\n",
    "# loss='0-1_loss',\n",
    "# random_seed=123)\n",
    "# #---\n",
    "# print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "# print('Average bias: %.3f' % avg_bias)\n",
    "# print('Average variance: %.3f' % avg_var)\n",
    "# print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_knn))\n",
    "\n",
    "# end = time.time()\n",
    "# print(f'Computing time:, {disc}, k = {k} is: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02fc4be",
   "metadata": {},
   "source": [
    "## 1.3 EWD, k = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "a8df6dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 690 entries, 0 to 689\n",
      "Data columns (total 15 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   A2      690 non-null    int64\n",
      " 1   A3      690 non-null    int64\n",
      " 2   A7      690 non-null    int64\n",
      " 3   A10     690 non-null    int64\n",
      " 4   A13     690 non-null    int64\n",
      " 5   A14     690 non-null    int64\n",
      " 6   A1      690 non-null    int64\n",
      " 7   A11     690 non-null    int64\n",
      " 8   A12     690 non-null    int64\n",
      " 9   A4      690 non-null    int64\n",
      " 10  A5      690 non-null    int64\n",
      " 11  A6      690 non-null    int64\n",
      " 12  A8      690 non-null    int64\n",
      " 13  A9      690 non-null    int64\n",
      " 14  label   690 non-null    int64\n",
      "dtypes: int64(15)\n",
      "memory usage: 81.0 KB\n",
      "(690, 14) (690,)\n",
      "Class representation - original:  Counter({0: 383, 1: 307})\n",
      "Class representation - training data:  Counter({0: 288, 1: 229})\n",
      "Class representation - testing data:  Counter({0: 95, 1: 78})\n"
     ]
    }
   ],
   "source": [
    "# Complete code for data preperation\n",
    "# Read data\n",
    "df_ewd3 = pd.read_csv('aus_ewd3.csv')\n",
    "disc = 'EWD'\n",
    "k = 10\n",
    "\n",
    "df_ewd3.info()\n",
    "data = df_ewd3.values\n",
    "data.shape\n",
    "\n",
    "features = df_ewd3.drop('label', axis = 1).columns\n",
    "\n",
    "# separate the data into X and y\n",
    "X = data[:, : len(features)]\n",
    "Y = data[:,-1]\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "# Split train test\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state = 30)\n",
    "\n",
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(Y)) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test)) \n",
    "\n",
    "# Check number of categories for features\n",
    "n_categories = df_ewd3[features].nunique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fb8398",
   "metadata": {},
   "source": [
    "### Models, EWD, k=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b8aad97f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.87      0.81        95\n",
      "           1       0.81      0.64      0.71        78\n",
      "\n",
      "    accuracy                           0.77       173\n",
      "   macro avg       0.78      0.76      0.76       173\n",
      "weighted avg       0.77      0.77      0.76       173\n",
      "\n",
      "Time for training model ID3 - default, EWD, k = 10 is: 0.11701393127441406.\n"
     ]
    }
   ],
   "source": [
    "# ID3 - Default\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "model_id3 = Id3Estimator()\n",
    "model_id3.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_id3 = model_id3.predict(x_test)\n",
    "print(classification_report(y_test, y_pred_id3))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model ID3 - default, {disc}, k = {k} is: {end - start}.') # Total time execution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "41c7f8db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.84      0.82        95\n",
      "           1       0.79      0.73      0.76        78\n",
      "\n",
      "    accuracy                           0.79       173\n",
      "   macro avg       0.79      0.79      0.79       173\n",
      "weighted avg       0.79      0.79      0.79       173\n",
      "\n",
      "Time for training model Naive Bayes - default, EWD, k = 7 is: 0.008220911026000977.\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes - min_categories = n_categories\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "model_nb = CategoricalNB(min_categories = n_categories)\n",
    "model_nb.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_nb = model_nb.predict(x_test)\n",
    "model_nb.classes_\n",
    "print(classification_report(y_test, y_pred_nb))\n",
    "end = time.time()\n",
    "print(f'Time for training model Naive Bayes - default, {disc}, k = {k} is: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "6ee86527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.81      0.79        95\n",
      "           1       0.76      0.72      0.74        78\n",
      "\n",
      "    accuracy                           0.77       173\n",
      "   macro avg       0.77      0.76      0.77       173\n",
      "weighted avg       0.77      0.77      0.77       173\n",
      "\n",
      "Time for training model Knn-VDM, EWD, k = 10 is: 45.563827991485596.\n"
     ]
    }
   ],
   "source": [
    "# Knn-VDM complete code\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "# specific the continuous columns index if any\n",
    "vdm = ValueDifferenceMetric(x_train, y_train, continuous = None)\n",
    "vdm.fit()\n",
    "# Knn model, n_neigbour = 3, metrics = vdm\n",
    "knn_vdm = KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')\n",
    "## Fit model\n",
    "knn_vdm.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_knn = knn_vdm.predict(x_test)\n",
    "knn_vdm.classes_\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model Knn-VDM, {disc}, k = {k} is: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "04538248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation result, accuracy, EWD, k = 10.\n",
      "ID3: - Mean: 0.817391, Standard deviation: 0.037718\n",
      "CNB: - Mean: nan, Standard deviation: nan\n",
      "Knn-VDM: - Mean: 0.849275, Standard deviation: 0.042927\n"
     ]
    }
   ],
   "source": [
    "# CROSS VALIDATION\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# param\n",
    "num_folds = 10\n",
    "num_repeat = 3\n",
    "seed = 7\n",
    "scores = 'accuracy'\n",
    "\n",
    "print(f'Cross validation result, {scores}, {disc}, k = {k}.')\n",
    "\n",
    "# Create list of algorithms\n",
    "models = []\n",
    "models.append(('ID3', Id3Estimator()))\n",
    "#models.append(('RIPPER', lw.RIPPER()))\n",
    "models.append(('CNB', CategoricalNB()))\n",
    "models.append(('Knn-VDM', KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')))\n",
    "\n",
    "# Evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "  #kfold = KFold(n_splits=num_folds, shuffle = True, random_state=10)\n",
    "    kfold = RepeatedKFold(n_splits=num_folds, n_repeats=num_repeat, random_state=seed)\n",
    "    cv_results = cross_val_score(model, X, Y, cv=kfold, scoring=scores)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = '%s: - Mean: %f, Standard deviation: %f' % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e3d5b0",
   "metadata": {},
   "source": [
    "### Evaluation, EWD, k=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "04071758",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import zero_one_loss\n",
    "#This library is used to decompose bias and variance in our models\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0d6d967f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.234\n",
      "Average bias: 0.185\n",
      "Average variance: 0.112\n",
      "Sklearn 0-1 loss: 0.231\n"
     ]
    }
   ],
   "source": [
    "# ID3\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "model_id3, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_id3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ece5f726",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 8 is out of bounds for axis 1 with size 8",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [62]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Naive Bayes\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m avg_expected_loss, avg_bias, avg_var \u001b[38;5;241m=\u001b[39m \u001b[43mbias_variance_decomp\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43mmodel_nb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m0-1_loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m123\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#---\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAverage expected loss: \u001b[39m\u001b[38;5;132;01m%.3f\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m avg_expected_loss)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/mlxtend/evaluate/bias_variance_decomp.py:131\u001b[0m, in \u001b[0;36mbias_variance_decomp\u001b[0;34m(estimator, X_train, y_train, X_test, y_test, loss, num_rounds, random_seed, **fit_params)\u001b[0m\n\u001b[1;32m    129\u001b[0m         pred \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mpredict(X_test)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 131\u001b[0m         pred \u001b[38;5;241m=\u001b[39m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_boot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_boot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m     all_pred[i] \u001b[38;5;241m=\u001b[39m pred\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loss \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0-1_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/naive_bayes.py:83\u001b[0m, in \u001b[0;36m_BaseNB.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     81\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m     82\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_X(X)\n\u001b[0;32m---> 83\u001b[0m jll \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_joint_log_likelihood\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_[np\u001b[38;5;241m.\u001b[39margmax(jll, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/naive_bayes.py:1461\u001b[0m, in \u001b[0;36mCategoricalNB._joint_log_likelihood\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1459\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_):\n\u001b[1;32m   1460\u001b[0m     indices \u001b[38;5;241m=\u001b[39m X[:, i]\n\u001b[0;32m-> 1461\u001b[0m     jll \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_log_prob_\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m   1462\u001b[0m total_ll \u001b[38;5;241m=\u001b[39m jll \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_log_prior_\n\u001b[1;32m   1463\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m total_ll\n",
      "\u001b[0;31mIndexError\u001b[0m: index 8 is out of bounds for axis 1 with size 8"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "model_nb, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "8f76bd6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.224\n",
      "Average bias: 0.214\n",
      "Average variance: 0.092\n",
      "Sklearn 0-1 loss: 0.231\n",
      "Computing time:, EWD, k = 10 is: 23212.079768896103.\n"
     ]
    }
   ],
   "source": [
    "# WARINING: LONG TIME \n",
    "# Knn-VDM\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "knn_vdm, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_knn))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Computing time:, {disc}, k = {k} is: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc73dbb8",
   "metadata": {},
   "source": [
    "# 2. EFD datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e0ab18",
   "metadata": {},
   "source": [
    "## 2.1 EFD, k = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "28f504b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 690 entries, 0 to 689\n",
      "Data columns (total 15 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   A2      690 non-null    int64\n",
      " 1   A3      690 non-null    int64\n",
      " 2   A7      690 non-null    int64\n",
      " 3   A10     690 non-null    int64\n",
      " 4   A13     690 non-null    int64\n",
      " 5   A14     690 non-null    int64\n",
      " 6   A1      690 non-null    int64\n",
      " 7   A11     690 non-null    int64\n",
      " 8   A12     690 non-null    int64\n",
      " 9   A4      690 non-null    int64\n",
      " 10  A5      690 non-null    int64\n",
      " 11  A6      690 non-null    int64\n",
      " 12  A8      690 non-null    int64\n",
      " 13  A9      690 non-null    int64\n",
      " 14  label   690 non-null    int64\n",
      "dtypes: int64(15)\n",
      "memory usage: 81.0 KB\n",
      "(690, 14) (690,)\n",
      "Class representation - original:  Counter({0: 383, 1: 307})\n",
      "Class representation - training data:  Counter({0: 288, 1: 229})\n",
      "Class representation - testing data:  Counter({0: 95, 1: 78})\n"
     ]
    }
   ],
   "source": [
    "# Complete code for data preperation\n",
    "# Read data\n",
    "df_efd1 = pd.read_csv('aus_efd1.csv')\n",
    "disc = 'EFD'\n",
    "k = 4\n",
    "\n",
    "df_efd1.info()\n",
    "data = df_efd1.values\n",
    "data.shape\n",
    "\n",
    "features = df_efd1.drop('label', axis = 1).columns\n",
    "\n",
    "# separate the data into X and y\n",
    "X = data[:, : len(features)]\n",
    "Y = data[:,-1]\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "# Split train test\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state = 30)\n",
    "\n",
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(Y)) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test)) \n",
    "\n",
    "# Check number of categories for features\n",
    "n_categories = df_efd1[features].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e54b64",
   "metadata": {},
   "source": [
    "### Models, EFD, k=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0e2f620c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.82      0.79        95\n",
      "           1       0.76      0.69      0.72        78\n",
      "\n",
      "    accuracy                           0.76       173\n",
      "   macro avg       0.76      0.76      0.76       173\n",
      "weighted avg       0.76      0.76      0.76       173\n",
      "\n",
      "Time for training model ID3 - default, EFD, k = 4 is: 0.08470487594604492.\n"
     ]
    }
   ],
   "source": [
    "# ID3 - Default\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "model_id3 = Id3Estimator()\n",
    "model_id3.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_id3 = model_id3.predict(x_test)\n",
    "print(classification_report(y_test, y_pred_id3))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model ID3 - default, {disc}, k = {k} is: {end - start}.') # Total time execution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5a9956d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.88      0.82        95\n",
      "           1       0.83      0.67      0.74        78\n",
      "\n",
      "    accuracy                           0.79       173\n",
      "   macro avg       0.79      0.78      0.78       173\n",
      "weighted avg       0.79      0.79      0.78       173\n",
      "\n",
      "Time for training model Naive Bayes - default, EFD, k = 4 is: 0.007628679275512695.\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes - min_categories\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "model_nb = CategoricalNB(min_categories = n_categories)\n",
    "model_nb.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_nb = model_nb.predict(x_test)\n",
    "model_nb.classes_\n",
    "print(classification_report(y_test, y_pred_nb))\n",
    "end = time.time()\n",
    "print(f'Time for training model Naive Bayes - default, {disc}, k = {k} is: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "4c2cb799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.85      0.80        95\n",
      "           1       0.79      0.67      0.72        78\n",
      "\n",
      "    accuracy                           0.77       173\n",
      "   macro avg       0.77      0.76      0.76       173\n",
      "weighted avg       0.77      0.77      0.77       173\n",
      "\n",
      "Time for training model Knn-VDM, EFD, k = 4 is: 45.63760209083557.\n"
     ]
    }
   ],
   "source": [
    "# Knn-VDM complete code\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "# specific the continuous columns index if any\n",
    "vdm = ValueDifferenceMetric(x_train, y_train, continuous = None)\n",
    "vdm.fit()\n",
    "# Knn model, n_neigbour = 3, metrics = vdm\n",
    "knn_vdm = KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')\n",
    "## Fit model\n",
    "knn_vdm.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_knn = knn_vdm.predict(x_test)\n",
    "knn_vdm.classes_\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model Knn-VDM, {disc}, k = {k} is: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2f189233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation result, accuracy, EFD, k = 4.\n",
      "ID3: - Mean: 0.812077, Standard deviation: 0.042416\n",
      "CNB: - Mean: nan, Standard deviation: nan\n",
      "Knn-VDM: - Mean: 0.851208, Standard deviation: 0.041658\n"
     ]
    }
   ],
   "source": [
    "# CROSS VALIDATION\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# param\n",
    "num_folds = 10\n",
    "num_repeat = 3\n",
    "seed = 7\n",
    "scores = 'accuracy'\n",
    "\n",
    "print(f'Cross validation result, {scores}, {disc}, k = {k}.')\n",
    "\n",
    "# Create list of algorithms\n",
    "models = []\n",
    "models.append(('ID3', Id3Estimator()))\n",
    "#models.append(('RIPPER', lw.RIPPER()))\n",
    "models.append(('CNB', CategoricalNB()))\n",
    "models.append(('Knn-VDM', KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')))\n",
    "\n",
    "# Evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "  #kfold = KFold(n_splits=num_folds, shuffle = True, random_state=10)\n",
    "    kfold = RepeatedKFold(n_splits=num_folds, n_repeats=num_repeat, random_state=seed)\n",
    "    cv_results = cross_val_score(model, X, Y, cv=kfold, scoring=scores)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = '%s: - Mean: %f, Standard deviation: %f' % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdc4f10",
   "metadata": {},
   "source": [
    "### Evaluation, EFD, k=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9fcda996",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import zero_one_loss\n",
    "#This library is used to decompose bias and variance in our models\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c22f894e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.235\n",
      "Average bias: 0.185\n",
      "Average variance: 0.123\n",
      "Sklearn 0-1 loss: 0.237\n"
     ]
    }
   ],
   "source": [
    "# ID3\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "model_id3, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_id3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "16ca99fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.221\n",
      "Average bias: 0.214\n",
      "Average variance: 0.027\n",
      "Sklearn 0-1 loss: 0.214\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "model_nb, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "6e9c6ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.232\n",
      "Average bias: 0.214\n",
      "Average variance: 0.087\n",
      "Sklearn 0-1 loss: 0.231\n",
      "Computing time:, EFD, k = 4 is: 43277.95894289017.\n"
     ]
    }
   ],
   "source": [
    "# WARINING: LONG TIME \n",
    "# Knn-VDM\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "knn_vdm, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_knn))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Computing time:, {disc}, k = {k} is: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927b824b",
   "metadata": {},
   "source": [
    "## 2.2 EFD, k = 7 (aus_efd2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "93449e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 690 entries, 0 to 689\n",
      "Data columns (total 15 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   A2      690 non-null    int64\n",
      " 1   A3      690 non-null    int64\n",
      " 2   A7      690 non-null    int64\n",
      " 3   A10     690 non-null    int64\n",
      " 4   A13     690 non-null    int64\n",
      " 5   A14     690 non-null    int64\n",
      " 6   A1      690 non-null    int64\n",
      " 7   A11     690 non-null    int64\n",
      " 8   A12     690 non-null    int64\n",
      " 9   A4      690 non-null    int64\n",
      " 10  A5      690 non-null    int64\n",
      " 11  A6      690 non-null    int64\n",
      " 12  A8      690 non-null    int64\n",
      " 13  A9      690 non-null    int64\n",
      " 14  label   690 non-null    int64\n",
      "dtypes: int64(15)\n",
      "memory usage: 81.0 KB\n",
      "(690, 14) (690,)\n",
      "Class representation - original:  Counter({0: 383, 1: 307})\n",
      "Class representation - training data:  Counter({0: 288, 1: 229})\n",
      "Class representation - testing data:  Counter({0: 95, 1: 78})\n"
     ]
    }
   ],
   "source": [
    "# Complete code for data preperation\n",
    "# Read data\n",
    "df_efd2 = pd.read_csv('aus_efd2.csv')\n",
    "disc = 'EFD'\n",
    "k = 7\n",
    "\n",
    "df_efd2.info()\n",
    "data = df_efd2.values\n",
    "data.shape\n",
    "\n",
    "features = df_efd2.drop('label', axis = 1).columns\n",
    "\n",
    "# separate the data into X and y\n",
    "X = data[:, : len(features)]\n",
    "Y = data[:,-1]\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "# Split train test\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state = 30)\n",
    "\n",
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(Y)) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test)) \n",
    "\n",
    "# Check number of categories for features\n",
    "n_categories = df_efd2[features].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e71c332",
   "metadata": {},
   "source": [
    "### Models, EFD, k=7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e3f82037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.82      0.79        95\n",
      "           1       0.76      0.69      0.72        78\n",
      "\n",
      "    accuracy                           0.76       173\n",
      "   macro avg       0.76      0.76      0.76       173\n",
      "weighted avg       0.76      0.76      0.76       173\n",
      "\n",
      "Time for training model ID3 - default, EFD, k = 7 is: 0.08503985404968262.\n"
     ]
    }
   ],
   "source": [
    "# ID3 - Default\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "model_id3 = Id3Estimator()\n",
    "model_id3.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_id3 = model_id3.predict(x_test)\n",
    "print(classification_report(y_test, y_pred_id3))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model ID3 - default, {disc}, k = {k} is: {end - start}.') # Total time execution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d0f76161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.88      0.82        95\n",
      "           1       0.83      0.67      0.74        78\n",
      "\n",
      "    accuracy                           0.79       173\n",
      "   macro avg       0.79      0.78      0.78       173\n",
      "weighted avg       0.79      0.79      0.78       173\n",
      "\n",
      "Time for training model Naive Bayes - default, EFD, k = 7 is: 0.007208824157714844.\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes - min_categories\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "model_nb = CategoricalNB(min_categories = n_categories)\n",
    "model_nb.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_nb = model_nb.predict(x_test)\n",
    "model_nb.classes_\n",
    "print(classification_report(y_test, y_pred_nb))\n",
    "end = time.time()\n",
    "print(f'Time for training model Naive Bayes - default, {disc}, k = {k} is: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "af033952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.85      0.80        95\n",
      "           1       0.79      0.67      0.72        78\n",
      "\n",
      "    accuracy                           0.77       173\n",
      "   macro avg       0.77      0.76      0.76       173\n",
      "weighted avg       0.77      0.77      0.77       173\n",
      "\n",
      "Time for training model Knn-VDM, EFD, k = 7 is: 41.25791263580322.\n"
     ]
    }
   ],
   "source": [
    "# Knn-VDM complete code\n",
    "# DONE\n",
    "# accuracy: 0.77 \n",
    "# time: 44.63345527648926.\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "# specific the continuous columns index if any\n",
    "vdm = ValueDifferenceMetric(x_train, y_train, continuous = None)\n",
    "vdm.fit()\n",
    "# Knn model, n_neigbour = 3, metrics = vdm\n",
    "knn_vdm = KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')\n",
    "## Fit model\n",
    "knn_vdm.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_knn = knn_vdm.predict(x_test)\n",
    "knn_vdm.classes_\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model Knn-VDM, {disc}, k = {k} is: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "28cd4145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation result, accuracy, EFD, k = 7.\n",
      "ID3: - Mean: 0.812077, Standard deviation: 0.042416\n",
      "CNB: - Mean: nan, Standard deviation: nan\n",
      "Knn-VDM: - Mean: 0.855072, Standard deviation: 0.037233\n"
     ]
    }
   ],
   "source": [
    "# CROSS VALIDATION\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# param\n",
    "num_folds = 10\n",
    "num_repeat = 3\n",
    "seed = 7\n",
    "scores = 'accuracy'\n",
    "\n",
    "print(f'Cross validation result, {scores}, {disc}, k = {k}.')\n",
    "\n",
    "# Create list of algorithms\n",
    "models = []\n",
    "models.append(('ID3', Id3Estimator()))\n",
    "#models.append(('RIPPER', lw.RIPPER()))\n",
    "models.append(('CNB', CategoricalNB()))\n",
    "models.append(('Knn-VDM', KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')))\n",
    "\n",
    "# Evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "  #kfold = KFold(n_splits=num_folds, shuffle = True, random_state=10)\n",
    "    kfold = RepeatedKFold(n_splits=num_folds, n_repeats=num_repeat, random_state=seed)\n",
    "    cv_results = cross_val_score(model, X, Y, cv=kfold, scoring=scores)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = '%s: - Mean: %f, Standard deviation: %f' % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e657de",
   "metadata": {},
   "source": [
    "### Evaluation, EFD, k=7 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b6b955ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import zero_one_loss\n",
    "#This library is used to decompose bias and variance in our models\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fbdde41d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.235\n",
      "Average bias: 0.185\n",
      "Average variance: 0.123\n",
      "Sklearn 0-1 loss: 0.237\n"
     ]
    }
   ],
   "source": [
    "# ID3\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "model_id3, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_id3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "53c068bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.221\n",
      "Average bias: 0.214\n",
      "Average variance: 0.027\n",
      "Sklearn 0-1 loss: 0.214\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "model_nb, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "d84dac77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.232\n",
      "Average bias: 0.214\n",
      "Average variance: 0.087\n",
      "Sklearn 0-1 loss: 0.231\n",
      "Computing time:, EFD, k = 7 is: 15698.569708108902.\n"
     ]
    }
   ],
   "source": [
    "# WARINING: LONG TIME \n",
    "# Knn-VDM\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "knn_vdm, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_knn))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Computing time:, {disc}, k = {k} is: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98edc4d0",
   "metadata": {},
   "source": [
    "## 2.3 EFD, k =10 (aus_efd3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "5b943a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 690 entries, 0 to 689\n",
      "Data columns (total 15 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   A2      690 non-null    int64\n",
      " 1   A3      690 non-null    int64\n",
      " 2   A7      690 non-null    int64\n",
      " 3   A10     690 non-null    int64\n",
      " 4   A13     690 non-null    int64\n",
      " 5   A14     690 non-null    int64\n",
      " 6   A1      690 non-null    int64\n",
      " 7   A11     690 non-null    int64\n",
      " 8   A12     690 non-null    int64\n",
      " 9   A4      690 non-null    int64\n",
      " 10  A5      690 non-null    int64\n",
      " 11  A6      690 non-null    int64\n",
      " 12  A8      690 non-null    int64\n",
      " 13  A9      690 non-null    int64\n",
      " 14  label   690 non-null    int64\n",
      "dtypes: int64(15)\n",
      "memory usage: 81.0 KB\n",
      "(690, 14) (690,)\n",
      "Class representation - original:  Counter({0: 383, 1: 307})\n",
      "Class representation - training data:  Counter({0: 288, 1: 229})\n",
      "Class representation - testing data:  Counter({0: 95, 1: 78})\n"
     ]
    }
   ],
   "source": [
    "# Complete code for data preperation\n",
    "# Read data\n",
    "df_efd3 = pd.read_csv('aus_efd3.csv')\n",
    "disc = 'EFD'\n",
    "k = 10\n",
    "\n",
    "df_efd3.info()\n",
    "data = df_efd3.values\n",
    "data.shape\n",
    "\n",
    "features = df_efd3.drop('label', axis = 1).columns\n",
    "\n",
    "# separate the data into X and y\n",
    "X = data[:, : len(features)]\n",
    "Y = data[:,-1]\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "# Split train test\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state = 30)\n",
    "\n",
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(Y)) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test))\n",
    "\n",
    "# Check number of categories for features\n",
    "n_categories = df_efd3[features].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1858e2a9",
   "metadata": {},
   "source": [
    "### Models, EFD, k=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2ee15b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.82      0.79        95\n",
      "           1       0.76      0.69      0.72        78\n",
      "\n",
      "    accuracy                           0.76       173\n",
      "   macro avg       0.76      0.76      0.76       173\n",
      "weighted avg       0.76      0.76      0.76       173\n",
      "\n",
      "Time for training model ID3 - default, EFD, k = 10 is: 0.07958078384399414.\n"
     ]
    }
   ],
   "source": [
    "# ID3 - Default\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "model_id3 = Id3Estimator()\n",
    "model_id3.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_id3 = model_id3.predict(x_test)\n",
    "print(classification_report(y_test, y_pred_id3))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model ID3 - default, {disc}, k = {k} is: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9a5a0e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.88      0.82        95\n",
      "           1       0.83      0.67      0.74        78\n",
      "\n",
      "    accuracy                           0.79       173\n",
      "   macro avg       0.79      0.78      0.78       173\n",
      "weighted avg       0.79      0.79      0.78       173\n",
      "\n",
      "Time for training model Naive Bayes - default, EFD, k = 10 is: 0.007249355316162109.\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes - min_categories\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "model_nb = CategoricalNB(min_categories = n_categories)\n",
    "model_nb.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_nb = model_nb.predict(x_test)\n",
    "model_nb.classes_\n",
    "print(classification_report(y_test, y_pred_nb))\n",
    "end = time.time()\n",
    "print(f'Time for training model Naive Bayes - default, {disc}, k = {k} is: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "4e81fdc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.85      0.80        95\n",
      "           1       0.79      0.67      0.72        78\n",
      "\n",
      "    accuracy                           0.77       173\n",
      "   macro avg       0.77      0.76      0.76       173\n",
      "weighted avg       0.77      0.77      0.77       173\n",
      "\n",
      "Time for training model Knn-VDM, EFD, k = 10 is: 42.22964096069336.\n"
     ]
    }
   ],
   "source": [
    "# Knn-VDM complete code\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "# specific the continuous columns index if any\n",
    "vdm = ValueDifferenceMetric(x_train, y_train, continuous = None)\n",
    "vdm.fit()\n",
    "# Knn model, n_neigbour = 3, metrics = vdm\n",
    "knn_vdm = KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')\n",
    "## Fit model\n",
    "knn_vdm.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_knn = knn_vdm.predict(x_test)\n",
    "knn_vdm.classes_\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model Knn-VDM, {disc}, k = {k} is: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8577aacb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation result, accuracy, EFD, k = 10.\n",
      "ID3: - Mean: 0.812077, Standard deviation: 0.042416\n",
      "CNB: - Mean: nan, Standard deviation: nan\n",
      "Knn-VDM: - Mean: 0.855072, Standard deviation: 0.037233\n"
     ]
    }
   ],
   "source": [
    "# CROSS VALIDATION\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# param\n",
    "num_folds = 10\n",
    "num_repeat = 3\n",
    "seed = 7\n",
    "scores = 'accuracy'\n",
    "\n",
    "print(f'Cross validation result, {scores}, {disc}, k = {k}.')\n",
    "\n",
    "# Create list of algorithms\n",
    "models = []\n",
    "models.append(('ID3', Id3Estimator()))\n",
    "#models.append(('RIPPER', lw.RIPPER()))\n",
    "models.append(('CNB', CategoricalNB()))\n",
    "models.append(('Knn-VDM', KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')))\n",
    "\n",
    "# Evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "  #kfold = KFold(n_splits=num_folds, shuffle = True, random_state=10)\n",
    "    kfold = RepeatedKFold(n_splits=num_folds, n_repeats=num_repeat, random_state=seed)\n",
    "    cv_results = cross_val_score(model, X, Y, cv=kfold, scoring=scores)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = '%s: - Mean: %f, Standard deviation: %f' % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44b941e",
   "metadata": {},
   "source": [
    "### Evaluation, EFD, k=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ee9acb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import zero_one_loss\n",
    "#This library is used to decompose bias and variance in our models\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "cea06f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.235\n",
      "Average bias: 0.185\n",
      "Average variance: 0.123\n",
      "Sklearn 0-1 loss: 0.237\n"
     ]
    }
   ],
   "source": [
    "# ID3\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "model_id3, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_id3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a7cb11eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.221\n",
      "Average bias: 0.214\n",
      "Average variance: 0.027\n",
      "Sklearn 0-1 loss: 0.214\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "model_nb, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "d97a0099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.232\n",
      "Average bias: 0.214\n",
      "Average variance: 0.087\n",
      "Sklearn 0-1 loss: 0.231\n",
      "Computing time:, EFD, k = 10 is: 26336.05382823944.\n"
     ]
    }
   ],
   "source": [
    "# WARINING: LONG TIME \n",
    "# Knn-VDM\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "knn_vdm, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_knn))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Computing time:, {disc}, k = {k} is: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e44dc0",
   "metadata": {},
   "source": [
    "# 3. FFD datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c05353",
   "metadata": {},
   "source": [
    "## 3.1 FFD, m =10 (aus_ffd1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "5c0cc369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 690 entries, 0 to 689\n",
      "Data columns (total 15 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   A2      690 non-null    int64\n",
      " 1   A3      690 non-null    int64\n",
      " 2   A7      690 non-null    int64\n",
      " 3   A10     690 non-null    int64\n",
      " 4   A13     690 non-null    int64\n",
      " 5   A14     690 non-null    int64\n",
      " 6   A1      690 non-null    int64\n",
      " 7   A11     690 non-null    int64\n",
      " 8   A12     690 non-null    int64\n",
      " 9   A4      690 non-null    int64\n",
      " 10  A5      690 non-null    int64\n",
      " 11  A6      690 non-null    int64\n",
      " 12  A8      690 non-null    int64\n",
      " 13  A9      690 non-null    int64\n",
      " 14  label   690 non-null    int64\n",
      "dtypes: int64(15)\n",
      "memory usage: 81.0 KB\n",
      "(690, 14) (690,)\n",
      "Class representation - original:  Counter({0: 383, 1: 307})\n",
      "Class representation - training data:  Counter({0: 288, 1: 229})\n",
      "Class representation - testing data:  Counter({0: 95, 1: 78})\n"
     ]
    }
   ],
   "source": [
    "# Complete code for data preperation\n",
    "# Read data\n",
    "df_ffd1 = pd.read_csv('aus_ffd1.csv')\n",
    "disc = 'FFD'\n",
    "m = 10\n",
    "\n",
    "df_ffd1.info()\n",
    "data = df_ffd1.values\n",
    "data.shape\n",
    "\n",
    "features = df_ffd1.drop('label', axis = 1).columns\n",
    "\n",
    "# separate the data into X and y\n",
    "X = data[:, : len(features)]\n",
    "Y = data[:,-1]\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "# Split train test\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state = 30)\n",
    "\n",
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(Y)) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test)) \n",
    "\n",
    "# Check number of categories for features\n",
    "n_categories = df_ffd1[features].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972d16c9",
   "metadata": {},
   "source": [
    "### Models, FFD, m=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1e430c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.83      0.79        95\n",
      "           1       0.76      0.67      0.71        78\n",
      "\n",
      "    accuracy                           0.76       173\n",
      "   macro avg       0.76      0.75      0.75       173\n",
      "weighted avg       0.76      0.76      0.75       173\n",
      "\n",
      "Time for training model ID3 - default, FFD, m = 10 is: 0.18407702445983887.\n"
     ]
    }
   ],
   "source": [
    "# ID3 - Default\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "model_id3 = Id3Estimator()\n",
    "model_id3.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_id3 = model_id3.predict(x_test)\n",
    "print(classification_report(y_test, y_pred_id3))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model ID3 - default, {disc}, m = {m} is: {end - start}.') # Total time execution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "36973d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.87      0.81        95\n",
      "           1       0.81      0.64      0.71        78\n",
      "\n",
      "    accuracy                           0.77       173\n",
      "   macro avg       0.78      0.76      0.76       173\n",
      "weighted avg       0.77      0.77      0.76       173\n",
      "\n",
      "Time for training model Naive Bayes - default, FFD, m = 10 is: 0.006767749786376953.\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes - min_categories\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "model_nb = CategoricalNB(min_categories = n_categories)\n",
    "model_nb.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_nb = model_nb.predict(x_test)\n",
    "model_nb.classes_\n",
    "print(classification_report(y_test, y_pred_nb))\n",
    "end = time.time()\n",
    "print(f'Time for training model Naive Bayes - default, {disc}, m = {m} is: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "b0ee4624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.84      0.80        95\n",
      "           1       0.78      0.69      0.73        78\n",
      "\n",
      "    accuracy                           0.77       173\n",
      "   macro avg       0.78      0.77      0.77       173\n",
      "weighted avg       0.78      0.77      0.77       173\n",
      "\n",
      "Time for training model Knn-VDM, FFD, m = 10 is: 44.93128705024719.\n"
     ]
    }
   ],
   "source": [
    "# Knn-VDM complete code\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "# specific the continuous columns index if any\n",
    "vdm = ValueDifferenceMetric(x_train, y_train, continuous = None)\n",
    "vdm.fit()\n",
    "# Knn model, n_neigbour = 3, metrics = vdm\n",
    "knn_vdm = KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')\n",
    "## Fit model\n",
    "knn_vdm.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_knn = knn_vdm.predict(x_test)\n",
    "knn_vdm.classes_\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model Knn-VDM, {disc}, m = {m} is: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1de574df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation result, accuracy, FFD, m = 10.\n",
      "ID3: - Mean: 0.835266, Standard deviation: 0.034395\n",
      "CNB: - Mean: nan, Standard deviation: nan\n",
      "Knn-VDM: - Mean: nan, Standard deviation: nan\n"
     ]
    }
   ],
   "source": [
    "# CROSS VALIDATION\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# param\n",
    "num_folds = 10\n",
    "num_repeat = 3\n",
    "seed = 7\n",
    "scores = 'accuracy'\n",
    "\n",
    "print(f'Cross validation result, {scores}, {disc}, m = {m}.')\n",
    "\n",
    "# Create list of algorithms\n",
    "models = []\n",
    "models.append(('ID3', Id3Estimator()))\n",
    "#models.append(('RIPPER', lw.RIPPER()))\n",
    "models.append(('CNB', CategoricalNB()))\n",
    "models.append(('Knn-VDM', KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')))\n",
    "\n",
    "# Evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "  #kfold = KFold(n_splits=num_folds, shuffle = True, random_state=10)\n",
    "    kfold = RepeatedKFold(n_splits=num_folds, n_repeats=num_repeat, random_state=seed)\n",
    "    cv_results = cross_val_score(model, X, Y, cv=kfold, scoring=scores)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = '%s: - Mean: %f, Standard deviation: %f' % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68810e10",
   "metadata": {},
   "source": [
    "### Evaluation, FFD, m=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "401cdcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import zero_one_loss\n",
    "#This library is used to decompose bias and variance in our models\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "408180c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.246\n",
      "Average bias: 0.225\n",
      "Average variance: 0.124\n",
      "Sklearn 0-1 loss: 0.243\n"
     ]
    }
   ],
   "source": [
    "# ID3\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "model_id3, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_id3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9eae8829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.222\n",
      "Average bias: 0.231\n",
      "Average variance: 0.055\n",
      "Sklearn 0-1 loss: 0.231\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "model_nb, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "e6f33386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.230\n",
      "Average bias: 0.214\n",
      "Average variance: 0.077\n",
      "Sklearn 0-1 loss: 0.225\n",
      "Computing time:, FFD, k = 10 is: 9381.151834011078.\n"
     ]
    }
   ],
   "source": [
    "# WARINING: LONG TIME \n",
    "# Knn-VDM\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "knn_vdm, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_knn))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Computing time:, {disc}, k = {k} is: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd83852",
   "metadata": {},
   "source": [
    "## 3.2 FFD, m = 30 (aus_ffd2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "3f144105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 690 entries, 0 to 689\n",
      "Data columns (total 15 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   A2      690 non-null    int64\n",
      " 1   A3      690 non-null    int64\n",
      " 2   A7      690 non-null    int64\n",
      " 3   A10     690 non-null    int64\n",
      " 4   A13     690 non-null    int64\n",
      " 5   A14     690 non-null    int64\n",
      " 6   A1      690 non-null    int64\n",
      " 7   A11     690 non-null    int64\n",
      " 8   A12     690 non-null    int64\n",
      " 9   A4      690 non-null    int64\n",
      " 10  A5      690 non-null    int64\n",
      " 11  A6      690 non-null    int64\n",
      " 12  A8      690 non-null    int64\n",
      " 13  A9      690 non-null    int64\n",
      " 14  label   690 non-null    int64\n",
      "dtypes: int64(15)\n",
      "memory usage: 81.0 KB\n",
      "(690, 14) (690,)\n",
      "Class representation - original:  Counter({0: 383, 1: 307})\n",
      "Class representation - training data:  Counter({0: 288, 1: 229})\n",
      "Class representation - testing data:  Counter({0: 95, 1: 78})\n"
     ]
    }
   ],
   "source": [
    "# Complete code for data preperation\n",
    "# Read data\n",
    "df_ffd2 = pd.read_csv('aus_ffd2.csv')\n",
    "disc = 'FFD'\n",
    "m = 30\n",
    "\n",
    "df_ffd2.info()\n",
    "data = df_ffd2.values\n",
    "data.shape\n",
    "\n",
    "features = df_ffd2.drop('label', axis = 1).columns\n",
    "\n",
    "# separate the data into X and y\n",
    "X = data[:, : len(features)]\n",
    "Y = data[:,-1]\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "# Split train test\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state = 30)\n",
    "\n",
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(Y)) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test))\n",
    "\n",
    "# Check number of categories for features\n",
    "n_categories = df_ffd2[features].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95e6ba5",
   "metadata": {},
   "source": [
    "### Models, FFD, m=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "593d778f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.80      0.77        95\n",
      "           1       0.73      0.67      0.70        78\n",
      "\n",
      "    accuracy                           0.74       173\n",
      "   macro avg       0.74      0.73      0.73       173\n",
      "weighted avg       0.74      0.74      0.74       173\n",
      "\n",
      "Time for training model ID3 - default, FFD, m = 30 is: 0.13190603256225586.\n"
     ]
    }
   ],
   "source": [
    "# ID3 - Default\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "model_id3 = Id3Estimator()\n",
    "model_id3.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_id3 = model_id3.predict(x_test)\n",
    "print(classification_report(y_test, y_pred_id3))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model ID3 - default, {disc}, m = {m} is: {end - start}.') # Total time execution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1378e6b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.88      0.82        95\n",
      "           1       0.83      0.67      0.74        78\n",
      "\n",
      "    accuracy                           0.79       173\n",
      "   macro avg       0.79      0.78      0.78       173\n",
      "weighted avg       0.79      0.79      0.78       173\n",
      "\n",
      "Time for training model Naive Bayes - default, FFD, m = 30 is: 0.008085012435913086.\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes - min_categories\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "model_nb = CategoricalNB(min_categories = n_categories)\n",
    "model_nb.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_nb = model_nb.predict(x_test)\n",
    "model_nb.classes_\n",
    "print(classification_report(y_test, y_pred_nb))\n",
    "end = time.time()\n",
    "print(f'Time for training model Naive Bayes - default, {disc}, m = {m} is: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "d3f75c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.85      0.83        95\n",
      "           1       0.81      0.74      0.77        78\n",
      "\n",
      "    accuracy                           0.80       173\n",
      "   macro avg       0.80      0.80      0.80       173\n",
      "weighted avg       0.80      0.80      0.80       173\n",
      "\n",
      "Time for training model Knn-VDM, FFD, m = 30 is: 41.25654697418213.\n"
     ]
    }
   ],
   "source": [
    "# Knn-VDM complete code\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "# specific the continuous columns index if any\n",
    "vdm = ValueDifferenceMetric(x_train, y_train, continuous = None)\n",
    "vdm.fit()\n",
    "# Knn model, n_neigbour = 3, metrics = vdm\n",
    "knn_vdm = KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')\n",
    "## Fit model\n",
    "knn_vdm.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_knn = knn_vdm.predict(x_test)\n",
    "knn_vdm.classes_\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model Knn-VDM, {disc}, m = {m} is: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7a93d105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation result, accuracy, FFD, m = 30.\n",
      "ID3: - Mean: 0.833816, Standard deviation: 0.038840\n",
      "CNB: - Mean: nan, Standard deviation: nan\n",
      "Knn-VDM: - Mean: nan, Standard deviation: nan\n"
     ]
    }
   ],
   "source": [
    "# CROSS VALIDATION\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# param\n",
    "num_folds = 10\n",
    "num_repeat = 3\n",
    "seed = 7\n",
    "scores = 'accuracy'\n",
    "\n",
    "print(f'Cross validation result, {scores}, {disc}, m = {m}.')\n",
    "\n",
    "# Create list of algorithms\n",
    "models = []\n",
    "models.append(('ID3', Id3Estimator()))\n",
    "#models.append(('RIPPER', lw.RIPPER()))\n",
    "models.append(('CNB', CategoricalNB()))\n",
    "models.append(('Knn-VDM', KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')))\n",
    "\n",
    "# Evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "  #kfold = KFold(n_splits=num_folds, shuffle = True, random_state=10)\n",
    "    kfold = RepeatedKFold(n_splits=num_folds, n_repeats=num_repeat, random_state=seed)\n",
    "    cv_results = cross_val_score(model, X, Y, cv=kfold, scoring=scores)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = '%s: - Mean: %f, Standard deviation: %f' % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ddd0bf",
   "metadata": {},
   "source": [
    "### Evaluation, FFD, m=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6a695eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import zero_one_loss\n",
    "#This library is used to decompose bias and variance in our models\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "46ba3704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.244\n",
      "Average bias: 0.225\n",
      "Average variance: 0.123\n",
      "Sklearn 0-1 loss: 0.260\n"
     ]
    }
   ],
   "source": [
    "# ID3\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "model_id3, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_id3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5078a5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.215\n",
      "Average bias: 0.214\n",
      "Average variance: 0.039\n",
      "Sklearn 0-1 loss: 0.214\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "model_nb, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "87f01a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.217\n",
      "Average bias: 0.197\n",
      "Average variance: 0.089\n",
      "Sklearn 0-1 loss: 0.197\n",
      "Computing time:, FFD, k = 10 is: 58174.83967471123.\n"
     ]
    }
   ],
   "source": [
    "# WARINING: LONG TIME \n",
    "# Knn-VDM\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "knn_vdm, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_knn))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Computing time:, {disc}, k = {k} is: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3445e377",
   "metadata": {},
   "source": [
    "## 3.3 FFD, m = 60 (aus_ffd3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "d71ed2f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 690 entries, 0 to 689\n",
      "Data columns (total 15 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   A2      690 non-null    int64\n",
      " 1   A3      690 non-null    int64\n",
      " 2   A7      690 non-null    int64\n",
      " 3   A10     690 non-null    int64\n",
      " 4   A13     690 non-null    int64\n",
      " 5   A14     690 non-null    int64\n",
      " 6   A1      690 non-null    int64\n",
      " 7   A11     690 non-null    int64\n",
      " 8   A12     690 non-null    int64\n",
      " 9   A4      690 non-null    int64\n",
      " 10  A5      690 non-null    int64\n",
      " 11  A6      690 non-null    int64\n",
      " 12  A8      690 non-null    int64\n",
      " 13  A9      690 non-null    int64\n",
      " 14  label   690 non-null    int64\n",
      "dtypes: int64(15)\n",
      "memory usage: 81.0 KB\n",
      "(690, 14) (690,)\n",
      "Class representation - original:  Counter({0: 383, 1: 307})\n",
      "Class representation - training data:  Counter({0: 288, 1: 229})\n",
      "Class representation - testing data:  Counter({0: 95, 1: 78})\n"
     ]
    }
   ],
   "source": [
    "# Complete code for data preperation\n",
    "# Read data\n",
    "df_ffd3 = pd.read_csv('aus_ffd3.csv')\n",
    "disc = 'FFD'\n",
    "m = 60\n",
    "\n",
    "df_ffd3.info()\n",
    "data = df_ffd3.values\n",
    "data.shape\n",
    "\n",
    "features = df_ffd3.drop('label', axis = 1).columns\n",
    "\n",
    "# separate the data into X and y\n",
    "X = data[:, : len(features)]\n",
    "Y = data[:,-1]\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "# Split train test\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state = 30)\n",
    "\n",
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(Y)) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test)) \n",
    "\n",
    "# Check number of categories for features\n",
    "n_categories = df_ffd3[features].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b47ec4",
   "metadata": {},
   "source": [
    "### Models, FFD, m= 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "97dd147b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.78        95\n",
      "           1       0.75      0.67      0.71        78\n",
      "\n",
      "    accuracy                           0.75       173\n",
      "   macro avg       0.75      0.74      0.75       173\n",
      "weighted avg       0.75      0.75      0.75       173\n",
      "\n",
      "Time for training model ID3 - default, FFD, m = 60 is: 0.10687708854675293.\n"
     ]
    }
   ],
   "source": [
    "# ID3 - Default\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "model_id3 = Id3Estimator()\n",
    "model_id3.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_id3 = model_id3.predict(x_test)\n",
    "print(classification_report(y_test, y_pred_id3))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model ID3 - default, {disc}, m = {m} is: {end - start}.') # Total time execution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9eecf8a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.87      0.81        95\n",
      "           1       0.81      0.65      0.72        78\n",
      "\n",
      "    accuracy                           0.77       173\n",
      "   macro avg       0.78      0.76      0.77       173\n",
      "weighted avg       0.78      0.77      0.77       173\n",
      "\n",
      "Time for training model Naive Bayes - min_categories, FFD, m = 60 is: 0.0066378116607666016.\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes - min_categories\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "model_nb = CategoricalNB(min_categories = n_categories)\n",
    "model_nb.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_nb = model_nb.predict(x_test)\n",
    "model_nb.classes_\n",
    "print(classification_report(y_test, y_pred_nb))\n",
    "end = time.time()\n",
    "print(f'Time for training model Naive Bayes - min_categories, {disc}, m = {m} is: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "bf64f183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.85      0.81        95\n",
      "           1       0.80      0.71      0.75        78\n",
      "\n",
      "    accuracy                           0.79       173\n",
      "   macro avg       0.79      0.78      0.78       173\n",
      "weighted avg       0.79      0.79      0.78       173\n",
      "\n",
      "Time for training model Knn-VDM, FFD, m = 60 is: 46.37032079696655.\n"
     ]
    }
   ],
   "source": [
    "# Knn-VDM complete code\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "# specific the continuous columns index if any\n",
    "vdm = ValueDifferenceMetric(x_train, y_train, continuous = None)\n",
    "vdm.fit()\n",
    "# Knn model, n_neigbour = 3, metrics = vdm\n",
    "knn_vdm = KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')\n",
    "## Fit model\n",
    "knn_vdm.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_knn = knn_vdm.predict(x_test)\n",
    "knn_vdm.classes_\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model Knn-VDM, {disc}, m = {m} is: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "173ecf99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation result, accuracy, FFD, m = 60.\n",
      "ID3: - Mean: 0.825121, Standard deviation: 0.042818\n",
      "CNB: - Mean: nan, Standard deviation: nan\n",
      "Knn-VDM: - Mean: 0.852174, Standard deviation: 0.044966\n"
     ]
    }
   ],
   "source": [
    "# CROSS VALIDATION\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# param\n",
    "num_folds = 10\n",
    "num_repeat = 3\n",
    "seed = 7\n",
    "scores = 'accuracy'\n",
    "\n",
    "print(f'Cross validation result, {scores}, {disc}, m = {m}.')\n",
    "\n",
    "# Create list of algorithms\n",
    "models = []\n",
    "models.append(('ID3', Id3Estimator()))\n",
    "#models.append(('RIPPER', lw.RIPPER()))\n",
    "models.append(('CNB', CategoricalNB()))\n",
    "models.append(('Knn-VDM', KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')))\n",
    "\n",
    "# Evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "  #kfold = KFold(n_splits=num_folds, shuffle = True, random_state=10)\n",
    "    kfold = RepeatedKFold(n_splits=num_folds, n_repeats=num_repeat, random_state=seed)\n",
    "    cv_results = cross_val_score(model, X, Y, cv=kfold, scoring=scores)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = '%s: - Mean: %f, Standard deviation: %f' % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70a902b",
   "metadata": {},
   "source": [
    "### Evaluation, FFD, m=60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f7519ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import zero_one_loss\n",
    "#This library is used to decompose bias and variance in our models\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f67bb518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.238\n",
      "Average bias: 0.185\n",
      "Average variance: 0.128\n",
      "Sklearn 0-1 loss: 0.249\n"
     ]
    }
   ],
   "source": [
    "# ID3\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "model_id3, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_id3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "83853192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.221\n",
      "Average bias: 0.220\n",
      "Average variance: 0.042\n",
      "Sklearn 0-1 loss: 0.225\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "model_nb, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "ad81b549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.225\n",
      "Average bias: 0.191\n",
      "Average variance: 0.086\n",
      "Sklearn 0-1 loss: 0.214\n",
      "Computing time:, FFD, k = 10 is: 21325.722386837006.\n"
     ]
    }
   ],
   "source": [
    "# WARINING: LONG TIME \n",
    "# Knn-VDM\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "knn_vdm, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_knn))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Computing time:, {disc}, k = {k} is: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7250ca",
   "metadata": {},
   "source": [
    "## 3.4 FFD, m = 100 (aus_ffd4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "1378e94d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 690 entries, 0 to 689\n",
      "Data columns (total 15 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   A2      690 non-null    int64\n",
      " 1   A3      690 non-null    int64\n",
      " 2   A7      690 non-null    int64\n",
      " 3   A10     690 non-null    int64\n",
      " 4   A13     690 non-null    int64\n",
      " 5   A14     690 non-null    int64\n",
      " 6   A1      690 non-null    int64\n",
      " 7   A11     690 non-null    int64\n",
      " 8   A12     690 non-null    int64\n",
      " 9   A4      690 non-null    int64\n",
      " 10  A5      690 non-null    int64\n",
      " 11  A6      690 non-null    int64\n",
      " 12  A8      690 non-null    int64\n",
      " 13  A9      690 non-null    int64\n",
      " 14  label   690 non-null    int64\n",
      "dtypes: int64(15)\n",
      "memory usage: 81.0 KB\n",
      "(690, 14) (690,)\n",
      "Class representation - original:  Counter({0: 383, 1: 307})\n",
      "Class representation - training data:  Counter({0: 288, 1: 229})\n",
      "Class representation - testing data:  Counter({0: 95, 1: 78})\n"
     ]
    }
   ],
   "source": [
    "# Complete code for data preperation\n",
    "# Read data\n",
    "df_ffd4 = pd.read_csv('aus_ffd4.csv')\n",
    "disc = 'FFD'\n",
    "m = 100\n",
    "\n",
    "df_ffd4.info()\n",
    "data = df_ffd4.values\n",
    "data.shape\n",
    "\n",
    "features = df_ffd4.drop('label', axis = 1).columns\n",
    "\n",
    "# separate the data into X and y\n",
    "X = data[:, : len(features)]\n",
    "Y = data[:,-1]\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "# Split train test\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state = 30)\n",
    "\n",
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(Y)) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test)) \n",
    "\n",
    "# Check number of categories for features\n",
    "n_categories = df_ffd4[features].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f30af4",
   "metadata": {},
   "source": [
    "### Models, FFD, m=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "e343591d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.79      0.77        95\n",
      "           1       0.72      0.67      0.69        78\n",
      "\n",
      "    accuracy                           0.73       173\n",
      "   macro avg       0.73      0.73      0.73       173\n",
      "weighted avg       0.73      0.73      0.73       173\n",
      "\n",
      "Time for training model ID3 - default, FFD, m = 100 is: 0.09049105644226074.\n"
     ]
    }
   ],
   "source": [
    "# ID3 - Default\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "model_id3 = Id3Estimator()\n",
    "model_id3.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_id3 = model_id3.predict(x_test)\n",
    "print(classification_report(y_test, y_pred_id3))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model ID3 - default, {disc}, m = {m} is: {end - start}.') # Total time execution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a73ae0a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.86      0.81        95\n",
      "           1       0.80      0.67      0.73        78\n",
      "\n",
      "    accuracy                           0.77       173\n",
      "   macro avg       0.78      0.76      0.77       173\n",
      "weighted avg       0.78      0.77      0.77       173\n",
      "\n",
      "Time for training model Naive Bayes - min_categories, FFD, m = 100 is: 0.007467985153198242.\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes - min_categories = n_categories\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "model_nb = CategoricalNB(min_categories = n_categories)\n",
    "model_nb.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_nb = model_nb.predict(x_test)\n",
    "model_nb.classes_\n",
    "print(classification_report(y_test, y_pred_nb))\n",
    "end = time.time()\n",
    "print(f'Time for training model Naive Bayes - min_categories, {disc}, m = {m} is: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "ee9b0c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.89      0.84        95\n",
      "           1       0.85      0.71      0.77        78\n",
      "\n",
      "    accuracy                           0.81       173\n",
      "   macro avg       0.82      0.80      0.80       173\n",
      "weighted avg       0.81      0.81      0.81       173\n",
      "\n",
      "Time for training model Knn-VDM, FFD, m = 100 is: 43.647905111312866.\n"
     ]
    }
   ],
   "source": [
    "# Knn-VDM complete code\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "# specific the continuous columns index if any\n",
    "vdm = ValueDifferenceMetric(x_train, y_train, continuous = None)\n",
    "vdm.fit()\n",
    "# Knn model, n_neigbour = 3, metrics = vdm\n",
    "knn_vdm = KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')\n",
    "## Fit model\n",
    "knn_vdm.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_knn = knn_vdm.predict(x_test)\n",
    "knn_vdm.classes_\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model Knn-VDM, {disc}, m = {m} is: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "f26baa66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation result, accuracy, FFD, m = 100.\n",
      "ID3: - Mean: 0.823188, Standard deviation: 0.042071\n",
      "CNB: - Mean: nan, Standard deviation: nan\n",
      "Knn-VDM: - Mean: 0.871014, Standard deviation: 0.033123\n"
     ]
    }
   ],
   "source": [
    "# CROSS VALIDATION\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# param\n",
    "num_folds = 10\n",
    "num_repeat = 3\n",
    "seed = 7\n",
    "scores = 'accuracy'\n",
    "\n",
    "print(f'Cross validation result, {scores}, {disc}, m = {m}.')\n",
    "\n",
    "# Create list of algorithms\n",
    "models = []\n",
    "models.append(('ID3', Id3Estimator()))\n",
    "#models.append(('RIPPER', lw.RIPPER()))\n",
    "models.append(('CNB', CategoricalNB()))\n",
    "models.append(('Knn-VDM', KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')))\n",
    "\n",
    "# Evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "  #kfold = KFold(n_splits=num_folds, shuffle = True, random_state=10)\n",
    "    kfold = RepeatedKFold(n_splits=num_folds, n_repeats=num_repeat, random_state=seed)\n",
    "    cv_results = cross_val_score(model, X, Y, cv=kfold, scoring=scores)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = '%s: - Mean: %f, Standard deviation: %f' % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee887608",
   "metadata": {},
   "source": [
    "### Evaluation, FFD, m=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a8ddeb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import zero_one_loss\n",
    "#This library is used to decompose bias and variance in our models\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b84d2fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.236\n",
      "Average bias: 0.202\n",
      "Average variance: 0.128\n",
      "Sklearn 0-1 loss: 0.266\n"
     ]
    }
   ],
   "source": [
    "# ID3\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "model_id3, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_id3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "03e874f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.224\n",
      "Average bias: 0.237\n",
      "Average variance: 0.030\n",
      "Sklearn 0-1 loss: 0.225\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "model_nb, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "f0d74244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.213\n",
      "Average bias: 0.202\n",
      "Average variance: 0.082\n",
      "Sklearn 0-1 loss: 0.191\n",
      "Computing time:, FFD, k = 10 is: 49172.59988498688.\n"
     ]
    }
   ],
   "source": [
    "# WARINING: LONG TIME \n",
    "# Knn-VDM\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "knn_vdm, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_knn))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Computing time:, {disc}, k = {k} is: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed68cc47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
