{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abd2336c",
   "metadata": {},
   "source": [
    "# Classification models - Supervised Discretization\n",
    "## Dataset: australia <br>\n",
    "\n",
    "Updated by: Sam\n",
    "Update at: 13/10/2022 <br>\n",
    "---\n",
    "Discretization methods: Decision Tree <br>\n",
    "Classification models: CNB, ID3, KNN-VDM\n",
    "---\n",
    "NOTE: \n",
    "Long time for computation of Knn-VDM (Run this part last) <br>\n",
    "Use Malina scripts for Knn, ID3 <br>\n",
    "Use Sam scripts (with min_categories) for Naive Bayes <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83bc40c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, roc_auc_score, recall_score, precision_score\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "import six\n",
    "import sys\n",
    "sys.modules['sklearn.externals.six'] = six\n",
    "import id3\n",
    "from id3 import Id3Estimator\n",
    "from id3 import export_graphviz\n",
    "import wittgenstein as lw\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "from pandas import set_option\n",
    "import numpy as np\n",
    "from numpy import arange\n",
    "## EDA\n",
    "from collections import Counter\n",
    "\n",
    "# Knn-VDM 3\n",
    "from vdm3 import ValueDifferenceMetric\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Pre-processing\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "# Cross validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score # 1 metric\n",
    "from sklearn.model_selection import cross_validate # more than 1 metric\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50eb04fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in data from Decisiton Tree discretization\n",
    "aus_m2 = pd.read_csv('DT_small_discretized_aus.csv') # max_depth = 2\n",
    "aus_m3 = pd.read_csv('DT_medium_discretized_aus.csv') # max_depth = 3\n",
    "aus_m4 = pd.read_csv('DT_large_discretized_aus.csv') # max_depth = 4\n",
    "aus_m5 = pd.read_csv('DT_verylarge_discretized_aus.csv') # max_depth = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24075c8",
   "metadata": {},
   "source": [
    "## Interval frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94258ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_list_m2 = [\"A2\", \"A3\", \"A7\", \"A10\", \"A13\", \"A14\"]\n",
    "num_list_m3 = [\"A2\", \"A3\", \"A7\", \"A10\", \"A13\", \"A14\"]\n",
    "num_list_m4 = [\"A2\", \"A3\", \"A7\", \"A10\", \"A13\", \"A14\"]\n",
    "num_list_m5 = [\"A2\", \"A3\", \"A7\", \"A10\", \"A13\", \"A14\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be896d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interval frequency for 6 Intervals\n",
      "Interval for A2\n",
      "Counter({1: 459, 2: 141, 0: 53, 3: 37})\n",
      "Interval for A3\n",
      "Counter({0: 396, 2: 236, 1: 46, 3: 12})\n",
      "Interval for A7\n",
      "Counter({2: 301, 0: 296, 1: 77, 3: 16})\n",
      "Interval for A10\n",
      "Counter({0: 395, 3: 136, 1: 116, 2: 43})\n",
      "Interval for A13\n",
      "Counter({0: 382, 1: 146, 2: 136, 3: 26})\n",
      "Interval for A14\n",
      "Counter({0: 455, 2: 150, 1: 62, 3: 23})\n"
     ]
    }
   ],
   "source": [
    "print('Interval frequency for 6 Intervals')\n",
    "for i in num_list_m2:\n",
    "    print('Interval for ' + i)\n",
    "    print(Counter(aus_m2[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3edf860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency for aus with 8 Intervals\n",
      "Interval for A2\n",
      "Counter({5: 303, 4: 156, 6: 114, 2: 39, 7: 30, 3: 27, 0: 14, 1: 7})\n",
      "Interval for A3\n",
      "Counter({1: 391, 5: 197, 4: 43, 2: 39, 6: 13, 0: 5, 3: 2})\n",
      "Interval for A7\n",
      "Counter({3: 198, 0: 193, 1: 103, 4: 103, 2: 75, 5: 18})\n",
      "Interval for A10\n",
      "Counter({0: 395, 6: 77, 2: 71, 5: 59, 1: 45, 3: 28, 4: 15})\n",
      "Interval for A13\n",
      "Counter({1: 301, 5: 132, 4: 130, 2: 81, 7: 17, 0: 16, 6: 9, 3: 4})\n",
      "Interval for A14\n",
      "Counter({2: 295, 0: 160, 5: 133, 3: 50, 6: 23, 4: 17, 1: 12})\n"
     ]
    }
   ],
   "source": [
    "print('Frequency for aus with 8 Intervals')\n",
    "for i in num_list_m3:\n",
    "    print('Interval for ' + i)\n",
    "    print(Counter(aus_m3[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd8cdde0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency for aus with 10 Intervals\n",
      "Interval for A2\n",
      "Counter({5: 244, 2: 105, 7: 88, 8: 59, 4: 51, 1: 36, 10: 26, 9: 24, 3: 23, 0: 21, 11: 9, 6: 4})\n",
      "Interval for A3\n",
      "Counter({1: 368, 6: 195, 2: 35, 3: 26, 5: 23, 4: 17, 7: 16, 0: 10})\n",
      "Interval for A7\n",
      "Counter({1: 181, 7: 145, 8: 86, 3: 71, 2: 70, 6: 53, 4: 33, 9: 18, 5: 17, 0: 16})\n",
      "Interval for A10\n",
      "Counter({0: 395, 3: 71, 6: 57, 7: 51, 1: 45, 4: 28, 8: 20, 5: 15, 2: 8})\n",
      "Interval for A13\n",
      "Counter({3: 272, 7: 132, 4: 118, 5: 80, 1: 29, 10: 18, 2: 12, 9: 11, 8: 9, 0: 5, 6: 4})\n",
      "Interval for A14\n",
      "Counter({3: 295, 2: 103, 7: 84, 1: 57, 9: 49, 5: 32, 10: 23, 8: 18, 6: 16, 0: 8, 4: 5})\n"
     ]
    }
   ],
   "source": [
    "print('Frequency for aus with 10 Intervals')\n",
    "for i in num_list_m4:\n",
    "    print('Interval for ' + i)\n",
    "    print(Counter(aus_m4[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25638c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency for aus with 15 Intervals\n",
      "Interval for A2\n",
      "Counter({4: 171, 8: 111, 2: 99, 7: 83, 5: 47, 0: 31, 1: 25, 13: 23, 3: 22, 12: 21, 11: 21, 9: 21, 6: 11, 10: 4})\n",
      "Interval for A3\n",
      "Counter({3: 198, 2: 170, 8: 117, 6: 78, 4: 33, 5: 25, 7: 24, 10: 18, 0: 11, 1: 11, 9: 5})\n",
      "Interval for A7\n",
      "Counter({9: 140, 1: 119, 3: 70, 11: 68, 5: 64, 2: 62, 8: 37, 7: 33, 14: 23, 13: 18, 0: 16, 4: 16, 6: 13, 10: 7, 12: 4})\n",
      "Interval for A10\n",
      "Counter({0: 395, 3: 71, 9: 46, 1: 45, 8: 39, 5: 28, 10: 20, 7: 18, 6: 15, 2: 8, 4: 5})\n",
      "Interval for A13\n",
      "Counter({3: 154, 8: 132, 5: 118, 6: 115, 7: 76, 11: 29, 1: 23, 2: 11, 0: 11, 9: 9, 4: 8, 10: 4})\n",
      "Interval for A14\n",
      "Counter({4: 295, 2: 89, 10: 60, 13: 44, 1: 44, 3: 28, 11: 28, 7: 24, 0: 24, 8: 18, 6: 14, 12: 14, 9: 4, 5: 4})\n"
     ]
    }
   ],
   "source": [
    "print('Frequency for aus with 15 Intervals')\n",
    "for i in num_list_m5:\n",
    "    print('Interval for ' + i)\n",
    "    print(Counter(aus_m5[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2d79abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 690 entries, 0 to 689\n",
      "Data columns (total 15 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   A1      690 non-null    int64\n",
      " 1   A2      690 non-null    int64\n",
      " 2   A3      690 non-null    int64\n",
      " 3   A4      690 non-null    int64\n",
      " 4   A5      690 non-null    int64\n",
      " 5   A6      690 non-null    int64\n",
      " 6   A7      690 non-null    int64\n",
      " 7   A8      690 non-null    int64\n",
      " 8   A9      690 non-null    int64\n",
      " 9   A10     690 non-null    int64\n",
      " 10  A11     690 non-null    int64\n",
      " 11  A12     690 non-null    int64\n",
      " 12  A13     690 non-null    int64\n",
      " 13  A14     690 non-null    int64\n",
      " 14  label   690 non-null    int64\n",
      "dtypes: int64(15)\n",
      "memory usage: 81.0 KB\n"
     ]
    }
   ],
   "source": [
    "aus_m2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb0320e",
   "metadata": {},
   "source": [
    "# 1. Categorical Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1cfced",
   "metadata": {},
   "source": [
    "## 1.1 Max_depth = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a86152",
   "metadata": {},
   "source": [
    "## 1.1 script version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a0b6d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make test & train split\n",
    "X = aus_m2.drop('label', axis=1)\n",
    "y = aus_m2['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e446fca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of categories\n",
    "n_categories = aus_m2.drop('label', axis=1).nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99b94bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CategoricalNB\n",
      "=========================\n",
      "Misclassified samples: 28\n",
      "Accuracy: 0.84\n",
      "=========================\n",
      "Recall score :  0.838150289017341\n",
      "Precision score :  0.838150289017341\n",
      "F1 score :  0.8381502890173411\n",
      "=========================\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.92      0.84        83\n",
      "           1       0.91      0.77      0.83        90\n",
      "\n",
      "    accuracy                           0.84       173\n",
      "   macro avg       0.85      0.84      0.84       173\n",
      "weighted avg       0.85      0.84      0.84       173\n",
      "\n",
      "Computation time:\n",
      "0.012994527816772461\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "cnb = CategoricalNB(min_categories = n_categories)\n",
    "cnb.fit(X_train, y_train)\n",
    "\n",
    "y_pred_cnb = cnb.predict(X_test)\n",
    "y_prob_pred_cnb = cnb.predict_proba(X_test)\n",
    "\n",
    "# how did our model perform?\n",
    "count_misclassified = (y_test != y_pred_cnb).sum()\n",
    "print(\"CategoricalNB\")\n",
    "print(\"=\" * 25)\n",
    "print('Misclassified samples: {}'.format(count_misclassified))\n",
    "accuracy = accuracy_score(y_test, y_pred_cnb)\n",
    "print('Accuracy: {:.2f}'.format(accuracy))\n",
    "print(\"=\" * 25)\n",
    "print(\"Recall score : \", recall_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"Precision score : \",precision_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"F1 score : \",f1_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"=\" * 25)\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred_cnb))\n",
    "\n",
    "end = time.time()\n",
    "print(\"Computation time:\")\n",
    "print(end - start) # Total time execution for this sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82d4dfb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.162\n",
      "Average bias: 0.162\n",
      "Average variance: 0.023\n",
      "Sklearn 0-1 loss: 0.162\n"
     ]
    }
   ],
   "source": [
    "# calculate classification bias and variance\n",
    "from sklearn.metrics import zero_one_loss\n",
    "#This library is used to decompose bias and variance in our models\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#We will load the Boston house dataset for our example\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn import metrics\n",
    "\n",
    "# y_pred_cnb\n",
    "# y_prob_pred_cnb\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        cnb, X_train.values, y_train.values, X_test.values, y_test.values, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=123)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_cnb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf64c978",
   "metadata": {},
   "source": [
    "## 1.2 Max_depth = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "257b3181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make test & train split\n",
    "X = aus_m3.drop('label', axis=1)\n",
    "y = aus_m3['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b8b0b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of categories\n",
    "n_categories = aus_m3.drop('label', axis=1).nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a1c57ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CategoricalNB\n",
      "=========================\n",
      "Misclassified samples: 26\n",
      "Accuracy: 0.85\n",
      "=========================\n",
      "Recall score :  0.8497109826589595\n",
      "Precision score :  0.8497109826589595\n",
      "F1 score :  0.8497109826589595\n",
      "=========================\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.93      0.86        83\n",
      "           1       0.92      0.78      0.84        90\n",
      "\n",
      "    accuracy                           0.85       173\n",
      "   macro avg       0.86      0.85      0.85       173\n",
      "weighted avg       0.86      0.85      0.85       173\n",
      "\n",
      "Computation time:\n",
      "0.013386964797973633\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "cnb = CategoricalNB(min_categories = n_categories)\n",
    "cnb.fit(X_train, y_train)\n",
    "\n",
    "y_pred_cnb = cnb.predict(X_test)\n",
    "y_prob_pred_cnb = cnb.predict_proba(X_test)\n",
    "\n",
    "# how did our model perform?\n",
    "count_misclassified = (y_test != y_pred_cnb).sum()\n",
    "print(\"CategoricalNB\")\n",
    "print(\"=\" * 25)\n",
    "print('Misclassified samples: {}'.format(count_misclassified))\n",
    "accuracy = accuracy_score(y_test, y_pred_cnb)\n",
    "print('Accuracy: {:.2f}'.format(accuracy))\n",
    "print(\"=\" * 25)\n",
    "print(\"Recall score : \", recall_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"Precision score : \",precision_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"F1 score : \",f1_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"=\" * 25)\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred_cnb))\n",
    "\n",
    "end = time.time()\n",
    "print(\"Computation time:\")\n",
    "print(end - start) # Total time execution for this sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "faa7e6ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.152\n",
      "Average bias: 0.150\n",
      "Average variance: 0.031\n",
      "Sklearn 0-1 loss: 0.150\n"
     ]
    }
   ],
   "source": [
    "# calculate classification bias and variance\n",
    "from sklearn.metrics import zero_one_loss\n",
    "#This library is used to decompose bias and variance in our models\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#We will load the Boston house dataset for our example\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn import metrics\n",
    "\n",
    "# y_pred_cnb\n",
    "# y_prob_pred_cnb\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        cnb, X_train.values, y_train.values, X_test.values, y_test.values, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=123)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_cnb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd86461",
   "metadata": {},
   "source": [
    "## 1.3 Max_depth = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "521d0d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make test & train split\n",
    "X = aus_m4.drop('label', axis=1)\n",
    "y = aus_m4['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7949486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of categories\n",
    "n_categories = aus_m4.drop('label', axis=1).nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f8b6d88f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CategoricalNB\n",
      "=========================\n",
      "Misclassified samples: 26\n",
      "Accuracy: 0.85\n",
      "=========================\n",
      "Recall score :  0.8497109826589595\n",
      "Precision score :  0.8497109826589595\n",
      "F1 score :  0.8497109826589595\n",
      "=========================\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.94      0.86        83\n",
      "           1       0.93      0.77      0.84        90\n",
      "\n",
      "    accuracy                           0.85       173\n",
      "   macro avg       0.86      0.85      0.85       173\n",
      "weighted avg       0.86      0.85      0.85       173\n",
      "\n",
      "Computation time:\n",
      "0.012998342514038086\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "cnb = CategoricalNB(min_categories = n_categories)\n",
    "cnb.fit(X_train, y_train)\n",
    "\n",
    "y_pred_cnb = cnb.predict(X_test)\n",
    "y_prob_pred_cnb = cnb.predict_proba(X_test)\n",
    "\n",
    "# how did our model perform?\n",
    "count_misclassified = (y_test != y_pred_cnb).sum()\n",
    "print(\"CategoricalNB\")\n",
    "print(\"=\" * 25)\n",
    "print('Misclassified samples: {}'.format(count_misclassified))\n",
    "accuracy = accuracy_score(y_test, y_pred_cnb)\n",
    "print('Accuracy: {:.2f}'.format(accuracy))\n",
    "print(\"=\" * 25)\n",
    "print(\"Recall score : \", recall_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"Precision score : \",precision_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"F1 score : \",f1_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"=\" * 25)\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred_cnb))\n",
    "\n",
    "end = time.time()\n",
    "print(\"Computation time:\")\n",
    "print(end - start) # Total time execution for this sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd346c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.153\n",
      "Average bias: 0.156\n",
      "Average variance: 0.030\n",
      "Sklearn 0-1 loss: 0.150\n"
     ]
    }
   ],
   "source": [
    "# calculate classification bias and variance\n",
    "from sklearn.metrics import zero_one_loss\n",
    "#This library is used to decompose bias and variance in our models\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#We will load the Boston house dataset for our example\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn import metrics\n",
    "\n",
    "# y_pred_cnb\n",
    "# y_prob_pred_cnb\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        cnb, X_train.values, y_train.values, X_test.values, y_test.values, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=123)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_cnb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b03574",
   "metadata": {},
   "source": [
    "## 1.4 Max_depth = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0824ef5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make test & train split\n",
    "X = aus_m5.drop('label', axis=1)\n",
    "y = aus_m5['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "60b5fae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAM\n",
    "# Count number of categories\n",
    "n_categories = aus_m5.drop('label', axis=1).nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce80e2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CategoricalNB\n",
      "=========================\n",
      "Misclassified samples: 25\n",
      "Accuracy: 0.86\n",
      "=========================\n",
      "Recall score :  0.8554913294797688\n",
      "Precision score :  0.8554913294797688\n",
      "F1 score :  0.8554913294797687\n",
      "=========================\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.93      0.86        83\n",
      "           1       0.92      0.79      0.85        90\n",
      "\n",
      "    accuracy                           0.86       173\n",
      "   macro avg       0.86      0.86      0.86       173\n",
      "weighted avg       0.86      0.86      0.86       173\n",
      "\n",
      "Computation time:\n",
      "0.017255544662475586\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "cnb = CategoricalNB(min_categories = n_categories)\n",
    "cnb.fit(X_train, y_train)\n",
    "\n",
    "y_pred_cnb = cnb.predict(X_test)\n",
    "y_prob_pred_cnb = cnb.predict_proba(X_test)\n",
    "\n",
    "# how did our model perform?\n",
    "count_misclassified = (y_test != y_pred_cnb).sum()\n",
    "print(\"CategoricalNB\")\n",
    "print(\"=\" * 25)\n",
    "print('Misclassified samples: {}'.format(count_misclassified))\n",
    "accuracy = accuracy_score(y_test, y_pred_cnb)\n",
    "print('Accuracy: {:.2f}'.format(accuracy))\n",
    "print(\"=\" * 25)\n",
    "print(\"Recall score : \", recall_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"Precision score : \",precision_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"F1 score : \",f1_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"=\" * 25)\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred_cnb))\n",
    "\n",
    "end = time.time()\n",
    "print(\"Computation time:\")\n",
    "print(end - start) # Total time execution for this sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1fa0fa7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.152\n",
      "Average bias: 0.145\n",
      "Average variance: 0.035\n",
      "Sklearn 0-1 loss: 0.145\n"
     ]
    }
   ],
   "source": [
    "# calculate classification bias and variance\n",
    "from sklearn.metrics import zero_one_loss\n",
    "#This library is used to decompose bias and variance in our models\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#We will load the Boston house dataset for our example\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn import metrics\n",
    "\n",
    "# y_pred_cnb\n",
    "# y_prob_pred_cnb\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        cnb, X_train.values, y_train.values, X_test.values, y_test.values, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=123)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_cnb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36de93a1",
   "metadata": {},
   "source": [
    "# 2. Decision Tree ID3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5da502c",
   "metadata": {},
   "source": [
    "## 2.1 Max_depth = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a0f2dd4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.83\n",
      "=========================\n",
      "Recall score :  0.8323699421965318\n",
      "Precision score :  0.8323699421965318\n",
      "F1 score :  0.8323699421965318\n",
      "=========================\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.86      0.83        83\n",
      "           1       0.86      0.81      0.83        90\n",
      "\n",
      "    accuracy                           0.83       173\n",
      "   macro avg       0.83      0.83      0.83       173\n",
      "weighted avg       0.83      0.83      0.83       173\n",
      "\n",
      "Computation time:\n",
      "0.08155369758605957\n"
     ]
    }
   ],
   "source": [
    "#make splits\n",
    "X = aus_m2.drop('label', axis=1)\n",
    "y = aus_m2['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=30)\n",
    "#time recording\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "#build estimator\n",
    "estimator = Id3Estimator()\n",
    "estimator = estimator.fit(X_train, y_train, check_input=True)\n",
    "tree = export_graphviz(estimator.tree_, 'tree.dot', y)\n",
    "#make predictions\n",
    "y_pred_id3 = estimator.predict(X_test)\n",
    "#_prob_pred_id3 = estimator.predict_proba(X_test)\n",
    "#report performance\n",
    "accuracy = accuracy_score(y_test, y_pred_id3)\n",
    "print('Accuracy: {:.2f}'.format(accuracy))\n",
    "print(\"=\" * 25)\n",
    "print(\"Recall score : \", recall_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"Precision score : \",precision_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"F1 score : \",f1_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"=\" * 25)\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred_id3))\n",
    "#stop time recoridng\n",
    "end = time.time()\n",
    "print(\"Computation time:\")\n",
    "print(end - start) # Total time execution for this sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2421a98e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.208\n",
      "Average bias: 0.145\n",
      "Average variance: 0.129\n",
      "Sklearn 0-1 loss: 0.168\n"
     ]
    }
   ],
   "source": [
    "# calculate classification bias and variance\n",
    "from sklearn.metrics import zero_one_loss\n",
    "#This library is used to decompose bias and variance in our models\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#We will load the Boston house dataset for our example\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn import metrics\n",
    "\n",
    "# y_pred_cnb\n",
    "# y_prob_pred_cnb\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        estimator, X_train.values, y_train.values, X_test.values, y_test.values, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=123)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_id3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c21b52",
   "metadata": {},
   "source": [
    "## 2.2 Max_depth = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "011a2f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.83\n",
      "=========================\n",
      "Recall score :  0.8265895953757225\n",
      "Precision score :  0.8265895953757225\n",
      "F1 score :  0.8265895953757225\n",
      "=========================\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82        83\n",
      "           1       0.84      0.82      0.83        90\n",
      "\n",
      "    accuracy                           0.83       173\n",
      "   macro avg       0.83      0.83      0.83       173\n",
      "weighted avg       0.83      0.83      0.83       173\n",
      "\n",
      "Computation time:\n",
      "0.09459757804870605\n"
     ]
    }
   ],
   "source": [
    "#make splits\n",
    "X = aus_m3.drop('label', axis=1)\n",
    "y = aus_m3['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=30)\n",
    "#time recording\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "#build estimator\n",
    "estimator = Id3Estimator()\n",
    "estimator = estimator.fit(X_train, y_train, check_input=True)\n",
    "tree = export_graphviz(estimator.tree_, 'tree.dot', y)\n",
    "#make predictions\n",
    "y_pred_id3 = estimator.predict(X_test)\n",
    "#_prob_pred_id3 = estimator.predict_proba(X_test)\n",
    "#report performance\n",
    "accuracy = accuracy_score(y_test, y_pred_id3)\n",
    "print('Accuracy: {:.2f}'.format(accuracy))\n",
    "print(\"=\" * 25)\n",
    "print(\"Recall score : \", recall_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"Precision score : \",precision_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"F1 score : \",f1_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"=\" * 25)\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred_id3))\n",
    "#stop time recoridng\n",
    "end = time.time()\n",
    "print(\"Computation time:\")\n",
    "print(end - start) # Total time execution for this sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6d626911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.204\n",
      "Average bias: 0.145\n",
      "Average variance: 0.128\n",
      "Sklearn 0-1 loss: 0.173\n"
     ]
    }
   ],
   "source": [
    "# calculate classification bias and variance\n",
    "from sklearn.metrics import zero_one_loss\n",
    "#This library is used to decompose bias and variance in our models\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#We will load the Boston house dataset for our example\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn import metrics\n",
    "\n",
    "# y_pred_cnb\n",
    "# y_prob_pred_cnb\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        estimator, X_train.values, y_train.values, X_test.values, y_test.values, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=123)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_id3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687f1ea3",
   "metadata": {},
   "source": [
    "## 2.3 max_depth = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "82063c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.80\n",
      "=========================\n",
      "Recall score :  0.8034682080924855\n",
      "Precision score :  0.8034682080924855\n",
      "F1 score :  0.8034682080924856\n",
      "=========================\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.83      0.80        83\n",
      "           1       0.83      0.78      0.80        90\n",
      "\n",
      "    accuracy                           0.80       173\n",
      "   macro avg       0.80      0.80      0.80       173\n",
      "weighted avg       0.81      0.80      0.80       173\n",
      "\n",
      "Computation time:\n",
      "0.0886995792388916\n"
     ]
    }
   ],
   "source": [
    "#make splits\n",
    "X = aus_m4.drop('label', axis=1)\n",
    "y = aus_m4['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=30)\n",
    "#time recording\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "#build estimator\n",
    "estimator = Id3Estimator()\n",
    "estimator = estimator.fit(X_train, y_train, check_input=True)\n",
    "tree = export_graphviz(estimator.tree_, 'tree.dot', y)\n",
    "#make predictions\n",
    "y_pred_id3 = estimator.predict(X_test)\n",
    "#_prob_pred_id3 = estimator.predict_proba(X_test)\n",
    "#report performance\n",
    "accuracy = accuracy_score(y_test, y_pred_id3)\n",
    "print('Accuracy: {:.2f}'.format(accuracy))\n",
    "print(\"=\" * 25)\n",
    "print(\"Recall score : \", recall_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"Precision score : \",precision_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"F1 score : \",f1_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"=\" * 25)\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred_id3))\n",
    "#stop time recoridng\n",
    "end = time.time()\n",
    "print(\"Computation time:\")\n",
    "print(end - start) # Total time execution for this sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "457f91d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.200\n",
      "Average bias: 0.168\n",
      "Average variance: 0.126\n",
      "Sklearn 0-1 loss: 0.197\n"
     ]
    }
   ],
   "source": [
    "# calculate classification bias and variance\n",
    "from sklearn.metrics import zero_one_loss\n",
    "#This library is used to decompose bias and variance in our models\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#We will load the Boston house dataset for our example\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn import metrics\n",
    "\n",
    "# y_pred_cnb\n",
    "# y_prob_pred_cnb\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        estimator, X_train.values, y_train.values, X_test.values, y_test.values, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=123)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_id3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251b1503",
   "metadata": {},
   "source": [
    "## 2.4 Max_depth = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9907debd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.79\n",
      "=========================\n",
      "Recall score :  0.791907514450867\n",
      "Precision score :  0.791907514450867\n",
      "F1 score :  0.791907514450867\n",
      "=========================\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.82      0.79        83\n",
      "           1       0.82      0.77      0.79        90\n",
      "\n",
      "    accuracy                           0.79       173\n",
      "   macro avg       0.79      0.79      0.79       173\n",
      "weighted avg       0.79      0.79      0.79       173\n",
      "\n",
      "Computation time:\n",
      "0.1000971794128418\n"
     ]
    }
   ],
   "source": [
    "#make splits\n",
    "X = aus_m5.drop('label', axis=1)\n",
    "y = aus_m5['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=30)\n",
    "#time recording\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "#build estimator\n",
    "estimator = Id3Estimator()\n",
    "estimator = estimator.fit(X_train, y_train, check_input=True)\n",
    "tree = export_graphviz(estimator.tree_, 'tree.dot', y)\n",
    "#make predictions\n",
    "y_pred_id3 = estimator.predict(X_test)\n",
    "#_prob_pred_id3 = estimator.predict_proba(X_test)\n",
    "#report performance\n",
    "accuracy = accuracy_score(y_test, y_pred_id3)\n",
    "print('Accuracy: {:.2f}'.format(accuracy))\n",
    "print(\"=\" * 25)\n",
    "print(\"Recall score : \", recall_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"Precision score : \",precision_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"F1 score : \",f1_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"=\" * 25)\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred_id3))\n",
    "#stop time recoridng\n",
    "end = time.time()\n",
    "print(\"Computation time:\")\n",
    "print(end - start) # Total time execution for this sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c23fced9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.189\n",
      "Average bias: 0.145\n",
      "Average variance: 0.124\n",
      "Sklearn 0-1 loss: 0.208\n"
     ]
    }
   ],
   "source": [
    "# calculate classification bias and variance\n",
    "from sklearn.metrics import zero_one_loss\n",
    "#This library is used to decompose bias and variance in our models\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#We will load the Boston house dataset for our example\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn import metrics\n",
    "\n",
    "# y_pred_cnb\n",
    "# y_prob_pred_cnb\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        estimator, X_train.values, y_train.values, X_test.values, y_test.values, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=123)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_id3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9d5f3d",
   "metadata": {},
   "source": [
    "# 3. KNN classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55006f71",
   "metadata": {},
   "source": [
    "## 3.1 KNN with DT max_depth = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ca32b2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make test & train split\n",
    "X = aus_m2.drop('label', axis=1) # max_depth = 2\n",
    "y = aus_m2['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e656e420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.87      0.84        83\n",
      "           1       0.87      0.82      0.85        90\n",
      "\n",
      "    accuracy                           0.84       173\n",
      "   macro avg       0.84      0.84      0.84       173\n",
      "weighted avg       0.85      0.84      0.84       173\n",
      "\n",
      "Time for training model Knn-VDM: 37.39223265647888.\n"
     ]
    }
   ],
   "source": [
    "# Knn-VDM complete code\n",
    "# accuracy 0.84 173\n",
    "# Time for training model Knn-VDM: 38.516900062561035\n",
    "# Time for training model Knn-VDM: 37.39223265647888.\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "# specific the continuous columns index if any\n",
    "vdm = ValueDifferenceMetric(X_train, y_train, continuous = None)\n",
    "vdm.fit()\n",
    "# Knn model, n_neigbour = 3, metrics = vdm\n",
    "knn_vdm = KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')\n",
    "# Fit model\n",
    "knn_vdm.fit(X_train, y_train)\n",
    "# Testing\n",
    "y_pred_knn = knn_vdm.predict(X_test)\n",
    "knn_vdm.classes_\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model Knn-VDM: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ebc4110f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.189\n",
      "Average bias: 0.173\n",
      "Average variance: 0.090\n",
      "Sklearn 0-1 loss: 0.156\n"
     ]
    }
   ],
   "source": [
    "# !!!! WARING: TIME CONSUMING\n",
    "\n",
    "# Bias and variance decomposition\n",
    "# Convert all dataframe to array first\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "y_train = y_train.values\n",
    "y_test = y_test.values\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        knn_vdm, X_train, y_train, X_test, y_test, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=123)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0074f7e6",
   "metadata": {},
   "source": [
    "## 3.2 KNN with DT max_depth = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3f70b6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make test & train split\n",
    "X = aus_m3.drop('label', axis=1)\n",
    "y = aus_m3['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "74b572d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.87      0.83        83\n",
      "           1       0.87      0.79      0.83        90\n",
      "\n",
      "    accuracy                           0.83       173\n",
      "   macro avg       0.83      0.83      0.83       173\n",
      "weighted avg       0.83      0.83      0.83       173\n",
      "\n",
      "Time for training model Knn-VDM: 39.29734921455383.\n"
     ]
    }
   ],
   "source": [
    "# Knn-VDM complete code\n",
    "# accuracy 0.83 173\n",
    "# Time for training model Knn-VDM: 38.24225306510925\n",
    "# Time for training model Knn-VDM: 39.29734921455383.\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "# specific the continuous columns index if any\n",
    "vdm = ValueDifferenceMetric(X_train, y_train, continuous = None)\n",
    "vdm.fit()\n",
    "# Knn model, n_neigbour = 3, metrics = vdm\n",
    "knn_vdm = KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')\n",
    "# Fit model\n",
    "knn_vdm.fit(X_train, y_train)\n",
    "# Testing\n",
    "y_pred_knn = knn_vdm.predict(X_test)\n",
    "knn_vdm.classes_\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model Knn-VDM: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e6fd45e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.197\n",
      "Average bias: 0.179\n",
      "Average variance: 0.091\n",
      "Sklearn 0-1 loss: 0.173\n"
     ]
    }
   ],
   "source": [
    "# !!!! WARING: TIME CONSUMING\n",
    "\n",
    "# Bias and variance decomposition\n",
    "# Convert all dataframe to array first\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "y_train = y_train.values\n",
    "y_test = y_test.values\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        knn_vdm, X_train, y_train, X_test, y_test, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=123)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a527ed9",
   "metadata": {},
   "source": [
    "## 3.3 KNN with DT max_depth = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ee252e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make test & train split\n",
    "X = aus_m4.drop('label', axis=1)\n",
    "y = aus_m4['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d8072b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.86      0.82        83\n",
      "           1       0.85      0.78      0.81        90\n",
      "\n",
      "    accuracy                           0.82       173\n",
      "   macro avg       0.82      0.82      0.82       173\n",
      "weighted avg       0.82      0.82      0.81       173\n",
      "\n",
      "Time for training model Knn-VDM: 37.068912744522095.\n"
     ]
    }
   ],
   "source": [
    "# Knn-VDM complete code\n",
    "# DONE\n",
    "# accuracy 0.82 173\n",
    "# Time for training model Knn-VDM: 37.76226568222046.\n",
    "# Time for training: 37.068912744522095\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "# specific the continuous columns index if any\n",
    "vdm = ValueDifferenceMetric(X_train, y_train, continuous = None)\n",
    "vdm.fit()\n",
    "# Knn model, n_neigbour = 3, metrics = vdm\n",
    "knn_vdm = KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')\n",
    "# Fit model\n",
    "knn_vdm.fit(X_train, y_train)\n",
    "# Testing\n",
    "y_pred_knn = knn_vdm.predict(X_test)\n",
    "knn_vdm.classes_\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model Knn-VDM: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a7438016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.201\n",
      "Average bias: 0.179\n",
      "Average variance: 0.089\n",
      "Sklearn 0-1 loss: 0.185\n"
     ]
    }
   ],
   "source": [
    "# !!!! WARING: TIME CONSUMING\n",
    "\n",
    "# Bias and variance decomposition\n",
    "# Convert all dataframe to array first\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "y_train = y_train.values\n",
    "y_test = y_test.values\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        knn_vdm, X_train, y_train, X_test, y_test, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=123)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb00a1f6",
   "metadata": {},
   "source": [
    "## 3.4 KNN with DT max_depth = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4848cc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make test & train split\n",
    "X = aus_m5.drop('label', axis=1)\n",
    "y = aus_m5['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "aabda2c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.87      0.83        83\n",
      "           1       0.87      0.79      0.83        90\n",
      "\n",
      "    accuracy                           0.83       173\n",
      "   macro avg       0.83      0.83      0.83       173\n",
      "weighted avg       0.83      0.83      0.83       173\n",
      "\n",
      "Time for training model Knn-VDM: 41.03129029273987.\n"
     ]
    }
   ],
   "source": [
    "# Knn-VDM complete code\n",
    "# DONE:\n",
    "# Time for training model Knn-VDM: 37.23736929893494.\n",
    "# accuracy 0.83 173\n",
    "# New time for training: 41.03129029273987\n",
    "\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "# specific the continuous columns index if any\n",
    "vdm = ValueDifferenceMetric(X_train, y_train, continuous = None)\n",
    "vdm.fit()\n",
    "# Knn model, n_neigbour = 3, metrics = vdm\n",
    "knn_vdm = KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')\n",
    "# Fit model\n",
    "knn_vdm.fit(X_train, y_train)\n",
    "# Testing\n",
    "y_pred_knn = knn_vdm.predict(X_test)\n",
    "knn_vdm.classes_\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model Knn-VDM: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "28cf29c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.199\n",
      "Average bias: 0.173\n",
      "Average variance: 0.095\n",
      "Sklearn 0-1 loss: 0.173\n"
     ]
    }
   ],
   "source": [
    "# !!!! WARING: TIME CONSUMING\n",
    "\n",
    "# Bias and variance decomposition\n",
    "# Convert all dataframe to array first\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "y_train = y_train.values\n",
    "y_test = y_test.values\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        knn_vdm, X_train, y_train, X_test, y_test, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=123)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f58c1c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
