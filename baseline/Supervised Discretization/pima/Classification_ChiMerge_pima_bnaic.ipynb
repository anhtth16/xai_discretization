{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abd2336c",
   "metadata": {},
   "source": [
    "# Classification models - Supervised Discretization\n",
    "## Dataset: pima\n",
    "\n",
    "Updated by: Sam\n",
    "Update at: 13/10/2022 <br>\n",
    "---\n",
    "Discretization methods: ChiMerge (manually defined function)<br>\n",
    "Classification models: CNB, ID3, KNN-VDM\n",
    "---\n",
    "NOTE: \n",
    "NEED TO DO SMOTE for imbalance dataset before training\n",
    "Long time for computation of Knn-VDM (Run this part last) <br>\n",
    "Use Malina scripts for Knn, ID3 <br>\n",
    "Use Sam scripts (with min_categories) for Naive Bayes <br>\n",
    "Key Errors for decomposition KNN-VDM models k = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83bc40c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, roc_auc_score, recall_score, precision_score\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "import six\n",
    "import sys\n",
    "sys.modules['sklearn.externals.six'] = six\n",
    "import id3\n",
    "from id3 import Id3Estimator\n",
    "from id3 import export_graphviz\n",
    "import wittgenstein as lw\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "from pandas import set_option\n",
    "import numpy as np\n",
    "from numpy import arange\n",
    "## EDA\n",
    "from collections import Counter\n",
    "\n",
    "# Knn-VDM 3\n",
    "from vdm3 import ValueDifferenceMetric\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Pre-processing\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "# Cross validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score # 1 metric\n",
    "from sklearn.model_selection import cross_validate # more than 1 metric\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50eb04fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in data from ChiMerge discretization\n",
    "pima6 = pd.read_csv('chim_pima_6int.csv')\n",
    "pima8 = pd.read_csv('chim_pima_8int.csv')\n",
    "pima10 = pd.read_csv('chim_pima_10int.csv')\n",
    "pima15 = pd.read_csv('chim_pima_15int.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c61fe4c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin  BMI  \\\n",
       "0            2        3              2              3        0    4   \n",
       "1            1        1              2              2        0    1   \n",
       "2            3        5              2              0        0    0   \n",
       "3            1        1              2              1        2    1   \n",
       "4            0        3              0              3        5    4   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                         2    3        1  \n",
       "1                         2    2        0  \n",
       "2                         2    2        1  \n",
       "3                         0    0        0  \n",
       "4                         5    2        1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pima6.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24075c8",
   "metadata": {},
   "source": [
    "## Interval frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94258ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_list6 = list(pima6.drop('Outcome', axis=1).columns)\n",
    "num_list8 = list(pima8.drop('Outcome', axis=1).columns)\n",
    "num_list10 = list(pima10.drop('Outcome', axis=1).columns)\n",
    "num_list15 = list(pima15.drop('Outcome', axis=1).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be896d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interval frequency for 6 Intervals\n",
      "Interval for Pregnancies\n",
      "Counter({2: 250, 1: 238, 3: 111, 0: 111, 4: 54, 5: 4})\n",
      "Interval for Glucose\n",
      "Counter({2: 288, 1: 192, 3: 161, 5: 79, 4: 43, 0: 5})\n",
      "Interval for BloodPressure\n",
      "Counter({2: 320, 3: 276, 1: 119, 0: 40, 5: 10, 4: 3})\n",
      "Interval for SkinThickness\n",
      "Counter({0: 229, 3: 211, 1: 170, 2: 150, 5: 4, 4: 4})\n",
      "Interval for Insulin\n",
      "Counter({0: 375, 5: 221, 1: 117, 4: 29, 2: 22, 3: 4})\n",
      "Interval for BMI\n",
      "Counter({4: 315, 1: 253, 0: 167, 5: 14, 3: 10, 2: 9})\n",
      "Interval for DiabetesPedigreeFunction\n",
      "Counter({2: 467, 0: 265, 3: 18, 4: 9, 5: 5, 1: 4})\n",
      "Interval for Age\n",
      "Counter({0: 219, 1: 198, 2: 197, 3: 100, 4: 33, 5: 21})\n"
     ]
    }
   ],
   "source": [
    "print('Interval frequency for 6 Intervals')\n",
    "for i in num_list6:\n",
    "    print('Interval for ' + i)\n",
    "    print(Counter(pima6[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3edf860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency for aus with 8 Intervals\n",
      "Interval for Pregnancies\n",
      "Counter({2: 250, 1: 238, 3: 111, 0: 111, 4: 24, 6: 19, 5: 11, 7: 4})\n",
      "Interval for Glucose\n",
      "Counter({1: 192, 2: 166, 5: 161, 4: 112, 7: 79, 6: 43, 3: 10, 0: 5})\n",
      "Interval for BloodPressure\n",
      "Counter({4: 320, 5: 276, 3: 73, 0: 40, 2: 40, 7: 10, 1: 6, 6: 3})\n",
      "Interval for SkinThickness\n",
      "Counter({0: 229, 3: 207, 1: 170, 2: 150, 7: 4, 6: 4, 4: 3, 5: 1})\n",
      "Interval for Insulin\n",
      "Counter({0: 375, 7: 221, 1: 104, 6: 29, 2: 13, 4: 12, 3: 10, 5: 4})\n",
      "Interval for BMI\n",
      "Counter({4: 298, 1: 253, 0: 167, 7: 14, 6: 11, 3: 10, 2: 9, 5: 6})\n",
      "Interval for DiabetesPedigreeFunction\n",
      "Counter({3: 247, 1: 243, 4: 220, 0: 22, 5: 18, 6: 9, 7: 5, 2: 4})\n",
      "Interval for Age\n",
      "Counter({2: 198, 3: 197, 1: 156, 4: 100, 0: 63, 5: 33, 7: 13, 6: 8})\n"
     ]
    }
   ],
   "source": [
    "print('Frequency for aus with 8 Intervals')\n",
    "for i in num_list8:\n",
    "    print('Interval for ' + i)\n",
    "    print(Counter(pima8[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd8cdde0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency for aus with 10 Intervals\n",
      "Interval for Pregnancies\n",
      "Counter({3: 250, 1: 135, 0: 111, 2: 103, 4: 83, 5: 28, 6: 24, 8: 19, 7: 11, 9: 4})\n",
      "Interval for Glucose\n",
      "Counter({1: 192, 2: 166, 7: 161, 9: 79, 4: 73, 8: 43, 5: 25, 6: 14, 3: 10, 0: 5})\n",
      "Interval for BloodPressure\n",
      "Counter({7: 276, 4: 159, 5: 153, 3: 73, 0: 40, 2: 40, 9: 10, 6: 8, 1: 6, 8: 3})\n",
      "Interval for SkinThickness\n",
      "Counter({0: 229, 4: 204, 3: 150, 2: 139, 1: 31, 9: 4, 8: 4, 6: 3, 5: 3, 7: 1})\n",
      "Interval for Insulin\n",
      "Counter({0: 375, 9: 221, 1: 56, 2: 46, 8: 29, 4: 13, 6: 12, 5: 10, 7: 4, 3: 2})\n",
      "Interval for BMI\n",
      "Counter({4: 268, 1: 253, 0: 167, 5: 24, 9: 14, 8: 11, 3: 10, 2: 9, 7: 6, 6: 6})\n",
      "Interval for DiabetesPedigreeFunction\n",
      "Counter({4: 247, 2: 237, 6: 214, 0: 22, 7: 18, 8: 9, 5: 6, 1: 6, 9: 5, 3: 4})\n",
      "Interval for Age\n",
      "Counter({2: 198, 3: 197, 1: 156, 0: 63, 5: 47, 6: 40, 7: 33, 4: 13, 9: 13, 8: 8})\n"
     ]
    }
   ],
   "source": [
    "print('Frequency for aus with 10 Intervals')\n",
    "for i in num_list10:\n",
    "    print('Interval for ' + i)\n",
    "    print(Counter(pima10[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25638c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency for aus with 15 Intervals\n",
      "Interval for Pregnancies\n",
      "Counter({1: 135, 0: 111, 2: 103, 3: 75, 4: 68, 5: 57, 6: 50, 7: 45, 8: 38, 9: 28, 10: 24, 11: 11, 13: 10, 12: 9, 14: 4})\n",
      "Interval for Glucose\n",
      "Counter({3: 166, 2: 163, 8: 153, 14: 79, 5: 73, 1: 29, 12: 26, 6: 25, 7: 14, 4: 10, 10: 8, 9: 8, 13: 7, 0: 5, 11: 2})\n",
      "Interval for BloodPressure\n",
      "Counter({6: 159, 7: 153, 11: 152, 10: 85, 3: 40, 0: 39, 9: 39, 5: 38, 4: 35, 13: 9, 8: 8, 2: 6, 12: 3, 1: 1, 14: 1})\n",
      "Interval for SkinThickness\n",
      "Counter({0: 229, 5: 150, 6: 145, 4: 113, 7: 59, 1: 31, 3: 20, 2: 6, 11: 4, 9: 3, 8: 3, 14: 2, 13: 1, 10: 1, 12: 1})\n",
      "Interval for Insulin\n",
      "Counter({0: 375, 14: 163, 12: 48, 5: 44, 11: 29, 1: 28, 3: 25, 7: 13, 9: 12, 8: 10, 13: 10, 10: 4, 2: 3, 4: 2, 6: 2})\n",
      "Interval for BMI\n",
      "Counter({9: 268, 6: 166, 4: 91, 5: 87, 1: 48, 10: 24, 14: 14, 0: 11, 2: 11, 13: 11, 8: 10, 7: 9, 3: 6, 12: 6, 11: 6})\n",
      "Interval for DiabetesPedigreeFunction\n",
      "Counter({11: 214, 9: 211, 2: 159, 4: 74, 6: 29, 0: 22, 12: 18, 13: 9, 10: 6, 1: 6, 14: 5, 8: 5, 5: 4, 3: 4, 7: 2})\n",
      "Interval for Age\n",
      "Counter({2: 198, 1: 156, 7: 81, 0: 63, 3: 57, 9: 42, 11: 40, 12: 33, 5: 26, 6: 19, 4: 14, 8: 13, 14: 13, 13: 8, 10: 5})\n"
     ]
    }
   ],
   "source": [
    "print('Frequency for aus with 15 Intervals')\n",
    "for i in num_list15:\n",
    "    print('Interval for ' + i)\n",
    "    print(Counter(pima15[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2d79abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype\n",
      "---  ------                    --------------  -----\n",
      " 0   Pregnancies               768 non-null    int64\n",
      " 1   Glucose                   768 non-null    int64\n",
      " 2   BloodPressure             768 non-null    int64\n",
      " 3   SkinThickness             768 non-null    int64\n",
      " 4   Insulin                   768 non-null    int64\n",
      " 5   BMI                       768 non-null    int64\n",
      " 6   DiabetesPedigreeFunction  768 non-null    int64\n",
      " 7   Age                       768 non-null    int64\n",
      " 8   Outcome                   768 non-null    int64\n",
      "dtypes: int64(9)\n",
      "memory usage: 54.1 KB\n"
     ]
    }
   ],
   "source": [
    "pima6.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb0320e",
   "metadata": {},
   "source": [
    "# 1. Categorical Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1cfced",
   "metadata": {},
   "source": [
    "## 1.1 CNB, 6 Intervals from ChiMerge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "956e32e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make test & train split\n",
    "X = pima6.drop('Outcome', axis=1)\n",
    "y = pima6['Outcome']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=30, stratify = y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6fe55cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class representation - original:  Counter({0: 500, 1: 268})\n",
      "Class representation - training data:  Counter({0: 375, 1: 201})\n",
      "Class representation - testing data:  Counter({0: 125, 1: 67})\n"
     ]
    }
   ],
   "source": [
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(pima6['Outcome'])) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "896beeb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(576, 8) (192, 8)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a89c1ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTE\n",
    "#! pip install imblearn --user\n",
    "from imblearn import under_sampling, over_sampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state = 22)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "757ca754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAM\n",
    "# Count number of categories\n",
    "n_categories = pima6.drop('Outcome', axis=1).nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "99b94bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CategoricalNB\n",
      "=========================\n",
      "Misclassified samples: 47\n",
      "Accuracy: 0.76\n",
      "=========================\n",
      "Recall score :  0.7552083333333334\n",
      "Precision score :  0.7552083333333334\n",
      "F1 score :  0.7552083333333334\n",
      "=========================\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.66      0.78       125\n",
      "           1       0.59      0.94      0.73        67\n",
      "\n",
      "    accuracy                           0.76       192\n",
      "   macro avg       0.77      0.80      0.75       192\n",
      "weighted avg       0.83      0.76      0.76       192\n",
      "\n",
      "Computation time:\n",
      "0.01199960708618164\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "cnb = CategoricalNB(min_categories = n_categories)\n",
    "cnb.fit(X_train, y_train)\n",
    "\n",
    "y_pred_cnb = cnb.predict(X_test)\n",
    "y_prob_pred_cnb = cnb.predict_proba(X_test)\n",
    "\n",
    "# how did our model perform?\n",
    "count_misclassified = (y_test != y_pred_cnb).sum()\n",
    "print(\"CategoricalNB\")\n",
    "print(\"=\" * 25)\n",
    "print('Misclassified samples: {}'.format(count_misclassified))\n",
    "accuracy = accuracy_score(y_test, y_pred_cnb)\n",
    "print('Accuracy: {:.2f}'.format(accuracy))\n",
    "print(\"=\" * 25)\n",
    "print(\"Recall score : \", recall_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"Precision score : \",precision_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"F1 score : \",f1_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"=\" * 25)\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred_cnb))\n",
    "\n",
    "end = time.time()\n",
    "print(\"Computation time:\")\n",
    "print(end - start) # Total time execution for this sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82d4dfb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.248\n",
      "Average bias: 0.250\n",
      "Average variance: 0.037\n",
      "Sklearn 0-1 loss: 0.245\n"
     ]
    }
   ],
   "source": [
    "# calculate classification bias and variance\n",
    "from sklearn.metrics import zero_one_loss\n",
    "#This library is used to decompose bias and variance in our models\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#We will load the Boston house dataset for our example\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn import metrics\n",
    "\n",
    "# y_pred_cnb\n",
    "# y_prob_pred_cnb\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        cnb, X_train.values, y_train.values, X_test.values, y_test.values, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=123)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_cnb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf64c978",
   "metadata": {},
   "source": [
    "## 1.2 CNB, 8 Intervals from ChiMerge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d77e34d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make test & train split\n",
    "X = pima8.drop('Outcome', axis=1)\n",
    "y = pima8['Outcome']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=30, stratify = y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f25b1db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class representation - original:  Counter({0: 500, 1: 268})\n",
      "Class representation - training data:  Counter({0: 375, 1: 201})\n",
      "Class representation - testing data:  Counter({0: 125, 1: 67})\n"
     ]
    }
   ],
   "source": [
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(pima8['Outcome'])) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1fa76a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(576, 8) (192, 8)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "804ef6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTE\n",
    "#! pip install imblearn --user\n",
    "from imblearn import under_sampling, over_sampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state = 22)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "52c26414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAM\n",
    "# Count number of categories\n",
    "n_categories = pima8.drop('Outcome', axis=1).nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "74dfb525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CategoricalNB\n",
      "=========================\n",
      "Misclassified samples: 46\n",
      "Accuracy: 0.76\n",
      "=========================\n",
      "Recall score :  0.7604166666666666\n",
      "Precision score :  0.7604166666666666\n",
      "F1 score :  0.7604166666666666\n",
      "=========================\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.67      0.79       125\n",
      "           1       0.60      0.93      0.73        67\n",
      "\n",
      "    accuracy                           0.76       192\n",
      "   macro avg       0.77      0.80      0.76       192\n",
      "weighted avg       0.82      0.76      0.77       192\n",
      "\n",
      "Computation time:\n",
      "0.012999296188354492\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "cnb = CategoricalNB(min_categories = n_categories)\n",
    "cnb.fit(X_train, y_train)\n",
    "\n",
    "y_pred_cnb = cnb.predict(X_test)\n",
    "y_prob_pred_cnb = cnb.predict_proba(X_test)\n",
    "\n",
    "# how did our model perform?\n",
    "count_misclassified = (y_test != y_pred_cnb).sum()\n",
    "print(\"CategoricalNB\")\n",
    "print(\"=\" * 25)\n",
    "print('Misclassified samples: {}'.format(count_misclassified))\n",
    "accuracy = accuracy_score(y_test, y_pred_cnb)\n",
    "print('Accuracy: {:.2f}'.format(accuracy))\n",
    "print(\"=\" * 25)\n",
    "print(\"Recall score : \", recall_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"Precision score : \",precision_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"F1 score : \",f1_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"=\" * 25)\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred_cnb))\n",
    "\n",
    "end = time.time()\n",
    "print(\"Computation time:\")\n",
    "print(end - start) # Total time execution for this sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f5eb2c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.251\n",
      "Average bias: 0.250\n",
      "Average variance: 0.049\n",
      "Sklearn 0-1 loss: 0.240\n"
     ]
    }
   ],
   "source": [
    "# calculate classification bias and variance\n",
    "from sklearn.metrics import zero_one_loss\n",
    "#This library is used to decompose bias and variance in our models\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#We will load the Boston house dataset for our example\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn import metrics\n",
    "\n",
    "# y_pred_cnb\n",
    "# y_prob_pred_cnb\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        cnb, X_train.values, y_train.values, X_test.values, y_test.values, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=123)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_cnb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd86461",
   "metadata": {},
   "source": [
    "## 1.3 CNB, 10 Intervals from ChiMerge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a6165490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make test & train split\n",
    "X = pima10.drop('Outcome', axis=1)\n",
    "y = pima10['Outcome']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=30, stratify = y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5faf61af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class representation - original:  Counter({0: 500, 1: 268})\n",
      "Class representation - training data:  Counter({0: 375, 1: 201})\n",
      "Class representation - testing data:  Counter({0: 125, 1: 67})\n"
     ]
    }
   ],
   "source": [
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(pima10['Outcome'])) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "24761949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(576, 8) (192, 8)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f2951c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTE\n",
    "#! pip install imblearn --user\n",
    "from imblearn import under_sampling, over_sampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state = 22)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "15dc9f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class representation - training data:  Counter({1: 375, 0: 375})\n"
     ]
    }
   ],
   "source": [
    "# Check representation of class after SMOTE \n",
    "print('Class representation - training data: ', Counter(y_train)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "245e4357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAM\n",
    "# Count number of categories\n",
    "n_categories = pima10.drop('Outcome', axis=1).nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e99d3956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CategoricalNB\n",
      "=========================\n",
      "Misclassified samples: 48\n",
      "Accuracy: 0.75\n",
      "=========================\n",
      "Recall score :  0.75\n",
      "Precision score :  0.75\n",
      "F1 score :  0.75\n",
      "=========================\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.68      0.78       125\n",
      "           1       0.60      0.88      0.71        67\n",
      "\n",
      "    accuracy                           0.75       192\n",
      "   macro avg       0.75      0.78      0.75       192\n",
      "weighted avg       0.80      0.75      0.76       192\n",
      "\n",
      "Computation time:\n",
      "0.012998342514038086\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "cnb = CategoricalNB(min_categories = n_categories)\n",
    "cnb.fit(X_train, y_train)\n",
    "\n",
    "y_pred_cnb = cnb.predict(X_test)\n",
    "y_prob_pred_cnb = cnb.predict_proba(X_test)\n",
    "\n",
    "# how did our model perform?\n",
    "count_misclassified = (y_test != y_pred_cnb).sum()\n",
    "print(\"CategoricalNB\")\n",
    "print(\"=\" * 25)\n",
    "print('Misclassified samples: {}'.format(count_misclassified))\n",
    "accuracy = accuracy_score(y_test, y_pred_cnb)\n",
    "print('Accuracy: {:.2f}'.format(accuracy))\n",
    "print(\"=\" * 25)\n",
    "print(\"Recall score : \", recall_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"Precision score : \",precision_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"F1 score : \",f1_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"=\" * 25)\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred_cnb))\n",
    "\n",
    "end = time.time()\n",
    "print(\"Computation time:\")\n",
    "print(end - start) # Total time execution for this sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "28d44e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.256\n",
      "Average bias: 0.250\n",
      "Average variance: 0.061\n",
      "Sklearn 0-1 loss: 0.250\n"
     ]
    }
   ],
   "source": [
    "# calculate classification bias and variance\n",
    "from sklearn.metrics import zero_one_loss\n",
    "#This library is used to decompose bias and variance in our models\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#We will load the Boston house dataset for our example\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn import metrics\n",
    "\n",
    "# y_pred_cnb\n",
    "# y_prob_pred_cnb\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        cnb, X_train.values, y_train.values, X_test.values, y_test.values, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=123)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_cnb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b03574",
   "metadata": {},
   "source": [
    "## 1.4 CNB, 15 Intervals from ChiMerge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f3809350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make test & train split\n",
    "X = pima15.drop('Outcome', axis=1)\n",
    "y = pima15['Outcome']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=30, stratify = y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "86dd7947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class representation - original:  Counter({0: 500, 1: 268})\n",
      "Class representation - training data:  Counter({0: 375, 1: 201})\n",
      "Class representation - testing data:  Counter({0: 125, 1: 67})\n"
     ]
    }
   ],
   "source": [
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(pima15['Outcome'])) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "779d8dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(576, 8) (192, 8)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7d5bc1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTE\n",
    "#! pip install imblearn --user\n",
    "from imblearn import under_sampling, over_sampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state = 22)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f47132d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class representation - training data:  Counter({1: 375, 0: 375})\n"
     ]
    }
   ],
   "source": [
    "# Check representation of class after SMOTE \n",
    "print('Class representation - training data: ', Counter(y_train)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "001a2f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAM\n",
    "# Count number of categories\n",
    "n_categories = pima15.drop('Outcome', axis=1).nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8bf7c935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CategoricalNB\n",
      "=========================\n",
      "Misclassified samples: 50\n",
      "Accuracy: 0.74\n",
      "=========================\n",
      "Recall score :  0.7395833333333334\n",
      "Precision score :  0.7395833333333334\n",
      "F1 score :  0.7395833333333334\n",
      "=========================\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.69      0.77       125\n",
      "           1       0.59      0.84      0.69        67\n",
      "\n",
      "    accuracy                           0.74       192\n",
      "   macro avg       0.74      0.76      0.73       192\n",
      "weighted avg       0.78      0.74      0.75       192\n",
      "\n",
      "Computation time:\n",
      "0.01299905776977539\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "cnb = CategoricalNB(min_categories = n_categories)\n",
    "cnb.fit(X_train, y_train)\n",
    "\n",
    "y_pred_cnb = cnb.predict(X_test)\n",
    "y_prob_pred_cnb = cnb.predict_proba(X_test)\n",
    "\n",
    "# how did our model perform?\n",
    "count_misclassified = (y_test != y_pred_cnb).sum()\n",
    "print(\"CategoricalNB\")\n",
    "print(\"=\" * 25)\n",
    "print('Misclassified samples: {}'.format(count_misclassified))\n",
    "accuracy = accuracy_score(y_test, y_pred_cnb)\n",
    "print('Accuracy: {:.2f}'.format(accuracy))\n",
    "print(\"=\" * 25)\n",
    "print(\"Recall score : \", recall_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"Precision score : \",precision_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"F1 score : \",f1_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"=\" * 25)\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred_cnb))\n",
    "\n",
    "end = time.time()\n",
    "print(\"Computation time:\")\n",
    "print(end - start) # Total time execution for this sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1b4d85c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.251\n",
      "Average bias: 0.255\n",
      "Average variance: 0.069\n",
      "Sklearn 0-1 loss: 0.260\n"
     ]
    }
   ],
   "source": [
    "# calculate classification bias and variance\n",
    "from sklearn.metrics import zero_one_loss\n",
    "#This library is used to decompose bias and variance in our models\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#We will load the Boston house dataset for our example\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn import metrics\n",
    "\n",
    "# y_pred_cnb\n",
    "# y_prob_pred_cnb\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        cnb, X_train.values, y_train.values, X_test.values, y_test.values, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=123)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_cnb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36de93a1",
   "metadata": {},
   "source": [
    "# 2. Decision Tree ID3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5da502c",
   "metadata": {},
   "source": [
    "## 2.1 ID3, 6 Intervals from ChiMerge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bee92c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class representation - original:  Counter({0: 500, 1: 268})\n",
      "Class representation - training data:  Counter({0: 375, 1: 201})\n",
      "Class representation - testing data:  Counter({0: 125, 1: 67})\n",
      "(576, 8) (192, 8)\n",
      "Class representation - training data:  Counter({1: 375, 0: 375})\n"
     ]
    }
   ],
   "source": [
    "# Prepare data and apply SMOTE\n",
    "# make test & train split\n",
    "X = pima6.drop('Outcome', axis=1)\n",
    "y = pima6['Outcome']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=30, stratify = y)\n",
    "\n",
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(pima6['Outcome'])) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test)) \n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "\n",
    "# SMOTE\n",
    "#! pip install imblearn --user\n",
    "from imblearn import under_sampling, over_sampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state = 22)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Check representation of class after SMOTE \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "\n",
    "# SAM\n",
    "# Count number of categories\n",
    "n_categories = pima6.drop('Outcome', axis=1).nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2516a4cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.69\n",
      "=========================\n",
      "Recall score :  0.6927083333333334\n",
      "Precision score :  0.6927083333333334\n",
      "F1 score :  0.6927083333333334\n",
      "=========================\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.70      0.75       125\n",
      "           1       0.55      0.67      0.60        67\n",
      "\n",
      "    accuracy                           0.69       192\n",
      "   macro avg       0.67      0.69      0.68       192\n",
      "weighted avg       0.71      0.69      0.70       192\n",
      "\n",
      "Computation time:\n",
      "0.057999610900878906\n"
     ]
    }
   ],
   "source": [
    "#time recording\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "#build estimator\n",
    "estimator = Id3Estimator()\n",
    "estimator = estimator.fit(X_train, y_train, check_input=True)\n",
    "tree = export_graphviz(estimator.tree_, 'tree.dot', y)\n",
    "#make predictions\n",
    "y_pred_id3 = estimator.predict(X_test)\n",
    "#_prob_pred_id3 = estimator.predict_proba(X_test)\n",
    "#report performance\n",
    "accuracy = accuracy_score(y_test, y_pred_id3)\n",
    "print('Accuracy: {:.2f}'.format(accuracy))\n",
    "print(\"=\" * 25)\n",
    "print(\"Recall score : \", recall_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"Precision score : \",precision_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"F1 score : \",f1_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"=\" * 25)\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred_id3))\n",
    "#stop time recoridng\n",
    "end = time.time()\n",
    "print(\"Computation time:\")\n",
    "print(end - start) # Total time execution for this sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2421a98e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.328\n",
      "Average bias: 0.281\n",
      "Average variance: 0.201\n",
      "Sklearn 0-1 loss: 0.307\n"
     ]
    }
   ],
   "source": [
    "# calculate classification bias and variance\n",
    "from sklearn.metrics import zero_one_loss\n",
    "#This library is used to decompose bias and variance in our models\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#We will load the Boston house dataset for our example\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn import metrics\n",
    "\n",
    "# y_pred_cnb\n",
    "# y_prob_pred_cnb\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        estimator, X_train.values, y_train.values, X_test.values, y_test.values, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=123)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_id3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c21b52",
   "metadata": {},
   "source": [
    "## 2.2 ID3, 8 Intervals from ChiMerge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "82a55254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class representation - original:  Counter({0: 500, 1: 268})\n",
      "Class representation - training data:  Counter({0: 375, 1: 201})\n",
      "Class representation - testing data:  Counter({0: 125, 1: 67})\n",
      "(576, 8) (192, 8)\n",
      "Class representation - training data:  Counter({1: 375, 0: 375})\n"
     ]
    }
   ],
   "source": [
    "# Prepare data and apply SMOTE\n",
    "# make test & train split\n",
    "X = pima8.drop('Outcome', axis=1)\n",
    "y = pima8['Outcome']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=30, stratify = y)\n",
    "\n",
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(pima8['Outcome'])) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test)) \n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "\n",
    "# SMOTE\n",
    "#! pip install imblearn --user\n",
    "from imblearn import under_sampling, over_sampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state = 22)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Check representation of class after SMOTE \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "\n",
    "# SAM\n",
    "# Count number of categories\n",
    "n_categories = pima8.drop('Outcome', axis=1).nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "67c19d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.67\n",
      "=========================\n",
      "Recall score :  0.6666666666666666\n",
      "Precision score :  0.6666666666666666\n",
      "F1 score :  0.6666666666666666\n",
      "=========================\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.62      0.71       125\n",
      "           1       0.52      0.75      0.61        67\n",
      "\n",
      "    accuracy                           0.67       192\n",
      "   macro avg       0.67      0.69      0.66       192\n",
      "weighted avg       0.71      0.67      0.67       192\n",
      "\n",
      "Computation time:\n",
      "0.06553030014038086\n"
     ]
    }
   ],
   "source": [
    "#time recording\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "#build estimator\n",
    "estimator = Id3Estimator()\n",
    "estimator = estimator.fit(X_train, y_train, check_input=True)\n",
    "tree = export_graphviz(estimator.tree_, 'tree.dot', y)\n",
    "#make predictions\n",
    "y_pred_id3 = estimator.predict(X_test)\n",
    "#_prob_pred_id3 = estimator.predict_proba(X_test)\n",
    "#report performance\n",
    "accuracy = accuracy_score(y_test, y_pred_id3)\n",
    "print('Accuracy: {:.2f}'.format(accuracy))\n",
    "print(\"=\" * 25)\n",
    "print(\"Recall score : \", recall_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"Precision score : \",precision_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"F1 score : \",f1_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"=\" * 25)\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred_id3))\n",
    "#stop time recoridng\n",
    "end = time.time()\n",
    "print(\"Computation time:\")\n",
    "print(end - start) # Total time execution for this sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d456f4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.338\n",
      "Average bias: 0.323\n",
      "Average variance: 0.180\n",
      "Sklearn 0-1 loss: 0.333\n"
     ]
    }
   ],
   "source": [
    "# calculate classification bias and variance\n",
    "from sklearn.metrics import zero_one_loss\n",
    "#This library is used to decompose bias and variance in our models\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#We will load the Boston house dataset for our example\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn import metrics\n",
    "\n",
    "# y_pred_cnb\n",
    "# y_prob_pred_cnb\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        estimator, X_train.values, y_train.values, X_test.values, y_test.values, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=123)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_id3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687f1ea3",
   "metadata": {},
   "source": [
    "## 2.3 ID3, 10 Intervals from ChiMerge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "21ba26c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class representation - original:  Counter({0: 500, 1: 268})\n",
      "Class representation - training data:  Counter({0: 375, 1: 201})\n",
      "Class representation - testing data:  Counter({0: 125, 1: 67})\n",
      "(576, 8) (192, 8)\n",
      "Class representation - training data:  Counter({1: 375, 0: 375})\n"
     ]
    }
   ],
   "source": [
    "# Prepare data and apply SMOTE\n",
    "# make test & train split\n",
    "X = pima10.drop('Outcome', axis=1)\n",
    "y = pima10['Outcome']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=30, stratify = y)\n",
    "\n",
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(pima10['Outcome'])) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test)) \n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "\n",
    "# SMOTE\n",
    "#! pip install imblearn --user\n",
    "from imblearn import under_sampling, over_sampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state = 22)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Check representation of class after SMOTE \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "\n",
    "# SAM\n",
    "# Count number of categories\n",
    "n_categories = pima10.drop('Outcome', axis=1).nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b7856ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.69\n",
      "=========================\n",
      "Recall score :  0.6875\n",
      "Precision score :  0.6875\n",
      "F1 score :  0.6875\n",
      "=========================\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.68      0.74       125\n",
      "           1       0.54      0.70      0.61        67\n",
      "\n",
      "    accuracy                           0.69       192\n",
      "   macro avg       0.67      0.69      0.67       192\n",
      "weighted avg       0.72      0.69      0.69       192\n",
      "\n",
      "Computation time:\n",
      "0.07196903228759766\n"
     ]
    }
   ],
   "source": [
    "#time recording\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "#build estimator\n",
    "estimator = Id3Estimator()\n",
    "estimator = estimator.fit(X_train, y_train, check_input=True)\n",
    "tree = export_graphviz(estimator.tree_, 'tree.dot', y)\n",
    "#make predictions\n",
    "y_pred_id3 = estimator.predict(X_test)\n",
    "#_prob_pred_id3 = estimator.predict_proba(X_test)\n",
    "#report performance\n",
    "accuracy = accuracy_score(y_test, y_pred_id3)\n",
    "print('Accuracy: {:.2f}'.format(accuracy))\n",
    "print(\"=\" * 25)\n",
    "print(\"Recall score : \", recall_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"Precision score : \",precision_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"F1 score : \",f1_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"=\" * 25)\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred_id3))\n",
    "#stop time recoridng\n",
    "end = time.time()\n",
    "print(\"Computation time:\")\n",
    "print(end - start) # Total time execution for this sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "42b253bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.327\n",
      "Average bias: 0.297\n",
      "Average variance: 0.179\n",
      "Sklearn 0-1 loss: 0.312\n"
     ]
    }
   ],
   "source": [
    "# calculate classification bias and variance\n",
    "from sklearn.metrics import zero_one_loss\n",
    "#This library is used to decompose bias and variance in our models\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#We will load the Boston house dataset for our example\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn import metrics\n",
    "\n",
    "# y_pred_cnb\n",
    "# y_prob_pred_cnb\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        estimator, X_train.values, y_train.values, X_test.values, y_test.values, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=123)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_id3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251b1503",
   "metadata": {},
   "source": [
    "## 2.4 ID3, 15 Intervals from CHiMerge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "35c9a134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class representation - original:  Counter({0: 500, 1: 268})\n",
      "Class representation - training data:  Counter({0: 375, 1: 201})\n",
      "Class representation - testing data:  Counter({0: 125, 1: 67})\n",
      "(576, 8) (192, 8)\n",
      "Class representation - training data:  Counter({1: 375, 0: 375})\n"
     ]
    }
   ],
   "source": [
    "# Prepare data and apply SMOTE\n",
    "# make test & train split\n",
    "X = pima15.drop('Outcome', axis=1)\n",
    "y = pima15['Outcome']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=30, stratify = y)\n",
    "\n",
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(pima15['Outcome'])) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test)) \n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "\n",
    "# SMOTE\n",
    "#! pip install imblearn --user\n",
    "from imblearn import under_sampling, over_sampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state = 22)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Check representation of class after SMOTE \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "\n",
    "# SAM\n",
    "# Count number of categories\n",
    "n_categories = pima15.drop('Outcome', axis=1).nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3426c93d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.65\n",
      "=========================\n",
      "Recall score :  0.6458333333333334\n",
      "Precision score :  0.6458333333333334\n",
      "F1 score :  0.6458333333333334\n",
      "=========================\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.57      0.68       125\n",
      "           1       0.50      0.79      0.61        67\n",
      "\n",
      "    accuracy                           0.65       192\n",
      "   macro avg       0.67      0.68      0.64       192\n",
      "weighted avg       0.72      0.65      0.65       192\n",
      "\n",
      "Computation time:\n",
      "0.08424687385559082\n"
     ]
    }
   ],
   "source": [
    "#time recording\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "#build estimator\n",
    "estimator = Id3Estimator()\n",
    "estimator = estimator.fit(X_train, y_train, check_input=True)\n",
    "tree = export_graphviz(estimator.tree_, 'tree.dot', y)\n",
    "#make predictions\n",
    "y_pred_id3 = estimator.predict(X_test)\n",
    "#_prob_pred_id3 = estimator.predict_proba(X_test)\n",
    "#report performance\n",
    "accuracy = accuracy_score(y_test, y_pred_id3)\n",
    "print('Accuracy: {:.2f}'.format(accuracy))\n",
    "print(\"=\" * 25)\n",
    "print(\"Recall score : \", recall_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"Precision score : \",precision_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"F1 score : \",f1_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"=\" * 25)\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred_id3))\n",
    "#stop time recoridng\n",
    "end = time.time()\n",
    "print(\"Computation time:\")\n",
    "print(end - start) # Total time execution for this sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "839ec68d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.331\n",
      "Average bias: 0.297\n",
      "Average variance: 0.191\n",
      "Sklearn 0-1 loss: 0.354\n"
     ]
    }
   ],
   "source": [
    "# calculate classification bias and variance\n",
    "from sklearn.metrics import zero_one_loss\n",
    "#This library is used to decompose bias and variance in our models\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#We will load the Boston house dataset for our example\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn import metrics\n",
    "\n",
    "# y_pred_cnb\n",
    "# y_prob_pred_cnb\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        estimator, X_train.values, y_train.values, X_test.values, y_test.values, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=123)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_id3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9d5f3d",
   "metadata": {},
   "source": [
    "# 3. KNN classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfc2760",
   "metadata": {},
   "source": [
    "## 3.1 KNN, 6 Intervals from CHiMerge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c9ed00bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class representation - original:  Counter({0: 500, 1: 268})\n",
      "Class representation - training data:  Counter({0: 375, 1: 201})\n",
      "Class representation - testing data:  Counter({0: 125, 1: 67})\n",
      "(576, 8) (192, 8)\n",
      "Class representation - training data:  Counter({1: 375, 0: 375})\n"
     ]
    }
   ],
   "source": [
    "# Prepare data and apply SMOTE\n",
    "# make test & train split\n",
    "X = pima6.drop('Outcome', axis=1)\n",
    "y = pima6['Outcome']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=30, stratify = y)\n",
    "\n",
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(pima6['Outcome'])) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test)) \n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "\n",
    "# SMOTE\n",
    "#! pip install imblearn --user\n",
    "from imblearn import under_sampling, over_sampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state = 22)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Check representation of class after SMOTE \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "\n",
    "# SAM\n",
    "# Count number of categories\n",
    "n_categories = pima6.drop('Outcome', axis=1).nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "dfe593f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.74      0.83       125\n",
      "           1       0.65      0.90      0.75        67\n",
      "\n",
      "    accuracy                           0.80       192\n",
      "   macro avg       0.79      0.82      0.79       192\n",
      "weighted avg       0.83      0.80      0.80       192\n",
      "\n",
      "Time for training model Knn-VDM: 44.129278898239136.\n"
     ]
    }
   ],
   "source": [
    "# Knn-VDM complete code\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "# specific the continuous columns index if any\n",
    "vdm = ValueDifferenceMetric(X_train, y_train, continuous = None)\n",
    "vdm.fit()\n",
    "# Knn model, n_neigbour = 3, metrics = vdm\n",
    "knn_vdm = KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')\n",
    "# Fit model\n",
    "knn_vdm.fit(X_train, y_train)\n",
    "# Testing\n",
    "y_pred_knn = knn_vdm.predict(X_test)\n",
    "knn_vdm.classes_\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model Knn-VDM: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a91d6c12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 2, 3, ..., 4, 0, 3],\n",
       "       [3, 4, 3, ..., 1, 0, 3],\n",
       "       [0, 3, 2, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [3, 2, 3, ..., 4, 2, 2],\n",
       "       [3, 5, 3, ..., 4, 2, 2],\n",
       "       [1, 5, 2, ..., 1, 0, 2]], dtype=int64)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8e68e4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.255\n",
      "Average bias: 0.198\n",
      "Average variance: 0.131\n",
      "Sklearn 0-1 loss: 0.203\n"
     ]
    }
   ],
   "source": [
    "# !!!! WARING: TIME CONSUMING\n",
    "\n",
    "# Bias and variance decomposition\n",
    "# Convert all dataframe to array first\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "y_train = y_train.values\n",
    "y_test = y_test.values\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        knn_vdm, X_train, y_train, X_test, y_test, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=123)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55006f71",
   "metadata": {},
   "source": [
    "## 3.2 KNN with ChiMerge 8 intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7ec9e695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class representation - original:  Counter({0: 500, 1: 268})\n",
      "Class representation - training data:  Counter({0: 375, 1: 201})\n",
      "Class representation - testing data:  Counter({0: 125, 1: 67})\n",
      "(576, 8) (192, 8)\n",
      "Class representation - training data:  Counter({1: 375, 0: 375})\n"
     ]
    }
   ],
   "source": [
    "# Prepare data and apply SMOTE\n",
    "# make test & train split\n",
    "X = pima8.drop('Outcome', axis=1)\n",
    "y = pima8['Outcome']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=30, stratify = y)\n",
    "\n",
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(pima8['Outcome'])) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test)) \n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "\n",
    "# SMOTE\n",
    "#! pip install imblearn --user\n",
    "from imblearn import under_sampling, over_sampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state = 22)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Check representation of class after SMOTE \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "\n",
    "# SAM\n",
    "# Count number of categories\n",
    "n_categories = pima8.drop('Outcome', axis=1).nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "cd4019bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.74      0.80       125\n",
      "           1       0.62      0.82      0.71        67\n",
      "\n",
      "    accuracy                           0.77       192\n",
      "   macro avg       0.75      0.78      0.76       192\n",
      "weighted avg       0.79      0.77      0.77       192\n",
      "\n",
      "Time for training model Knn-VDM: 37.5856409072876.\n"
     ]
    }
   ],
   "source": [
    "# Knn-VDM complete code\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "# specific the continuous columns index if any\n",
    "vdm = ValueDifferenceMetric(X_train, y_train, continuous = None)\n",
    "vdm.fit()\n",
    "# Knn model, n_neigbour = 3, metrics = vdm\n",
    "knn_vdm = KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')\n",
    "# Fit model\n",
    "knn_vdm.fit(X_train, y_train)\n",
    "# Testing\n",
    "y_pred_knn = knn_vdm.predict(X_test)\n",
    "knn_vdm.classes_\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model Knn-VDM: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ebea6f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.253\n",
      "Average bias: 0.234\n",
      "Average variance: 0.126\n",
      "Sklearn 0-1 loss: 0.234\n"
     ]
    }
   ],
   "source": [
    "# !!!! WARING: TIME CONSUMING\n",
    "\n",
    "# Bias and variance decomposition\n",
    "# Convert all dataframe to array first\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "y_train = y_train.values\n",
    "y_test = y_test.values\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        knn_vdm, X_train, y_train, X_test, y_test, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=123)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a527ed9",
   "metadata": {},
   "source": [
    "## 3.3 KNN with ChiMerge 10 intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "55cd983d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class representation - original:  Counter({0: 500, 1: 268})\n",
      "Class representation - training data:  Counter({0: 375, 1: 201})\n",
      "Class representation - testing data:  Counter({0: 125, 1: 67})\n",
      "(576, 8) (192, 8)\n",
      "Class representation - training data:  Counter({1: 375, 0: 375})\n"
     ]
    }
   ],
   "source": [
    "# Prepare data and apply SMOTE\n",
    "# make test & train split\n",
    "X = pima10.drop('Outcome', axis=1)\n",
    "y = pima10['Outcome']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=30, stratify = y)\n",
    "\n",
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(pima10['Outcome'])) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test)) \n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "\n",
    "# SMOTE\n",
    "#! pip install imblearn --user\n",
    "from imblearn import under_sampling, over_sampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state = 22)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Check representation of class after SMOTE \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "\n",
    "# SAM\n",
    "# Count number of categories\n",
    "n_categories = pima10.drop('Outcome', axis=1).nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "351221a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.78      0.83       125\n",
      "           1       0.66      0.79      0.72        67\n",
      "\n",
      "    accuracy                           0.79       192\n",
      "   macro avg       0.77      0.79      0.77       192\n",
      "weighted avg       0.80      0.79      0.79       192\n",
      "\n",
      "Time for training model Knn-VDM: 39.26955699920654.\n"
     ]
    }
   ],
   "source": [
    "# Knn-VDM complete code\n",
    "# accuracy                           0.79       192\n",
    "# Time for training model Knn-VDM: 39.84472727775574.\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "# specific the continuous columns index if any\n",
    "vdm = ValueDifferenceMetric(X_train, y_train, continuous = None)\n",
    "vdm.fit()\n",
    "# Knn model, n_neigbour = 3, metrics = vdm\n",
    "knn_vdm = KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')\n",
    "# Fit model\n",
    "knn_vdm.fit(X_train, y_train)\n",
    "# Testing\n",
    "y_pred_knn = knn_vdm.predict(X_test)\n",
    "knn_vdm.classes_\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model Knn-VDM: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "68246577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.242\n",
      "Average bias: 0.219\n",
      "Average variance: 0.126\n",
      "Sklearn 0-1 loss: 0.214\n"
     ]
    }
   ],
   "source": [
    "# !!!! WARING: TIME CONSUMING\n",
    "\n",
    "# Bias and variance decomposition\n",
    "# Convert all dataframe to array first\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "y_train = y_train.values\n",
    "y_test = y_test.values\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        knn_vdm, X_train, y_train, X_test, y_test, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=123)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb00a1f6",
   "metadata": {},
   "source": [
    "## 3.4 KNN with ChiMerge 15 intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c19c6d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class representation - original:  Counter({0: 500, 1: 268})\n",
      "Class representation - training data:  Counter({0: 375, 1: 201})\n",
      "Class representation - testing data:  Counter({0: 125, 1: 67})\n",
      "(576, 8) (192, 8)\n",
      "Class representation - training data:  Counter({1: 375, 0: 375})\n"
     ]
    }
   ],
   "source": [
    "# Prepare data and apply SMOTE\n",
    "# make test & train split\n",
    "X = pima15.drop('Outcome', axis=1)\n",
    "y = pima15['Outcome']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=30, stratify = y)\n",
    "\n",
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(pima15['Outcome'])) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test)) \n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "\n",
    "# SMOTE\n",
    "#! pip install imblearn --user\n",
    "from imblearn import under_sampling, over_sampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state = 22)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Check representation of class after SMOTE \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "\n",
    "# SAM\n",
    "# Count number of categories\n",
    "n_categories = pima15.drop('Outcome', axis=1).nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cee14d45",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "13.0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [70]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m knn_vdm\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Testing\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m y_pred_knn \u001b[38;5;241m=\u001b[39m \u001b[43mknn_vdm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m knn_vdm\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(y_test, y_pred_knn))\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:226\u001b[0m, in \u001b[0;36mKNeighborsClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;124;03m\"\"\"Predict the class labels for the provided data.\u001b[39;00m\n\u001b[0;32m    211\u001b[0m \n\u001b[0;32m    212\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;124;03m    Class labels for each data sample.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muniform\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;66;03m# In that case, we do not need the distances to perform\u001b[39;00m\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;66;03m# the weighting so we do not compute them.\u001b[39;00m\n\u001b[1;32m--> 226\u001b[0m     neigh_ind \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkneighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    227\u001b[0m     neigh_dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py:796\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    793\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    794\u001b[0m         kwds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meffective_metric_params_\n\u001b[1;32m--> 796\u001b[0m     chunked_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpairwise_distances_chunked\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    798\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_X\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    800\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreduce_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreduce_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    801\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meffective_metric_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    802\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    803\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    804\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    805\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    807\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_method \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mball_tree\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkd_tree\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m issparse(X):\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1850\u001b[0m, in \u001b[0;36mpairwise_distances_chunked\u001b[1;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1849\u001b[0m     X_chunk \u001b[38;5;241m=\u001b[39m X[sl]\n\u001b[1;32m-> 1850\u001b[0m D_chunk \u001b[38;5;241m=\u001b[39m pairwise_distances(X_chunk, Y, metric\u001b[38;5;241m=\u001b[39mmetric, n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m   1851\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (X \u001b[38;5;129;01mis\u001b[39;00m Y \u001b[38;5;129;01mor\u001b[39;00m Y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m PAIRWISE_DISTANCE_FUNCTIONS\u001b[38;5;241m.\u001b[39mget(\n\u001b[0;32m   1852\u001b[0m     metric, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1853\u001b[0m ) \u001b[38;5;129;01mis\u001b[39;00m euclidean_distances:\n\u001b[0;32m   1854\u001b[0m     \u001b[38;5;66;03m# zeroing diagonal, taking care of aliases of \"euclidean\",\u001b[39;00m\n\u001b[0;32m   1855\u001b[0m     \u001b[38;5;66;03m# i.e. \"l2\"\u001b[39;00m\n\u001b[0;32m   1856\u001b[0m     D_chunk\u001b[38;5;241m.\u001b[39mflat[sl\u001b[38;5;241m.\u001b[39mstart :: _num_samples(X) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:2022\u001b[0m, in \u001b[0;36mpairwise_distances\u001b[1;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[0;32m   2019\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m distance\u001b[38;5;241m.\u001b[39msquareform(distance\u001b[38;5;241m.\u001b[39mpdist(X, metric\u001b[38;5;241m=\u001b[39mmetric, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds))\n\u001b[0;32m   2020\u001b[0m     func \u001b[38;5;241m=\u001b[39m partial(distance\u001b[38;5;241m.\u001b[39mcdist, metric\u001b[38;5;241m=\u001b[39mmetric, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m-> 2022\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _parallel_pairwise(X, Y, func, n_jobs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1563\u001b[0m, in \u001b[0;36m_parallel_pairwise\u001b[1;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[0;32m   1560\u001b[0m X, Y, dtype \u001b[38;5;241m=\u001b[39m _return_float_dtype(X, Y)\n\u001b[0;32m   1562\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m effective_n_jobs(n_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m-> 1563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(X, Y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m   1565\u001b[0m \u001b[38;5;66;03m# enforce a threading backend to prevent data communication overhead\u001b[39;00m\n\u001b[0;32m   1566\u001b[0m fd \u001b[38;5;241m=\u001b[39m delayed(_dist_wrapper)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1607\u001b[0m, in \u001b[0;36m_pairwise_callable\u001b[1;34m(X, Y, metric, force_all_finite, **kwds)\u001b[0m\n\u001b[0;32m   1605\u001b[0m     iterator \u001b[38;5;241m=\u001b[39m itertools\u001b[38;5;241m.\u001b[39mproduct(\u001b[38;5;28mrange\u001b[39m(X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]), \u001b[38;5;28mrange\u001b[39m(Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]))\n\u001b[0;32m   1606\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, j \u001b[38;5;129;01min\u001b[39;00m iterator:\n\u001b[1;32m-> 1607\u001b[0m         out[i, j] \u001b[38;5;241m=\u001b[39m metric(X[i], Y[j], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m   1609\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\vdm3\\vdm.py:83\u001b[0m, in \u001b[0;36mValueDifferenceMetric.get_distance\u001b[1;34m(self, ins_1, ins_2, norm)\u001b[0m\n\u001b[0;32m     80\u001b[0m     ins_1_cat \u001b[38;5;241m=\u001b[39m ins_1\n\u001b[0;32m     81\u001b[0m     ins_2_cat \u001b[38;5;241m=\u001b[39m ins_2\n\u001b[1;32m---> 83\u001b[0m cat_dist \u001b[38;5;241m=\u001b[39m \u001b[43mget_delta_nd\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcond_proba\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mins_1_cat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mins_2_cat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontinuous \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     86\u001b[0m     cont_dist \u001b[38;5;241m=\u001b[39m get_cont_dist(ins_1_cont, ins_2_cont, norm)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\vdm3\\components.py:77\u001b[0m, in \u001b[0;36mget_delta_nd\u001b[1;34m(cond_proba, ins_1, ins_2, norm)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_delta_nd\u001b[39m(cond_proba, ins_1, ins_2, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m):\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;124;03m\"\"\" get deltas for vdm for multidimensional data\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    Parameters: cond_proba (dict) - a dictionary of conditional probability, extract from get_conditional_proba_nd()\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;124;03m    Returns: deltas (array) - the delta values between ins_1 and ins_2\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 77\u001b[0m     deltas \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([get_delta(cond_proba[col], ins_1[col], ins_2[col], norm) \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m cond_proba])\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m deltas\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\vdm3\\components.py:77\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_delta_nd\u001b[39m(cond_proba, ins_1, ins_2, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m):\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;124;03m\"\"\" get deltas for vdm for multidimensional data\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    Parameters: cond_proba (dict) - a dictionary of conditional probability, extract from get_conditional_proba_nd()\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;124;03m    Returns: deltas (array) - the delta values between ins_1 and ins_2\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 77\u001b[0m     deltas \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[43mget_delta\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcond_proba\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mins_1\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mins_2\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m cond_proba])\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m deltas\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\vdm3\\components.py:51\u001b[0m, in \u001b[0;36mget_delta\u001b[1;34m(cond_proba, val_1, val_2, norm)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_delta\u001b[39m(cond_proba, val_1, val_2, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m):\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;124;03m\"\"\" get delta for vdm\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \n\u001b[0;32m     44\u001b[0m \u001b[38;5;124;03m    Parameters: cond_proba (dict) - a dictionary of conditional probability, extract from get_conditional_proba()\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;124;03m    Returns: delta (float) - the delta value for this instance\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m     proba \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;28mabs\u001b[39m(cond_proba[val_1][uni_x] \u001b[38;5;241m-\u001b[39m cond_proba[val_2][uni_x]) \u001b[38;5;28;01mfor\u001b[39;00m uni_x \u001b[38;5;129;01min\u001b[39;00m \u001b[43mcond_proba\u001b[49m\u001b[43m[\u001b[49m\u001b[43mval_1\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mindex])\n\u001b[0;32m     52\u001b[0m     delta \u001b[38;5;241m=\u001b[39m (proba\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnorm)\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m delta\n",
      "\u001b[1;31mKeyError\u001b[0m: 13.0"
     ]
    }
   ],
   "source": [
    "# Knn-VDM complete code\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "# specific the continuous columns index if any\n",
    "vdm = ValueDifferenceMetric(X_train, y_train, continuous = None)\n",
    "vdm.fit()\n",
    "# Knn model, n_neigbour = 3, metrics = vdm\n",
    "knn_vdm = KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')\n",
    "# Fit model\n",
    "knn_vdm.fit(X_train, y_train)\n",
    "# Testing\n",
    "y_pred_knn = knn_vdm.predict(X_test)\n",
    "knn_vdm.classes_\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model Knn-VDM: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7d20fc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # !!!! WARING: TIME CONSUMING\n",
    "\n",
    "# # Bias and variance decomposition\n",
    "# # Convert all dataframe to array first\n",
    "# X_train = X_train.values\n",
    "# X_test = X_test.values\n",
    "# y_train = y_train.values\n",
    "# y_test = y_test.values\n",
    "\n",
    "# avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "#         knn_vdm, X_train, y_train, X_test, y_test, \n",
    "#         loss='0-1_loss',\n",
    "#         random_seed=123)\n",
    "\n",
    "# print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "# print('Average bias: %.3f' % avg_bias)\n",
    "# print('Average variance: %.3f' % avg_var)\n",
    "# print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bad5936",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
