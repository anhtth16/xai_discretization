{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abd2336c",
   "metadata": {},
   "source": [
    "# Classification models - Supervised Discretization\n",
    "## Dataset: pima\n",
    "\n",
    "Updated by: Sam\n",
    "Update at: 13/10/2022 <br>\n",
    "---\n",
    "Discretization methods: DecisionTree (DT)<br>\n",
    "Classification models: CNB, ID3, KNN-VDM\n",
    "---\n",
    "NOTE: \n",
    "NEED TO DO SMOTE for imbalance dataset before training\n",
    "Long time for computation of Knn-VDM (Run this part last) <br>\n",
    "Use Malina scripts for Knn, ID3 <br>\n",
    "Use Sam scripts (with min_categories) for Naive Bayes <br>\n",
    "Key Errors for training and decomposition KNN-VDM models => No metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83bc40c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, roc_auc_score, recall_score, precision_score\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "import six\n",
    "import sys\n",
    "sys.modules['sklearn.externals.six'] = six\n",
    "import id3\n",
    "from id3 import Id3Estimator\n",
    "from id3 import export_graphviz\n",
    "import wittgenstein as lw\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "from pandas import set_option\n",
    "import numpy as np\n",
    "from numpy import arange\n",
    "## EDA\n",
    "from collections import Counter\n",
    "\n",
    "# Knn-VDM 3\n",
    "from vdm3 import ValueDifferenceMetric\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Pre-processing\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "# Cross validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score # 1 metric\n",
    "from sklearn.model_selection import cross_validate # more than 1 metric\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50eb04fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in data from ChiMerge discretization\n",
    "pima_m2 = pd.read_csv('DT_small_discretized_pima.csv') # max_depth = 2\n",
    "pima_m3 = pd.read_csv('DT_medium_discretized_pima.csv')  # max_depth = 3\n",
    "pima_m4 = pd.read_csv('DT_large_discretized_pima.csv')  # max_depth = 4\n",
    "pima_m5 = pd.read_csv('DT_verylarge_discretized_pima.csv')  # max_depth = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "409c4ba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin  BMI  \\\n",
       "0            1        2              3              2        1    2   \n",
       "1            0        0              1              1        1    0   \n",
       "2            0        1              1              2        1    2   \n",
       "3            0        2              2              1        1    2   \n",
       "4            1        1              1              1        1    2   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                         2    0        1  \n",
       "1                         2    2        0  \n",
       "2                         2    2        0  \n",
       "3                         2    1        1  \n",
       "4                         1    3        1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pima_m2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24075c8",
   "metadata": {},
   "source": [
    "## Interval frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94258ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_list_m2 = list(pima_m2.drop('Outcome', axis=1).columns)\n",
    "num_list_m3 = list(pima_m3.drop('Outcome', axis=1).columns)\n",
    "num_list_m4 = list(pima_m4.drop('Outcome', axis=1).columns)\n",
    "num_list_m5 = list(pima_m5.drop('Outcome', axis=1).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be896d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interval frequency for 6 Intervals\n",
      "Interval for Pregnancies\n",
      "Counter({0: 488, 2: 165, 1: 111, 3: 4})\n",
      "Interval for Glucose\n",
      "Counter({0: 419, 1: 180, 3: 102, 2: 67})\n",
      "Interval for BloodPressure\n",
      "Counter({1: 479, 2: 154, 3: 134, 0: 1})\n",
      "Interval for SkinThickness\n",
      "Counter({2: 367, 1: 229, 0: 170, 3: 2})\n",
      "Interval for Insulin\n",
      "Counter({1: 375, 0: 230, 2: 157, 3: 6})\n",
      "Interval for BMI\n",
      "Counter({2: 560, 0: 170, 1: 24, 3: 14})\n",
      "Interval for DiabetesPedigreeFunction\n",
      "Counter({2: 308, 1: 208, 3: 135, 0: 117})\n",
      "Interval for Age\n",
      "Counter({3: 380, 2: 232, 0: 135, 1: 21})\n"
     ]
    }
   ],
   "source": [
    "print('Interval frequency for 6 Intervals')\n",
    "for i in num_list_m2:\n",
    "    print('Interval for ' + i)\n",
    "    print(Counter(pima_m2[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3edf860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency for aus with 8 Intervals\n",
      "Interval for Pregnancies\n",
      "Counter({1: 250, 0: 238, 2: 111, 4: 111, 3: 54, 5: 4})\n",
      "Interval for Glucose\n",
      "Counter({1: 222, 0: 197, 3: 153, 7: 79, 4: 41, 2: 27, 5: 26, 6: 23})\n",
      "Interval for BloodPressure\n",
      "Counter({1: 404, 5: 122, 4: 84, 3: 75, 2: 70, 6: 12, 0: 1})\n",
      "Interval for SkinThickness\n",
      "Counter({3: 355, 2: 227, 1: 99, 0: 71, 5: 12, 6: 2, 4: 2})\n",
      "Interval for Insulin\n",
      "Counter({3: 374, 4: 155, 1: 117, 2: 113, 5: 4, 6: 3, 0: 2})\n",
      "Interval for BMI\n",
      "Counter({4: 411, 2: 149, 1: 126, 0: 53, 3: 15, 6: 11, 5: 3})\n",
      "Interval for DiabetesPedigreeFunction\n",
      "Counter({4: 260, 5: 152, 6: 121, 2: 61, 1: 56, 0: 56, 7: 48, 3: 14})\n",
      "Interval for Age\n",
      "Counter({6: 207, 7: 173, 4: 148, 3: 84, 2: 72, 1: 63, 5: 13, 0: 8})\n"
     ]
    }
   ],
   "source": [
    "print('Frequency for aus with 8 Intervals')\n",
    "for i in num_list_m3:\n",
    "    print('Interval for ' + i)\n",
    "    print(Counter(pima_m3[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd8cdde0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency for aus with 10 Intervals\n",
      "Interval for Pregnancies\n",
      "Counter({3: 200, 1: 135, 4: 111, 0: 103, 7: 83, 2: 50, 5: 44, 8: 28, 6: 10, 9: 4})\n",
      "Interval for Glucose\n",
      "Counter({1: 192, 5: 141, 7: 128, 2: 81, 15: 57, 10: 38, 9: 25, 12: 22, 11: 21, 6: 18, 14: 16, 3: 9, 4: 7, 13: 5, 8: 5, 0: 3})\n",
      "Interval for BloodPressure\n",
      "Counter({4: 358, 9: 111, 5: 51, 1: 46, 8: 45, 3: 40, 7: 39, 6: 30, 10: 24, 2: 11, 11: 9, 12: 3, 0: 1})\n",
      "Interval for SkinThickness\n",
      "Counter({5: 227, 6: 217, 4: 138, 2: 61, 1: 58, 3: 38, 0: 13, 8: 12, 9: 2, 7: 2})\n",
      "Interval for Insulin\n",
      "Counter({4: 374, 5: 144, 3: 109, 1: 108, 7: 11, 2: 9, 6: 7, 8: 4, 0: 2})\n",
      "Interval for BMI\n",
      "Counter({5: 340, 1: 123, 2: 103, 7: 71, 0: 54, 4: 46, 8: 15, 3: 13, 6: 3})\n",
      "Interval for DiabetesPedigreeFunction\n",
      "Counter({6: 247, 5: 148, 7: 103, 3: 54, 0: 45, 2: 34, 8: 30, 1: 29, 4: 27, 12: 18, 11: 18, 9: 7, 13: 4, 10: 4})\n",
      "Interval for Age\n",
      "Counter({10: 182, 11: 140, 5: 100, 2: 72, 1: 63, 6: 48, 3: 46, 4: 38, 9: 33, 8: 25, 7: 11, 0: 10})\n"
     ]
    }
   ],
   "source": [
    "print('Frequency for aus with 10 Intervals')\n",
    "for i in num_list_m4:\n",
    "    print('Interval for ' + i)\n",
    "    print(Counter(pima_m4[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25638c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency for aus with 15 Intervals\n",
      "Interval for Pregnancies\n",
      "Counter({3: 143, 1: 135, 5: 111, 0: 103, 4: 57, 2: 50, 10: 45, 9: 38, 7: 35, 11: 28, 8: 10, 6: 9, 12: 4})\n",
      "Interval for Glucose\n",
      "Counter({2: 165, 10: 114, 7: 95, 5: 67, 4: 46, 0: 34, 19: 33, 20: 31, 13: 27, 11: 26, 15: 20, 3: 14, 12: 14, 1: 14, 8: 12, 18: 11, 14: 11, 17: 10, 6: 9, 16: 9, 9: 6})\n",
      "Interval for BloodPressure\n",
      "Counter({6: 350, 11: 75, 5: 50, 10: 45, 7: 40, 9: 39, 13: 36, 1: 35, 8: 30, 12: 13, 2: 11, 14: 11, 4: 11, 3: 8, 15: 6, 0: 5, 16: 3})\n",
      "Interval for SkinThickness\n",
      "Counter({9: 227, 11: 207, 8: 106, 5: 51, 1: 34, 10: 32, 4: 24, 3: 22, 7: 16, 0: 13, 13: 12, 2: 10, 6: 10, 14: 2, 12: 2})\n",
      "Interval for Insulin\n",
      "Counter({5: 374, 8: 127, 3: 70, 1: 56, 2: 52, 6: 39, 4: 17, 0: 10, 10: 9, 9: 7, 7: 7})\n",
      "Interval for BMI\n",
      "Counter({9: 329, 7: 89, 3: 64, 1: 59, 0: 54, 11: 46, 6: 36, 8: 25, 13: 15, 2: 14, 4: 11, 12: 10, 5: 10, 10: 6})\n",
      "Interval for DiabetesPedigreeFunction\n",
      "Counter({10: 128, 8: 120, 7: 119, 0: 59, 13: 57, 9: 46, 5: 32, 1: 30, 6: 28, 18: 26, 3: 25, 2: 22, 11: 19, 4: 15, 15: 11, 17: 11, 16: 9, 12: 7, 14: 4})\n",
      "Interval for Age\n",
      "Counter({12: 166, 13: 105, 2: 72, 6: 67, 1: 63, 9: 48, 4: 46, 5: 38, 15: 35, 3: 33, 10: 29, 14: 16, 11: 13, 7: 12, 8: 10, 0: 10, 16: 5})\n"
     ]
    }
   ],
   "source": [
    "print('Frequency for aus with 15 Intervals')\n",
    "for i in num_list_m5:\n",
    "    print('Interval for ' + i)\n",
    "    print(Counter(pima_m5[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2d79abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype\n",
      "---  ------                    --------------  -----\n",
      " 0   Pregnancies               768 non-null    int64\n",
      " 1   Glucose                   768 non-null    int64\n",
      " 2   BloodPressure             768 non-null    int64\n",
      " 3   SkinThickness             768 non-null    int64\n",
      " 4   Insulin                   768 non-null    int64\n",
      " 5   BMI                       768 non-null    int64\n",
      " 6   DiabetesPedigreeFunction  768 non-null    int64\n",
      " 7   Age                       768 non-null    int64\n",
      " 8   Outcome                   768 non-null    int64\n",
      "dtypes: int64(9)\n",
      "memory usage: 54.1 KB\n"
     ]
    }
   ],
   "source": [
    "pima_m2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb0320e",
   "metadata": {},
   "source": [
    "# 1. Categorical Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1cfced",
   "metadata": {},
   "source": [
    "## 1.1 CNB, DT, max_depth = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "956e32e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make test & train split\n",
    "X = pima_m2.drop('Outcome', axis=1)\n",
    "y = pima_m2['Outcome']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=30, stratify = y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39b29b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class representation - original:  Counter({0: 500, 1: 268})\n",
      "Class representation - training data:  Counter({0: 375, 1: 201})\n",
      "Class representation - testing data:  Counter({0: 125, 1: 67})\n"
     ]
    }
   ],
   "source": [
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(pima_m2['Outcome'])) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76c26c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(576, 8) (192, 8)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "146d9043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTE\n",
    "#! pip install imblearn --user\n",
    "from imblearn import under_sampling, over_sampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state = 22)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "757ca754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAM\n",
    "# Count number of categories\n",
    "n_categories = pima_m2.drop('Outcome', axis=1).nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99b94bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CategoricalNB\n",
      "=========================\n",
      "Misclassified samples: 61\n",
      "Accuracy: 0.68\n",
      "=========================\n",
      "Recall score :  0.6822916666666666\n",
      "Precision score :  0.6822916666666666\n",
      "F1 score :  0.6822916666666666\n",
      "=========================\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.59      0.71       125\n",
      "           1       0.53      0.85      0.65        67\n",
      "\n",
      "    accuracy                           0.68       192\n",
      "   macro avg       0.70      0.72      0.68       192\n",
      "weighted avg       0.76      0.68      0.69       192\n",
      "\n",
      "Computation time:\n",
      "0.012999773025512695\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "cnb = CategoricalNB(min_categories = n_categories)\n",
    "cnb.fit(X_train, y_train)\n",
    "\n",
    "y_pred_cnb = cnb.predict(X_test)\n",
    "y_prob_pred_cnb = cnb.predict_proba(X_test)\n",
    "\n",
    "# how did our model perform?\n",
    "count_misclassified = (y_test != y_pred_cnb).sum()\n",
    "print(\"CategoricalNB\")\n",
    "print(\"=\" * 25)\n",
    "print('Misclassified samples: {}'.format(count_misclassified))\n",
    "accuracy = accuracy_score(y_test, y_pred_cnb)\n",
    "print('Accuracy: {:.2f}'.format(accuracy))\n",
    "print(\"=\" * 25)\n",
    "print(\"Recall score : \", recall_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"Precision score : \",precision_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"F1 score : \",f1_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"=\" * 25)\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred_cnb))\n",
    "\n",
    "end = time.time()\n",
    "print(\"Computation time:\")\n",
    "print(end - start) # Total time execution for this sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82d4dfb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.301\n",
      "Average bias: 0.312\n",
      "Average variance: 0.045\n",
      "Sklearn 0-1 loss: 0.318\n"
     ]
    }
   ],
   "source": [
    "# calculate classification bias and variance\n",
    "from sklearn.metrics import zero_one_loss\n",
    "#This library is used to decompose bias and variance in our models\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#We will load the Boston house dataset for our example\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn import metrics\n",
    "\n",
    "# y_pred_cnb\n",
    "# y_prob_pred_cnb\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        cnb, X_train.values, y_train.values, X_test.values, y_test.values, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=123)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_cnb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf64c978",
   "metadata": {},
   "source": [
    "## 1.2 CNB, DT, max_depth = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e7ca74bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make test & train split\n",
    "X = pima_m3.drop('Outcome', axis=1)\n",
    "y = pima_m3['Outcome']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=30, stratify = y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "71302373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class representation - original:  Counter({0: 500, 1: 268})\n",
      "Class representation - training data:  Counter({0: 375, 1: 201})\n",
      "Class representation - testing data:  Counter({0: 125, 1: 67})\n"
     ]
    }
   ],
   "source": [
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(pima_m3['Outcome'])) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1398701d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(576, 8) (192, 8)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0d26b1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTE\n",
    "#! pip install imblearn --user\n",
    "from imblearn import under_sampling, over_sampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state = 22)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "933a05f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAM\n",
    "# Count number of categories\n",
    "n_categories = pima_m3.drop('Outcome', axis=1).nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5268cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CategoricalNB\n",
      "=========================\n",
      "Misclassified samples: 46\n",
      "Accuracy: 0.76\n",
      "=========================\n",
      "Recall score :  0.7604166666666666\n",
      "Precision score :  0.7604166666666666\n",
      "F1 score :  0.7604166666666666\n",
      "=========================\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.67      0.79       125\n",
      "           1       0.60      0.93      0.73        67\n",
      "\n",
      "    accuracy                           0.76       192\n",
      "   macro avg       0.77      0.80      0.76       192\n",
      "weighted avg       0.82      0.76      0.77       192\n",
      "\n",
      "Computation time:\n",
      "0.012999296188354492\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "cnb = CategoricalNB(min_categories = n_categories)\n",
    "cnb.fit(X_train, y_train)\n",
    "\n",
    "y_pred_cnb = cnb.predict(X_test)\n",
    "y_prob_pred_cnb = cnb.predict_proba(X_test)\n",
    "\n",
    "# how did our model perform?\n",
    "count_misclassified = (y_test != y_pred_cnb).sum()\n",
    "print(\"CategoricalNB\")\n",
    "print(\"=\" * 25)\n",
    "print('Misclassified samples: {}'.format(count_misclassified))\n",
    "accuracy = accuracy_score(y_test, y_pred_cnb)\n",
    "print('Accuracy: {:.2f}'.format(accuracy))\n",
    "print(\"=\" * 25)\n",
    "print(\"Recall score : \", recall_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"Precision score : \",precision_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"F1 score : \",f1_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"=\" * 25)\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred_cnb))\n",
    "\n",
    "end = time.time()\n",
    "print(\"Computation time:\")\n",
    "print(end - start) # Total time execution for this sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5fd110cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.251\n",
      "Average bias: 0.250\n",
      "Average variance: 0.049\n",
      "Sklearn 0-1 loss: 0.240\n"
     ]
    }
   ],
   "source": [
    "# calculate classification bias and variance\n",
    "from sklearn.metrics import zero_one_loss\n",
    "#This library is used to decompose bias and variance in our models\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#We will load the Boston house dataset for our example\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn import metrics\n",
    "\n",
    "# y_pred_cnb\n",
    "# y_prob_pred_cnb\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        cnb, X_train.values, y_train.values, X_test.values, y_test.values, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=123)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_cnb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd86461",
   "metadata": {},
   "source": [
    "## 1.3 CNB, DT, max_depth = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1ec77945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make test & train split\n",
    "X = pima_m4.drop('Outcome', axis=1)\n",
    "y = pima_m4['Outcome']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=30, stratify = y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8a724a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class representation - original:  Counter({0: 500, 1: 268})\n",
      "Class representation - training data:  Counter({0: 375, 1: 201})\n",
      "Class representation - testing data:  Counter({0: 125, 1: 67})\n"
     ]
    }
   ],
   "source": [
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(pima_m4['Outcome'])) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0b86370e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(576, 8) (192, 8)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "14162040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTE\n",
    "#! pip install imblearn --user\n",
    "from imblearn import under_sampling, over_sampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state = 22)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6a924dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class representation - training data:  Counter({1: 375, 0: 375})\n"
     ]
    }
   ],
   "source": [
    "# Check representation of class after SMOTE \n",
    "print('Class representation - training data: ', Counter(y_train)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b887149d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAM\n",
    "# Count number of categories\n",
    "n_categories = pima_m4.drop('Outcome', axis=1).nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ee6f165d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CategoricalNB\n",
      "=========================\n",
      "Misclassified samples: 48\n",
      "Accuracy: 0.75\n",
      "=========================\n",
      "Recall score :  0.75\n",
      "Precision score :  0.75\n",
      "F1 score :  0.75\n",
      "=========================\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.68      0.78       125\n",
      "           1       0.60      0.88      0.71        67\n",
      "\n",
      "    accuracy                           0.75       192\n",
      "   macro avg       0.75      0.78      0.75       192\n",
      "weighted avg       0.80      0.75      0.76       192\n",
      "\n",
      "Computation time:\n",
      "0.012998342514038086\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "cnb = CategoricalNB(min_categories = n_categories)\n",
    "cnb.fit(X_train, y_train)\n",
    "\n",
    "y_pred_cnb = cnb.predict(X_test)\n",
    "y_prob_pred_cnb = cnb.predict_proba(X_test)\n",
    "\n",
    "# how did our model perform?\n",
    "count_misclassified = (y_test != y_pred_cnb).sum()\n",
    "print(\"CategoricalNB\")\n",
    "print(\"=\" * 25)\n",
    "print('Misclassified samples: {}'.format(count_misclassified))\n",
    "accuracy = accuracy_score(y_test, y_pred_cnb)\n",
    "print('Accuracy: {:.2f}'.format(accuracy))\n",
    "print(\"=\" * 25)\n",
    "print(\"Recall score : \", recall_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"Precision score : \",precision_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"F1 score : \",f1_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"=\" * 25)\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred_cnb))\n",
    "\n",
    "end = time.time()\n",
    "print(\"Computation time:\")\n",
    "print(end - start) # Total time execution for this sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f61dff92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.256\n",
      "Average bias: 0.250\n",
      "Average variance: 0.061\n",
      "Sklearn 0-1 loss: 0.250\n"
     ]
    }
   ],
   "source": [
    "# calculate classification bias and variance\n",
    "from sklearn.metrics import zero_one_loss\n",
    "#This library is used to decompose bias and variance in our models\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#We will load the Boston house dataset for our example\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn import metrics\n",
    "\n",
    "# y_pred_cnb\n",
    "# y_prob_pred_cnb\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        cnb, X_train.values, y_train.values, X_test.values, y_test.values, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=123)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_cnb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b03574",
   "metadata": {},
   "source": [
    "## 1.4 CNB, DT, max_depth = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6a5d3e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make test & train split\n",
    "X = pima_m5.drop('Outcome', axis=1)\n",
    "y = pima_m5['Outcome']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=30, stratify = y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "414d5d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class representation - original:  Counter({0: 500, 1: 268})\n",
      "Class representation - training data:  Counter({0: 375, 1: 201})\n",
      "Class representation - testing data:  Counter({0: 125, 1: 67})\n"
     ]
    }
   ],
   "source": [
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(pima_m5['Outcome'])) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9f04daa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(576, 8) (192, 8)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ae87cb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTE\n",
    "#! pip install imblearn --user\n",
    "from imblearn import under_sampling, over_sampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state = 22)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bc1b10d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class representation - training data:  Counter({1: 375, 0: 375})\n"
     ]
    }
   ],
   "source": [
    "# Check representation of class after SMOTE \n",
    "print('Class representation - training data: ', Counter(y_train)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "07cf06b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAM\n",
    "# Count number of categories\n",
    "n_categories = pima_m5.drop('Outcome', axis=1).nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6a4ab13c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CategoricalNB\n",
      "=========================\n",
      "Misclassified samples: 50\n",
      "Accuracy: 0.74\n",
      "=========================\n",
      "Recall score :  0.7395833333333334\n",
      "Precision score :  0.7395833333333334\n",
      "F1 score :  0.7395833333333334\n",
      "=========================\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.69      0.77       125\n",
      "           1       0.59      0.84      0.69        67\n",
      "\n",
      "    accuracy                           0.74       192\n",
      "   macro avg       0.74      0.76      0.73       192\n",
      "weighted avg       0.78      0.74      0.75       192\n",
      "\n",
      "Computation time:\n",
      "0.01299905776977539\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "cnb = CategoricalNB(min_categories = n_categories)\n",
    "cnb.fit(X_train, y_train)\n",
    "\n",
    "y_pred_cnb = cnb.predict(X_test)\n",
    "y_prob_pred_cnb = cnb.predict_proba(X_test)\n",
    "\n",
    "# how did our model perform?\n",
    "count_misclassified = (y_test != y_pred_cnb).sum()\n",
    "print(\"CategoricalNB\")\n",
    "print(\"=\" * 25)\n",
    "print('Misclassified samples: {}'.format(count_misclassified))\n",
    "accuracy = accuracy_score(y_test, y_pred_cnb)\n",
    "print('Accuracy: {:.2f}'.format(accuracy))\n",
    "print(\"=\" * 25)\n",
    "print(\"Recall score : \", recall_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"Precision score : \",precision_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"F1 score : \",f1_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"=\" * 25)\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred_cnb))\n",
    "\n",
    "end = time.time()\n",
    "print(\"Computation time:\")\n",
    "print(end - start) # Total time execution for this sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a386ec1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.251\n",
      "Average bias: 0.255\n",
      "Average variance: 0.069\n",
      "Sklearn 0-1 loss: 0.260\n"
     ]
    }
   ],
   "source": [
    "# calculate classification bias and variance\n",
    "from sklearn.metrics import zero_one_loss\n",
    "#This library is used to decompose bias and variance in our models\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#We will load the Boston house dataset for our example\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn import metrics\n",
    "\n",
    "# y_pred_cnb\n",
    "# y_prob_pred_cnb\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        cnb, X_train.values, y_train.values, X_test.values, y_test.values, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=123)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_cnb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36de93a1",
   "metadata": {},
   "source": [
    "# 2. Decision Tree ID3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5da502c",
   "metadata": {},
   "source": [
    "## 2.1 ID3, DT, max_depth = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4f1ec5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class representation - original:  Counter({0: 500, 1: 268})\n",
      "Class representation - training data:  Counter({0: 375, 1: 201})\n",
      "Class representation - testing data:  Counter({0: 125, 1: 67})\n",
      "(576, 8) (192, 8)\n",
      "Class representation - training data:  Counter({1: 375, 0: 375})\n"
     ]
    }
   ],
   "source": [
    "# Prepare data and apply SMOTE\n",
    "# make test & train split\n",
    "X = pima_m2.drop('Outcome', axis=1)\n",
    "y = pima_m2['Outcome']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=30, stratify = y)\n",
    "\n",
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(pima_m2['Outcome'])) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test)) \n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "\n",
    "# SMOTE\n",
    "#! pip install imblearn --user\n",
    "from imblearn import under_sampling, over_sampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state = 22)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Check representation of class after SMOTE \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "\n",
    "# SAM\n",
    "# Count number of categories\n",
    "n_categories = pima_m2.drop('Outcome', axis=1).nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2516a4cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.70\n",
      "=========================\n",
      "Recall score :  0.703125\n",
      "Precision score :  0.703125\n",
      "F1 score :  0.703125\n",
      "=========================\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.70      0.75       125\n",
      "           1       0.56      0.72      0.63        67\n",
      "\n",
      "    accuracy                           0.70       192\n",
      "   macro avg       0.69      0.71      0.69       192\n",
      "weighted avg       0.73      0.70      0.71       192\n",
      "\n",
      "Computation time:\n",
      "0.05203819274902344\n"
     ]
    }
   ],
   "source": [
    "#time recording\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "#build estimator\n",
    "estimator = Id3Estimator()\n",
    "estimator = estimator.fit(X_train, y_train, check_input=True)\n",
    "tree = export_graphviz(estimator.tree_, 'tree.dot', y)\n",
    "#make predictions\n",
    "y_pred_id3 = estimator.predict(X_test)\n",
    "#_prob_pred_id3 = estimator.predict_proba(X_test)\n",
    "#report performance\n",
    "accuracy = accuracy_score(y_test, y_pred_id3)\n",
    "print('Accuracy: {:.2f}'.format(accuracy))\n",
    "print(\"=\" * 25)\n",
    "print(\"Recall score : \", recall_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"Precision score : \",precision_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"F1 score : \",f1_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"=\" * 25)\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred_id3))\n",
    "#stop time recoridng\n",
    "end = time.time()\n",
    "print(\"Computation time:\")\n",
    "print(end - start) # Total time execution for this sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2421a98e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.323\n",
      "Average bias: 0.281\n",
      "Average variance: 0.181\n",
      "Sklearn 0-1 loss: 0.297\n"
     ]
    }
   ],
   "source": [
    "# calculate classification bias and variance\n",
    "from sklearn.metrics import zero_one_loss\n",
    "#This library is used to decompose bias and variance in our models\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#We will load the Boston house dataset for our example\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn import metrics\n",
    "\n",
    "# y_pred_cnb\n",
    "# y_prob_pred_cnb\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        estimator, X_train.values, y_train.values, X_test.values, y_test.values, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=123)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_id3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c21b52",
   "metadata": {},
   "source": [
    "## 2.2 ID3, DT, max_depth = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc8fa94e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class representation - original:  Counter({0: 500, 1: 268})\n",
      "Class representation - training data:  Counter({0: 375, 1: 201})\n",
      "Class representation - testing data:  Counter({0: 125, 1: 67})\n",
      "(576, 8) (192, 8)\n",
      "Class representation - training data:  Counter({1: 375, 0: 375})\n"
     ]
    }
   ],
   "source": [
    "# Prepare data and apply SMOTE\n",
    "# make test & train split\n",
    "X = pima_m3.drop('Outcome', axis=1)\n",
    "y = pima_m3['Outcome']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=30, stratify = y)\n",
    "\n",
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(pima_m3['Outcome'])) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test)) \n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "\n",
    "# SMOTE\n",
    "#! pip install imblearn --user\n",
    "from imblearn import under_sampling, over_sampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state = 22)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Check representation of class after SMOTE \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "\n",
    "# SAM\n",
    "# Count number of categories\n",
    "n_categories = pima_m3.drop('Outcome', axis=1).nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7cae5344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.78\n",
      "=========================\n",
      "Recall score :  0.78125\n",
      "Precision score :  0.78125\n",
      "F1 score :  0.78125\n",
      "=========================\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.70      0.81       125\n",
      "           1       0.62      0.94      0.75        67\n",
      "\n",
      "    accuracy                           0.78       192\n",
      "   macro avg       0.79      0.82      0.78       192\n",
      "weighted avg       0.84      0.78      0.79       192\n",
      "\n",
      "Computation time:\n",
      "0.05827927589416504\n"
     ]
    }
   ],
   "source": [
    "#time recording\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "#build estimator\n",
    "estimator = Id3Estimator()\n",
    "estimator = estimator.fit(X_train, y_train, check_input=True)\n",
    "tree = export_graphviz(estimator.tree_, 'tree.dot', y)\n",
    "#make predictions\n",
    "y_pred_id3 = estimator.predict(X_test)\n",
    "#_prob_pred_id3 = estimator.predict_proba(X_test)\n",
    "#report performance\n",
    "accuracy = accuracy_score(y_test, y_pred_id3)\n",
    "print('Accuracy: {:.2f}'.format(accuracy))\n",
    "print(\"=\" * 25)\n",
    "print(\"Recall score : \", recall_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"Precision score : \",precision_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"F1 score : \",f1_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"=\" * 25)\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred_id3))\n",
    "#stop time recoridng\n",
    "end = time.time()\n",
    "print(\"Computation time:\")\n",
    "print(end - start) # Total time execution for this sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e9ddbc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.289\n",
      "Average bias: 0.240\n",
      "Average variance: 0.175\n",
      "Sklearn 0-1 loss: 0.219\n"
     ]
    }
   ],
   "source": [
    "# calculate classification bias and variance\n",
    "from sklearn.metrics import zero_one_loss\n",
    "#This library is used to decompose bias and variance in our models\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#We will load the Boston house dataset for our example\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn import metrics\n",
    "\n",
    "# y_pred_cnb\n",
    "# y_prob_pred_cnb\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        estimator, X_train.values, y_train.values, X_test.values, y_test.values, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=123)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_id3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687f1ea3",
   "metadata": {},
   "source": [
    "## 2.3 ID3, DT, max_depth = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c109b584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class representation - original:  Counter({0: 500, 1: 268})\n",
      "Class representation - training data:  Counter({0: 375, 1: 201})\n",
      "Class representation - testing data:  Counter({0: 125, 1: 67})\n",
      "(576, 8) (192, 8)\n",
      "Class representation - training data:  Counter({1: 375, 0: 375})\n"
     ]
    }
   ],
   "source": [
    "# Prepare data and apply SMOTE\n",
    "# make test & train split\n",
    "X = pima_m4.drop('Outcome', axis=1)\n",
    "y = pima_m4['Outcome']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=30, stratify = y)\n",
    "\n",
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(pima_m4['Outcome'])) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test)) \n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "\n",
    "# SMOTE\n",
    "#! pip install imblearn --user\n",
    "from imblearn import under_sampling, over_sampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state = 22)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Check representation of class after SMOTE \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "\n",
    "# SAM\n",
    "# Count number of categories\n",
    "n_categories = pima_m4.drop('Outcome', axis=1).nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9c733d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.76\n",
      "=========================\n",
      "Recall score :  0.7604166666666666\n",
      "Precision score :  0.7604166666666666\n",
      "F1 score :  0.7604166666666666\n",
      "=========================\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.71      0.79       125\n",
      "           1       0.61      0.85      0.71        67\n",
      "\n",
      "    accuracy                           0.76       192\n",
      "   macro avg       0.76      0.78      0.75       192\n",
      "weighted avg       0.80      0.76      0.77       192\n",
      "\n",
      "Computation time:\n",
      "0.06502556800842285\n"
     ]
    }
   ],
   "source": [
    "#time recording\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "#build estimator\n",
    "estimator = Id3Estimator()\n",
    "estimator = estimator.fit(X_train, y_train, check_input=True)\n",
    "tree = export_graphviz(estimator.tree_, 'tree.dot', y)\n",
    "#make predictions\n",
    "y_pred_id3 = estimator.predict(X_test)\n",
    "#_prob_pred_id3 = estimator.predict_proba(X_test)\n",
    "#report performance\n",
    "accuracy = accuracy_score(y_test, y_pred_id3)\n",
    "print('Accuracy: {:.2f}'.format(accuracy))\n",
    "print(\"=\" * 25)\n",
    "print(\"Recall score : \", recall_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"Precision score : \",precision_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"F1 score : \",f1_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"=\" * 25)\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred_id3))\n",
    "#stop time recoridng\n",
    "end = time.time()\n",
    "print(\"Computation time:\")\n",
    "print(end - start) # Total time execution for this sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d456eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.286\n",
      "Average bias: 0.198\n",
      "Average variance: 0.192\n",
      "Sklearn 0-1 loss: 0.240\n"
     ]
    }
   ],
   "source": [
    "# calculate classification bias and variance\n",
    "from sklearn.metrics import zero_one_loss\n",
    "#This library is used to decompose bias and variance in our models\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#We will load the Boston house dataset for our example\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn import metrics\n",
    "\n",
    "# y_pred_cnb\n",
    "# y_prob_pred_cnb\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        estimator, X_train.values, y_train.values, X_test.values, y_test.values, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=123)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_id3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251b1503",
   "metadata": {},
   "source": [
    "## 2.4 ID3, DT, max_depth = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "99d1f556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class representation - original:  Counter({0: 500, 1: 268})\n",
      "Class representation - training data:  Counter({0: 375, 1: 201})\n",
      "Class representation - testing data:  Counter({0: 125, 1: 67})\n",
      "(576, 8) (192, 8)\n",
      "Class representation - training data:  Counter({1: 375, 0: 375})\n"
     ]
    }
   ],
   "source": [
    "# Prepare data and apply SMOTE\n",
    "# make test & train split\n",
    "X = pima_m5.drop('Outcome', axis=1)\n",
    "y = pima_m5['Outcome']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=30, stratify = y)\n",
    "\n",
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(pima_m5['Outcome'])) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test)) \n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "\n",
    "# SMOTE\n",
    "#! pip install imblearn --user\n",
    "from imblearn import under_sampling, over_sampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state = 22)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Check representation of class after SMOTE \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "\n",
    "# SAM\n",
    "# Count number of categories\n",
    "n_categories = pima_m5.drop('Outcome', axis=1).nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d614577e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.71\n",
      "=========================\n",
      "Recall score :  0.7135416666666666\n",
      "Precision score :  0.7135416666666666\n",
      "F1 score :  0.7135416666666666\n",
      "=========================\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.74      0.77       125\n",
      "           1       0.58      0.66      0.62        67\n",
      "\n",
      "    accuracy                           0.71       192\n",
      "   macro avg       0.69      0.70      0.69       192\n",
      "weighted avg       0.72      0.71      0.72       192\n",
      "\n",
      "Computation time:\n",
      "0.09893083572387695\n"
     ]
    }
   ],
   "source": [
    "#time recording\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "#build estimator\n",
    "estimator = Id3Estimator()\n",
    "estimator = estimator.fit(X_train, y_train, check_input=True)\n",
    "tree = export_graphviz(estimator.tree_, 'tree.dot', y)\n",
    "#make predictions\n",
    "y_pred_id3 = estimator.predict(X_test)\n",
    "#_prob_pred_id3 = estimator.predict_proba(X_test)\n",
    "#report performance\n",
    "accuracy = accuracy_score(y_test, y_pred_id3)\n",
    "print('Accuracy: {:.2f}'.format(accuracy))\n",
    "print(\"=\" * 25)\n",
    "print(\"Recall score : \", recall_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"Precision score : \",precision_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"F1 score : \",f1_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"=\" * 25)\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred_id3))\n",
    "#stop time recoridng\n",
    "end = time.time()\n",
    "print(\"Computation time:\")\n",
    "print(end - start) # Total time execution for this sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "265cf5e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.261\n",
      "Average bias: 0.177\n",
      "Average variance: 0.187\n",
      "Sklearn 0-1 loss: 0.286\n"
     ]
    }
   ],
   "source": [
    "# calculate classification bias and variance\n",
    "from sklearn.metrics import zero_one_loss\n",
    "#This library is used to decompose bias and variance in our models\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#We will load the Boston house dataset for our example\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn import metrics\n",
    "\n",
    "# y_pred_cnb\n",
    "# y_prob_pred_cnb\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        estimator, X_train.values, y_train.values, X_test.values, y_test.values, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=123)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_id3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9d5f3d",
   "metadata": {},
   "source": [
    "# 3. KNN classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfc2760",
   "metadata": {},
   "source": [
    "## 3.1 KNN-VDM, DT, max_depth = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "58948588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class representation - original:  Counter({0: 500, 1: 268})\n",
      "Class representation - training data:  Counter({0: 375, 1: 201})\n",
      "Class representation - testing data:  Counter({0: 125, 1: 67})\n",
      "(576, 8) (192, 8)\n",
      "Class representation - training data:  Counter({1: 375, 0: 375})\n"
     ]
    }
   ],
   "source": [
    "# Prepare data and apply SMOTE\n",
    "# make test & train split\n",
    "X = pima_m2.drop('Outcome', axis=1)\n",
    "y = pima_m2['Outcome']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=30, stratify = y)\n",
    "\n",
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(pima_m2['Outcome'])) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test)) \n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "\n",
    "# SMOTE\n",
    "#! pip install imblearn --user\n",
    "from imblearn import under_sampling, over_sampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state = 22)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Check representation of class after SMOTE \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "\n",
    "# SAM\n",
    "# Count number of categories\n",
    "n_categories = pima_m2.drop('Outcome', axis=1).nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dfe593f7",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "3.0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [30]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m knn_vdm\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Testing\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m y_pred_knn \u001b[38;5;241m=\u001b[39m \u001b[43mknn_vdm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m knn_vdm\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(y_test, y_pred_knn))\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:226\u001b[0m, in \u001b[0;36mKNeighborsClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;124;03m\"\"\"Predict the class labels for the provided data.\u001b[39;00m\n\u001b[0;32m    211\u001b[0m \n\u001b[0;32m    212\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;124;03m    Class labels for each data sample.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muniform\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;66;03m# In that case, we do not need the distances to perform\u001b[39;00m\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;66;03m# the weighting so we do not compute them.\u001b[39;00m\n\u001b[1;32m--> 226\u001b[0m     neigh_ind \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkneighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    227\u001b[0m     neigh_dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py:796\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    793\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    794\u001b[0m         kwds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meffective_metric_params_\n\u001b[1;32m--> 796\u001b[0m     chunked_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpairwise_distances_chunked\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    798\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_X\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    800\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreduce_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreduce_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    801\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meffective_metric_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    802\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    803\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    804\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    805\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    807\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_method \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mball_tree\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkd_tree\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m issparse(X):\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1850\u001b[0m, in \u001b[0;36mpairwise_distances_chunked\u001b[1;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1849\u001b[0m     X_chunk \u001b[38;5;241m=\u001b[39m X[sl]\n\u001b[1;32m-> 1850\u001b[0m D_chunk \u001b[38;5;241m=\u001b[39m pairwise_distances(X_chunk, Y, metric\u001b[38;5;241m=\u001b[39mmetric, n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m   1851\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (X \u001b[38;5;129;01mis\u001b[39;00m Y \u001b[38;5;129;01mor\u001b[39;00m Y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m PAIRWISE_DISTANCE_FUNCTIONS\u001b[38;5;241m.\u001b[39mget(\n\u001b[0;32m   1852\u001b[0m     metric, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1853\u001b[0m ) \u001b[38;5;129;01mis\u001b[39;00m euclidean_distances:\n\u001b[0;32m   1854\u001b[0m     \u001b[38;5;66;03m# zeroing diagonal, taking care of aliases of \"euclidean\",\u001b[39;00m\n\u001b[0;32m   1855\u001b[0m     \u001b[38;5;66;03m# i.e. \"l2\"\u001b[39;00m\n\u001b[0;32m   1856\u001b[0m     D_chunk\u001b[38;5;241m.\u001b[39mflat[sl\u001b[38;5;241m.\u001b[39mstart :: _num_samples(X) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:2022\u001b[0m, in \u001b[0;36mpairwise_distances\u001b[1;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[0;32m   2019\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m distance\u001b[38;5;241m.\u001b[39msquareform(distance\u001b[38;5;241m.\u001b[39mpdist(X, metric\u001b[38;5;241m=\u001b[39mmetric, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds))\n\u001b[0;32m   2020\u001b[0m     func \u001b[38;5;241m=\u001b[39m partial(distance\u001b[38;5;241m.\u001b[39mcdist, metric\u001b[38;5;241m=\u001b[39mmetric, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m-> 2022\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _parallel_pairwise(X, Y, func, n_jobs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1563\u001b[0m, in \u001b[0;36m_parallel_pairwise\u001b[1;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[0;32m   1560\u001b[0m X, Y, dtype \u001b[38;5;241m=\u001b[39m _return_float_dtype(X, Y)\n\u001b[0;32m   1562\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m effective_n_jobs(n_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m-> 1563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(X, Y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m   1565\u001b[0m \u001b[38;5;66;03m# enforce a threading backend to prevent data communication overhead\u001b[39;00m\n\u001b[0;32m   1566\u001b[0m fd \u001b[38;5;241m=\u001b[39m delayed(_dist_wrapper)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1607\u001b[0m, in \u001b[0;36m_pairwise_callable\u001b[1;34m(X, Y, metric, force_all_finite, **kwds)\u001b[0m\n\u001b[0;32m   1605\u001b[0m     iterator \u001b[38;5;241m=\u001b[39m itertools\u001b[38;5;241m.\u001b[39mproduct(\u001b[38;5;28mrange\u001b[39m(X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]), \u001b[38;5;28mrange\u001b[39m(Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]))\n\u001b[0;32m   1606\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, j \u001b[38;5;129;01min\u001b[39;00m iterator:\n\u001b[1;32m-> 1607\u001b[0m         out[i, j] \u001b[38;5;241m=\u001b[39m metric(X[i], Y[j], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m   1609\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\vdm3\\vdm.py:83\u001b[0m, in \u001b[0;36mValueDifferenceMetric.get_distance\u001b[1;34m(self, ins_1, ins_2, norm)\u001b[0m\n\u001b[0;32m     80\u001b[0m     ins_1_cat \u001b[38;5;241m=\u001b[39m ins_1\n\u001b[0;32m     81\u001b[0m     ins_2_cat \u001b[38;5;241m=\u001b[39m ins_2\n\u001b[1;32m---> 83\u001b[0m cat_dist \u001b[38;5;241m=\u001b[39m \u001b[43mget_delta_nd\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcond_proba\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mins_1_cat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mins_2_cat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontinuous \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     86\u001b[0m     cont_dist \u001b[38;5;241m=\u001b[39m get_cont_dist(ins_1_cont, ins_2_cont, norm)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\vdm3\\components.py:77\u001b[0m, in \u001b[0;36mget_delta_nd\u001b[1;34m(cond_proba, ins_1, ins_2, norm)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_delta_nd\u001b[39m(cond_proba, ins_1, ins_2, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m):\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;124;03m\"\"\" get deltas for vdm for multidimensional data\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    Parameters: cond_proba (dict) - a dictionary of conditional probability, extract from get_conditional_proba_nd()\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;124;03m    Returns: deltas (array) - the delta values between ins_1 and ins_2\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 77\u001b[0m     deltas \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([get_delta(cond_proba[col], ins_1[col], ins_2[col], norm) \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m cond_proba])\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m deltas\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\vdm3\\components.py:77\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_delta_nd\u001b[39m(cond_proba, ins_1, ins_2, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m):\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;124;03m\"\"\" get deltas for vdm for multidimensional data\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    Parameters: cond_proba (dict) - a dictionary of conditional probability, extract from get_conditional_proba_nd()\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;124;03m    Returns: deltas (array) - the delta values between ins_1 and ins_2\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 77\u001b[0m     deltas \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[43mget_delta\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcond_proba\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mins_1\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mins_2\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m cond_proba])\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m deltas\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\vdm3\\components.py:51\u001b[0m, in \u001b[0;36mget_delta\u001b[1;34m(cond_proba, val_1, val_2, norm)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_delta\u001b[39m(cond_proba, val_1, val_2, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m):\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;124;03m\"\"\" get delta for vdm\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \n\u001b[0;32m     44\u001b[0m \u001b[38;5;124;03m    Parameters: cond_proba (dict) - a dictionary of conditional probability, extract from get_conditional_proba()\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;124;03m    Returns: delta (float) - the delta value for this instance\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m     proba \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;28mabs\u001b[39m(cond_proba[val_1][uni_x] \u001b[38;5;241m-\u001b[39m cond_proba[val_2][uni_x]) \u001b[38;5;28;01mfor\u001b[39;00m uni_x \u001b[38;5;129;01min\u001b[39;00m \u001b[43mcond_proba\u001b[49m\u001b[43m[\u001b[49m\u001b[43mval_1\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mindex])\n\u001b[0;32m     52\u001b[0m     delta \u001b[38;5;241m=\u001b[39m (proba\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnorm)\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m delta\n",
      "\u001b[1;31mKeyError\u001b[0m: 3.0"
     ]
    }
   ],
   "source": [
    "# Knn-VDM complete code\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "# specific the continuous columns index if any\n",
    "vdm = ValueDifferenceMetric(X_train, y_train, continuous = None)\n",
    "vdm.fit()\n",
    "# Knn model, n_neigbour = 3, metrics = vdm\n",
    "knn_vdm = KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')\n",
    "# Fit model\n",
    "knn_vdm.fit(X_train, y_train)\n",
    "# Testing\n",
    "y_pred_knn = knn_vdm.predict(X_test)\n",
    "knn_vdm.classes_\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model Knn-VDM: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a91d6c12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 3, 1, ..., 0, 2, 3],\n",
       "       [2, 3, 1, ..., 0, 2, 3],\n",
       "       [1, 0, 1, ..., 2, 1, 2],\n",
       "       ...,\n",
       "       [2, 1, 2, ..., 2, 1, 3],\n",
       "       [2, 3, 3, ..., 2, 3, 3],\n",
       "       [0, 1, 3, ..., 2, 2, 0]], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8e68e4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # !!!! WARING: TIME CONSUMING\n",
    "\n",
    "# # Bias and variance decomposition\n",
    "# # Convert all dataframe to array first\n",
    "# X_train = X_train.values\n",
    "# X_test = X_test.values\n",
    "# y_train = y_train.values\n",
    "# y_test = y_test.values\n",
    "\n",
    "# avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "#         knn_vdm, X_train, y_train, X_test, y_test, \n",
    "#         loss='0-1_loss',\n",
    "#         random_seed=123)\n",
    "\n",
    "# print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "# print('Average bias: %.3f' % avg_bias)\n",
    "# print('Average variance: %.3f' % avg_var)\n",
    "# print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55006f71",
   "metadata": {},
   "source": [
    "## 3.2 KNN-VDM, DT, max_depth = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "29122302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class representation - original:  Counter({0: 500, 1: 268})\n",
      "Class representation - training data:  Counter({0: 375, 1: 201})\n",
      "Class representation - testing data:  Counter({0: 125, 1: 67})\n",
      "(576, 8) (192, 8)\n",
      "Class representation - training data:  Counter({1: 375, 0: 375})\n"
     ]
    }
   ],
   "source": [
    "# Prepare data and apply SMOTE\n",
    "# make test & train split\n",
    "X = pima_m3.drop('Outcome', axis=1)\n",
    "y = pima_m3['Outcome']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=30, stratify = y)\n",
    "\n",
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(pima_m3['Outcome'])) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test)) \n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "\n",
    "# SMOTE\n",
    "#! pip install imblearn --user\n",
    "from imblearn import under_sampling, over_sampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state = 22)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Check representation of class after SMOTE \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "\n",
    "# SAM\n",
    "# Count number of categories\n",
    "n_categories = pima_m3.drop('Outcome', axis=1).nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cd4019bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "6.0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [34]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m knn_vdm\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Testing\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m y_pred_knn \u001b[38;5;241m=\u001b[39m \u001b[43mknn_vdm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m knn_vdm\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(y_test, y_pred_knn))\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:226\u001b[0m, in \u001b[0;36mKNeighborsClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;124;03m\"\"\"Predict the class labels for the provided data.\u001b[39;00m\n\u001b[0;32m    211\u001b[0m \n\u001b[0;32m    212\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;124;03m    Class labels for each data sample.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muniform\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;66;03m# In that case, we do not need the distances to perform\u001b[39;00m\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;66;03m# the weighting so we do not compute them.\u001b[39;00m\n\u001b[1;32m--> 226\u001b[0m     neigh_ind \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkneighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    227\u001b[0m     neigh_dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py:796\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    793\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    794\u001b[0m         kwds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meffective_metric_params_\n\u001b[1;32m--> 796\u001b[0m     chunked_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpairwise_distances_chunked\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    798\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_X\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    800\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreduce_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreduce_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    801\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meffective_metric_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    802\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    803\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    804\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    805\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    807\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_method \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mball_tree\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkd_tree\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m issparse(X):\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1850\u001b[0m, in \u001b[0;36mpairwise_distances_chunked\u001b[1;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1849\u001b[0m     X_chunk \u001b[38;5;241m=\u001b[39m X[sl]\n\u001b[1;32m-> 1850\u001b[0m D_chunk \u001b[38;5;241m=\u001b[39m pairwise_distances(X_chunk, Y, metric\u001b[38;5;241m=\u001b[39mmetric, n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m   1851\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (X \u001b[38;5;129;01mis\u001b[39;00m Y \u001b[38;5;129;01mor\u001b[39;00m Y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m PAIRWISE_DISTANCE_FUNCTIONS\u001b[38;5;241m.\u001b[39mget(\n\u001b[0;32m   1852\u001b[0m     metric, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1853\u001b[0m ) \u001b[38;5;129;01mis\u001b[39;00m euclidean_distances:\n\u001b[0;32m   1854\u001b[0m     \u001b[38;5;66;03m# zeroing diagonal, taking care of aliases of \"euclidean\",\u001b[39;00m\n\u001b[0;32m   1855\u001b[0m     \u001b[38;5;66;03m# i.e. \"l2\"\u001b[39;00m\n\u001b[0;32m   1856\u001b[0m     D_chunk\u001b[38;5;241m.\u001b[39mflat[sl\u001b[38;5;241m.\u001b[39mstart :: _num_samples(X) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:2022\u001b[0m, in \u001b[0;36mpairwise_distances\u001b[1;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[0;32m   2019\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m distance\u001b[38;5;241m.\u001b[39msquareform(distance\u001b[38;5;241m.\u001b[39mpdist(X, metric\u001b[38;5;241m=\u001b[39mmetric, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds))\n\u001b[0;32m   2020\u001b[0m     func \u001b[38;5;241m=\u001b[39m partial(distance\u001b[38;5;241m.\u001b[39mcdist, metric\u001b[38;5;241m=\u001b[39mmetric, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m-> 2022\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _parallel_pairwise(X, Y, func, n_jobs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1563\u001b[0m, in \u001b[0;36m_parallel_pairwise\u001b[1;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[0;32m   1560\u001b[0m X, Y, dtype \u001b[38;5;241m=\u001b[39m _return_float_dtype(X, Y)\n\u001b[0;32m   1562\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m effective_n_jobs(n_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m-> 1563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(X, Y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m   1565\u001b[0m \u001b[38;5;66;03m# enforce a threading backend to prevent data communication overhead\u001b[39;00m\n\u001b[0;32m   1566\u001b[0m fd \u001b[38;5;241m=\u001b[39m delayed(_dist_wrapper)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1607\u001b[0m, in \u001b[0;36m_pairwise_callable\u001b[1;34m(X, Y, metric, force_all_finite, **kwds)\u001b[0m\n\u001b[0;32m   1605\u001b[0m     iterator \u001b[38;5;241m=\u001b[39m itertools\u001b[38;5;241m.\u001b[39mproduct(\u001b[38;5;28mrange\u001b[39m(X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]), \u001b[38;5;28mrange\u001b[39m(Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]))\n\u001b[0;32m   1606\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, j \u001b[38;5;129;01min\u001b[39;00m iterator:\n\u001b[1;32m-> 1607\u001b[0m         out[i, j] \u001b[38;5;241m=\u001b[39m metric(X[i], Y[j], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m   1609\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\vdm3\\vdm.py:83\u001b[0m, in \u001b[0;36mValueDifferenceMetric.get_distance\u001b[1;34m(self, ins_1, ins_2, norm)\u001b[0m\n\u001b[0;32m     80\u001b[0m     ins_1_cat \u001b[38;5;241m=\u001b[39m ins_1\n\u001b[0;32m     81\u001b[0m     ins_2_cat \u001b[38;5;241m=\u001b[39m ins_2\n\u001b[1;32m---> 83\u001b[0m cat_dist \u001b[38;5;241m=\u001b[39m \u001b[43mget_delta_nd\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcond_proba\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mins_1_cat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mins_2_cat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontinuous \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     86\u001b[0m     cont_dist \u001b[38;5;241m=\u001b[39m get_cont_dist(ins_1_cont, ins_2_cont, norm)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\vdm3\\components.py:77\u001b[0m, in \u001b[0;36mget_delta_nd\u001b[1;34m(cond_proba, ins_1, ins_2, norm)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_delta_nd\u001b[39m(cond_proba, ins_1, ins_2, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m):\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;124;03m\"\"\" get deltas for vdm for multidimensional data\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    Parameters: cond_proba (dict) - a dictionary of conditional probability, extract from get_conditional_proba_nd()\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;124;03m    Returns: deltas (array) - the delta values between ins_1 and ins_2\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 77\u001b[0m     deltas \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([get_delta(cond_proba[col], ins_1[col], ins_2[col], norm) \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m cond_proba])\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m deltas\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\vdm3\\components.py:77\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_delta_nd\u001b[39m(cond_proba, ins_1, ins_2, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m):\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;124;03m\"\"\" get deltas for vdm for multidimensional data\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    Parameters: cond_proba (dict) - a dictionary of conditional probability, extract from get_conditional_proba_nd()\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;124;03m    Returns: deltas (array) - the delta values between ins_1 and ins_2\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 77\u001b[0m     deltas \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[43mget_delta\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcond_proba\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mins_1\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mins_2\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m cond_proba])\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m deltas\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\vdm3\\components.py:51\u001b[0m, in \u001b[0;36mget_delta\u001b[1;34m(cond_proba, val_1, val_2, norm)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_delta\u001b[39m(cond_proba, val_1, val_2, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m):\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;124;03m\"\"\" get delta for vdm\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \n\u001b[0;32m     44\u001b[0m \u001b[38;5;124;03m    Parameters: cond_proba (dict) - a dictionary of conditional probability, extract from get_conditional_proba()\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;124;03m    Returns: delta (float) - the delta value for this instance\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m     proba \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;28mabs\u001b[39m(cond_proba[val_1][uni_x] \u001b[38;5;241m-\u001b[39m cond_proba[val_2][uni_x]) \u001b[38;5;28;01mfor\u001b[39;00m uni_x \u001b[38;5;129;01min\u001b[39;00m \u001b[43mcond_proba\u001b[49m\u001b[43m[\u001b[49m\u001b[43mval_1\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mindex])\n\u001b[0;32m     52\u001b[0m     delta \u001b[38;5;241m=\u001b[39m (proba\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnorm)\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m delta\n",
      "\u001b[1;31mKeyError\u001b[0m: 6.0"
     ]
    }
   ],
   "source": [
    "# Knn-VDM complete code\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "# specific the continuous columns index if any\n",
    "vdm = ValueDifferenceMetric(X_train, y_train, continuous = None)\n",
    "vdm.fit()\n",
    "# Knn model, n_neigbour = 3, metrics = vdm\n",
    "knn_vdm = KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')\n",
    "# Fit model\n",
    "knn_vdm.fit(X_train, y_train)\n",
    "# Testing\n",
    "y_pred_knn = knn_vdm.predict(X_test)\n",
    "knn_vdm.classes_\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model Knn-VDM: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ebea6f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # !!!! WARING: TIME CONSUMING\n",
    "\n",
    "# # Bias and variance decomposition\n",
    "# # Convert all dataframe to array first\n",
    "# X_train = X_train.values\n",
    "# X_test = X_test.values\n",
    "# y_train = y_train.values\n",
    "# y_test = y_test.values\n",
    "\n",
    "# avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "#         knn_vdm, X_train, y_train, X_test, y_test, \n",
    "#         loss='0-1_loss',\n",
    "#         random_seed=123)\n",
    "\n",
    "# print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "# print('Average bias: %.3f' % avg_bias)\n",
    "# print('Average variance: %.3f' % avg_var)\n",
    "# print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a527ed9",
   "metadata": {},
   "source": [
    "## 3.3 KNN-VDM, DT, max_depth = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b662a3c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class representation - original:  Counter({0: 500, 1: 268})\n",
      "Class representation - training data:  Counter({0: 375, 1: 201})\n",
      "Class representation - testing data:  Counter({0: 125, 1: 67})\n",
      "(576, 8) (192, 8)\n",
      "Class representation - training data:  Counter({1: 375, 0: 375})\n"
     ]
    }
   ],
   "source": [
    "# Prepare data and apply SMOTE\n",
    "# make test & train split\n",
    "X = pima_m4.drop('Outcome', axis=1)\n",
    "y = pima_m4['Outcome']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=30, stratify = y)\n",
    "\n",
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(pima_m4['Outcome'])) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test)) \n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "\n",
    "# SMOTE\n",
    "#! pip install imblearn --user\n",
    "from imblearn import under_sampling, over_sampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state = 22)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Check representation of class after SMOTE \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "\n",
    "# SAM\n",
    "# Count number of categories\n",
    "n_categories = pima_m4.drop('Outcome', axis=1).nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "351221a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "9.0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [42]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m knn_vdm\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Testing\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m y_pred_knn \u001b[38;5;241m=\u001b[39m \u001b[43mknn_vdm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m knn_vdm\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(y_test, y_pred_knn))\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:226\u001b[0m, in \u001b[0;36mKNeighborsClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;124;03m\"\"\"Predict the class labels for the provided data.\u001b[39;00m\n\u001b[0;32m    211\u001b[0m \n\u001b[0;32m    212\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;124;03m    Class labels for each data sample.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muniform\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;66;03m# In that case, we do not need the distances to perform\u001b[39;00m\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;66;03m# the weighting so we do not compute them.\u001b[39;00m\n\u001b[1;32m--> 226\u001b[0m     neigh_ind \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkneighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    227\u001b[0m     neigh_dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py:796\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    793\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    794\u001b[0m         kwds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meffective_metric_params_\n\u001b[1;32m--> 796\u001b[0m     chunked_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpairwise_distances_chunked\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    798\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_X\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    800\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreduce_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreduce_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    801\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meffective_metric_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    802\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    803\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    804\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    805\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    807\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_method \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mball_tree\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkd_tree\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m issparse(X):\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1850\u001b[0m, in \u001b[0;36mpairwise_distances_chunked\u001b[1;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1849\u001b[0m     X_chunk \u001b[38;5;241m=\u001b[39m X[sl]\n\u001b[1;32m-> 1850\u001b[0m D_chunk \u001b[38;5;241m=\u001b[39m pairwise_distances(X_chunk, Y, metric\u001b[38;5;241m=\u001b[39mmetric, n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m   1851\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (X \u001b[38;5;129;01mis\u001b[39;00m Y \u001b[38;5;129;01mor\u001b[39;00m Y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m PAIRWISE_DISTANCE_FUNCTIONS\u001b[38;5;241m.\u001b[39mget(\n\u001b[0;32m   1852\u001b[0m     metric, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1853\u001b[0m ) \u001b[38;5;129;01mis\u001b[39;00m euclidean_distances:\n\u001b[0;32m   1854\u001b[0m     \u001b[38;5;66;03m# zeroing diagonal, taking care of aliases of \"euclidean\",\u001b[39;00m\n\u001b[0;32m   1855\u001b[0m     \u001b[38;5;66;03m# i.e. \"l2\"\u001b[39;00m\n\u001b[0;32m   1856\u001b[0m     D_chunk\u001b[38;5;241m.\u001b[39mflat[sl\u001b[38;5;241m.\u001b[39mstart :: _num_samples(X) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:2022\u001b[0m, in \u001b[0;36mpairwise_distances\u001b[1;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[0;32m   2019\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m distance\u001b[38;5;241m.\u001b[39msquareform(distance\u001b[38;5;241m.\u001b[39mpdist(X, metric\u001b[38;5;241m=\u001b[39mmetric, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds))\n\u001b[0;32m   2020\u001b[0m     func \u001b[38;5;241m=\u001b[39m partial(distance\u001b[38;5;241m.\u001b[39mcdist, metric\u001b[38;5;241m=\u001b[39mmetric, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m-> 2022\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _parallel_pairwise(X, Y, func, n_jobs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1563\u001b[0m, in \u001b[0;36m_parallel_pairwise\u001b[1;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[0;32m   1560\u001b[0m X, Y, dtype \u001b[38;5;241m=\u001b[39m _return_float_dtype(X, Y)\n\u001b[0;32m   1562\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m effective_n_jobs(n_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m-> 1563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(X, Y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m   1565\u001b[0m \u001b[38;5;66;03m# enforce a threading backend to prevent data communication overhead\u001b[39;00m\n\u001b[0;32m   1566\u001b[0m fd \u001b[38;5;241m=\u001b[39m delayed(_dist_wrapper)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1607\u001b[0m, in \u001b[0;36m_pairwise_callable\u001b[1;34m(X, Y, metric, force_all_finite, **kwds)\u001b[0m\n\u001b[0;32m   1605\u001b[0m     iterator \u001b[38;5;241m=\u001b[39m itertools\u001b[38;5;241m.\u001b[39mproduct(\u001b[38;5;28mrange\u001b[39m(X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]), \u001b[38;5;28mrange\u001b[39m(Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]))\n\u001b[0;32m   1606\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, j \u001b[38;5;129;01min\u001b[39;00m iterator:\n\u001b[1;32m-> 1607\u001b[0m         out[i, j] \u001b[38;5;241m=\u001b[39m metric(X[i], Y[j], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m   1609\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\vdm3\\vdm.py:83\u001b[0m, in \u001b[0;36mValueDifferenceMetric.get_distance\u001b[1;34m(self, ins_1, ins_2, norm)\u001b[0m\n\u001b[0;32m     80\u001b[0m     ins_1_cat \u001b[38;5;241m=\u001b[39m ins_1\n\u001b[0;32m     81\u001b[0m     ins_2_cat \u001b[38;5;241m=\u001b[39m ins_2\n\u001b[1;32m---> 83\u001b[0m cat_dist \u001b[38;5;241m=\u001b[39m \u001b[43mget_delta_nd\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcond_proba\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mins_1_cat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mins_2_cat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontinuous \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     86\u001b[0m     cont_dist \u001b[38;5;241m=\u001b[39m get_cont_dist(ins_1_cont, ins_2_cont, norm)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\vdm3\\components.py:77\u001b[0m, in \u001b[0;36mget_delta_nd\u001b[1;34m(cond_proba, ins_1, ins_2, norm)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_delta_nd\u001b[39m(cond_proba, ins_1, ins_2, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m):\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;124;03m\"\"\" get deltas for vdm for multidimensional data\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    Parameters: cond_proba (dict) - a dictionary of conditional probability, extract from get_conditional_proba_nd()\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;124;03m    Returns: deltas (array) - the delta values between ins_1 and ins_2\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 77\u001b[0m     deltas \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([get_delta(cond_proba[col], ins_1[col], ins_2[col], norm) \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m cond_proba])\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m deltas\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\vdm3\\components.py:77\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_delta_nd\u001b[39m(cond_proba, ins_1, ins_2, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m):\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;124;03m\"\"\" get deltas for vdm for multidimensional data\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    Parameters: cond_proba (dict) - a dictionary of conditional probability, extract from get_conditional_proba_nd()\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;124;03m    Returns: deltas (array) - the delta values between ins_1 and ins_2\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 77\u001b[0m     deltas \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[43mget_delta\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcond_proba\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mins_1\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mins_2\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m cond_proba])\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m deltas\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\vdm3\\components.py:51\u001b[0m, in \u001b[0;36mget_delta\u001b[1;34m(cond_proba, val_1, val_2, norm)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_delta\u001b[39m(cond_proba, val_1, val_2, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m):\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;124;03m\"\"\" get delta for vdm\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \n\u001b[0;32m     44\u001b[0m \u001b[38;5;124;03m    Parameters: cond_proba (dict) - a dictionary of conditional probability, extract from get_conditional_proba()\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;124;03m    Returns: delta (float) - the delta value for this instance\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m     proba \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;28mabs\u001b[39m(cond_proba[val_1][uni_x] \u001b[38;5;241m-\u001b[39m cond_proba[val_2][uni_x]) \u001b[38;5;28;01mfor\u001b[39;00m uni_x \u001b[38;5;129;01min\u001b[39;00m \u001b[43mcond_proba\u001b[49m\u001b[43m[\u001b[49m\u001b[43mval_1\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mindex])\n\u001b[0;32m     52\u001b[0m     delta \u001b[38;5;241m=\u001b[39m (proba\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnorm)\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m delta\n",
      "\u001b[1;31mKeyError\u001b[0m: 9.0"
     ]
    }
   ],
   "source": [
    "# Knn-VDM complete code\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "# specific the continuous columns index if any\n",
    "vdm = ValueDifferenceMetric(X_train, y_train, continuous = None)\n",
    "vdm.fit()\n",
    "# Knn model, n_neigbour = 3, metrics = vdm\n",
    "knn_vdm = KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')\n",
    "# Fit model\n",
    "knn_vdm.fit(X_train, y_train)\n",
    "# Testing\n",
    "y_pred_knn = knn_vdm.predict(X_test)\n",
    "knn_vdm.classes_\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model Knn-VDM: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68246577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # !!!! WARING: TIME CONSUMING\n",
    "\n",
    "# # Bias and variance decomposition\n",
    "# # Convert all dataframe to array first\n",
    "# X_train = X_train.values\n",
    "# X_test = X_test.values\n",
    "# y_train = y_train.values\n",
    "# y_test = y_test.values\n",
    "\n",
    "# avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "#         knn_vdm, X_train, y_train, X_test, y_test, \n",
    "#         loss='0-1_loss',\n",
    "#         random_seed=123)\n",
    "\n",
    "# print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "# print('Average bias: %.3f' % avg_bias)\n",
    "# print('Average variance: %.3f' % avg_var)\n",
    "# print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb00a1f6",
   "metadata": {},
   "source": [
    "## 3.4 KNN-VDM, DT, max_depth = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a9fcc018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class representation - original:  Counter({0: 500, 1: 268})\n",
      "Class representation - training data:  Counter({0: 375, 1: 201})\n",
      "Class representation - testing data:  Counter({0: 125, 1: 67})\n",
      "(576, 8) (192, 8)\n",
      "Class representation - training data:  Counter({1: 375, 0: 375})\n"
     ]
    }
   ],
   "source": [
    "# Prepare data and apply SMOTE\n",
    "# make test & train split\n",
    "X = pima_m5.drop('Outcome', axis=1)\n",
    "y = pima_m5['Outcome']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=30, stratify = y)\n",
    "\n",
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(pima_m5['Outcome'])) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test)) \n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "\n",
    "# SMOTE\n",
    "#! pip install imblearn --user\n",
    "from imblearn import under_sampling, over_sampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state = 22)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Check representation of class after SMOTE \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "\n",
    "# SAM\n",
    "# Count number of categories\n",
    "n_categories = pima_m5.drop('Outcome', axis=1).nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cee14d45",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "14.0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [40]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m knn_vdm\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Testing\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m y_pred_knn \u001b[38;5;241m=\u001b[39m \u001b[43mknn_vdm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m knn_vdm\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(y_test, y_pred_knn))\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:226\u001b[0m, in \u001b[0;36mKNeighborsClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;124;03m\"\"\"Predict the class labels for the provided data.\u001b[39;00m\n\u001b[0;32m    211\u001b[0m \n\u001b[0;32m    212\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;124;03m    Class labels for each data sample.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muniform\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;66;03m# In that case, we do not need the distances to perform\u001b[39;00m\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;66;03m# the weighting so we do not compute them.\u001b[39;00m\n\u001b[1;32m--> 226\u001b[0m     neigh_ind \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkneighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    227\u001b[0m     neigh_dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py:796\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    793\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    794\u001b[0m         kwds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meffective_metric_params_\n\u001b[1;32m--> 796\u001b[0m     chunked_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpairwise_distances_chunked\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    798\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_X\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    800\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreduce_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreduce_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    801\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meffective_metric_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    802\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    803\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    804\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    805\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    807\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_method \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mball_tree\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkd_tree\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m issparse(X):\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1850\u001b[0m, in \u001b[0;36mpairwise_distances_chunked\u001b[1;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1849\u001b[0m     X_chunk \u001b[38;5;241m=\u001b[39m X[sl]\n\u001b[1;32m-> 1850\u001b[0m D_chunk \u001b[38;5;241m=\u001b[39m pairwise_distances(X_chunk, Y, metric\u001b[38;5;241m=\u001b[39mmetric, n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m   1851\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (X \u001b[38;5;129;01mis\u001b[39;00m Y \u001b[38;5;129;01mor\u001b[39;00m Y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m PAIRWISE_DISTANCE_FUNCTIONS\u001b[38;5;241m.\u001b[39mget(\n\u001b[0;32m   1852\u001b[0m     metric, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1853\u001b[0m ) \u001b[38;5;129;01mis\u001b[39;00m euclidean_distances:\n\u001b[0;32m   1854\u001b[0m     \u001b[38;5;66;03m# zeroing diagonal, taking care of aliases of \"euclidean\",\u001b[39;00m\n\u001b[0;32m   1855\u001b[0m     \u001b[38;5;66;03m# i.e. \"l2\"\u001b[39;00m\n\u001b[0;32m   1856\u001b[0m     D_chunk\u001b[38;5;241m.\u001b[39mflat[sl\u001b[38;5;241m.\u001b[39mstart :: _num_samples(X) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:2022\u001b[0m, in \u001b[0;36mpairwise_distances\u001b[1;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[0;32m   2019\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m distance\u001b[38;5;241m.\u001b[39msquareform(distance\u001b[38;5;241m.\u001b[39mpdist(X, metric\u001b[38;5;241m=\u001b[39mmetric, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds))\n\u001b[0;32m   2020\u001b[0m     func \u001b[38;5;241m=\u001b[39m partial(distance\u001b[38;5;241m.\u001b[39mcdist, metric\u001b[38;5;241m=\u001b[39mmetric, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m-> 2022\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _parallel_pairwise(X, Y, func, n_jobs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1563\u001b[0m, in \u001b[0;36m_parallel_pairwise\u001b[1;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[0;32m   1560\u001b[0m X, Y, dtype \u001b[38;5;241m=\u001b[39m _return_float_dtype(X, Y)\n\u001b[0;32m   1562\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m effective_n_jobs(n_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m-> 1563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(X, Y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m   1565\u001b[0m \u001b[38;5;66;03m# enforce a threading backend to prevent data communication overhead\u001b[39;00m\n\u001b[0;32m   1566\u001b[0m fd \u001b[38;5;241m=\u001b[39m delayed(_dist_wrapper)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1607\u001b[0m, in \u001b[0;36m_pairwise_callable\u001b[1;34m(X, Y, metric, force_all_finite, **kwds)\u001b[0m\n\u001b[0;32m   1605\u001b[0m     iterator \u001b[38;5;241m=\u001b[39m itertools\u001b[38;5;241m.\u001b[39mproduct(\u001b[38;5;28mrange\u001b[39m(X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]), \u001b[38;5;28mrange\u001b[39m(Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]))\n\u001b[0;32m   1606\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, j \u001b[38;5;129;01min\u001b[39;00m iterator:\n\u001b[1;32m-> 1607\u001b[0m         out[i, j] \u001b[38;5;241m=\u001b[39m metric(X[i], Y[j], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m   1609\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\vdm3\\vdm.py:83\u001b[0m, in \u001b[0;36mValueDifferenceMetric.get_distance\u001b[1;34m(self, ins_1, ins_2, norm)\u001b[0m\n\u001b[0;32m     80\u001b[0m     ins_1_cat \u001b[38;5;241m=\u001b[39m ins_1\n\u001b[0;32m     81\u001b[0m     ins_2_cat \u001b[38;5;241m=\u001b[39m ins_2\n\u001b[1;32m---> 83\u001b[0m cat_dist \u001b[38;5;241m=\u001b[39m \u001b[43mget_delta_nd\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcond_proba\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mins_1_cat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mins_2_cat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontinuous \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     86\u001b[0m     cont_dist \u001b[38;5;241m=\u001b[39m get_cont_dist(ins_1_cont, ins_2_cont, norm)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\vdm3\\components.py:77\u001b[0m, in \u001b[0;36mget_delta_nd\u001b[1;34m(cond_proba, ins_1, ins_2, norm)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_delta_nd\u001b[39m(cond_proba, ins_1, ins_2, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m):\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;124;03m\"\"\" get deltas for vdm for multidimensional data\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    Parameters: cond_proba (dict) - a dictionary of conditional probability, extract from get_conditional_proba_nd()\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;124;03m    Returns: deltas (array) - the delta values between ins_1 and ins_2\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 77\u001b[0m     deltas \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([get_delta(cond_proba[col], ins_1[col], ins_2[col], norm) \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m cond_proba])\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m deltas\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\vdm3\\components.py:77\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_delta_nd\u001b[39m(cond_proba, ins_1, ins_2, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m):\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;124;03m\"\"\" get deltas for vdm for multidimensional data\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    Parameters: cond_proba (dict) - a dictionary of conditional probability, extract from get_conditional_proba_nd()\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;124;03m    Returns: deltas (array) - the delta values between ins_1 and ins_2\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 77\u001b[0m     deltas \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[43mget_delta\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcond_proba\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mins_1\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mins_2\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m cond_proba])\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m deltas\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\vdm3\\components.py:51\u001b[0m, in \u001b[0;36mget_delta\u001b[1;34m(cond_proba, val_1, val_2, norm)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_delta\u001b[39m(cond_proba, val_1, val_2, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m):\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;124;03m\"\"\" get delta for vdm\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \n\u001b[0;32m     44\u001b[0m \u001b[38;5;124;03m    Parameters: cond_proba (dict) - a dictionary of conditional probability, extract from get_conditional_proba()\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;124;03m    Returns: delta (float) - the delta value for this instance\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m     proba \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;28mabs\u001b[39m(cond_proba[val_1][uni_x] \u001b[38;5;241m-\u001b[39m cond_proba[val_2][uni_x]) \u001b[38;5;28;01mfor\u001b[39;00m uni_x \u001b[38;5;129;01min\u001b[39;00m \u001b[43mcond_proba\u001b[49m\u001b[43m[\u001b[49m\u001b[43mval_1\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mindex])\n\u001b[0;32m     52\u001b[0m     delta \u001b[38;5;241m=\u001b[39m (proba\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnorm)\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m delta\n",
      "\u001b[1;31mKeyError\u001b[0m: 14.0"
     ]
    }
   ],
   "source": [
    "# Knn-VDM complete code\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "# specific the continuous columns index if any\n",
    "vdm = ValueDifferenceMetric(X_train, y_train, continuous = None)\n",
    "vdm.fit()\n",
    "# Knn model, n_neigbour = 3, metrics = vdm\n",
    "knn_vdm = KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')\n",
    "# Fit model\n",
    "knn_vdm.fit(X_train, y_train)\n",
    "# Testing\n",
    "y_pred_knn = knn_vdm.predict(X_test)\n",
    "knn_vdm.classes_\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model Knn-VDM: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d20fc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # !!!! WARING: TIME CONSUMING\n",
    "\n",
    "# # Bias and variance decomposition\n",
    "# # Convert all dataframe to array first\n",
    "# X_train = X_train.values\n",
    "# X_test = X_test.values\n",
    "# y_train = y_train.values\n",
    "# y_test = y_test.values\n",
    "\n",
    "# avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "#         knn_vdm, X_train, y_train, X_test, y_test, \n",
    "#         loss='0-1_loss',\n",
    "#         random_seed=123)\n",
    "\n",
    "# print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "# print('Average bias: %.3f' % avg_bias)\n",
    "# print('Average variance: %.3f' % avg_var)\n",
    "# print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bad5936",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
