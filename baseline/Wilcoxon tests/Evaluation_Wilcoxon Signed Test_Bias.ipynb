{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e739595",
   "metadata": {},
   "source": [
    "# Wilcoxon SIGNED test-BIAS\n",
    "By: Sam<br>\n",
    "Updated at: 16/10/2022<br>\n",
    "Compare performance of discretizers <br>\n",
    "Matched pairs settings\n",
    "Sample: 270 ML models after discretization (as at 16/10/2022)\n",
    "Purpose: pair-wise comparison metrics of the models using different discretization method\n",
    "\n",
    "===\n",
    "\n",
    "Input data: instrinsic properties and model performance metrics\n",
    "!!! **NB: Please update the data for metrics and export to csv before running this script!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1810bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5845bab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import evaluation data (updated at 16/10/2022)\n",
    "data = pd.read_csv(\"all_evaluation_161022.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e6fd0c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>disc</th>\n",
       "      <th>param</th>\n",
       "      <th>inconsistency</th>\n",
       "      <th>models</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>con_features</th>\n",
       "      <th>time_disc</th>\n",
       "      <th>time_train</th>\n",
       "      <th>bias</th>\n",
       "      <th>variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iris</td>\n",
       "      <td>EWD</td>\n",
       "      <td>4</td>\n",
       "      <td>0.06666667</td>\n",
       "      <td>ID3</td>\n",
       "      <td>0.84</td>\n",
       "      <td>4</td>\n",
       "      <td>0.016412</td>\n",
       "      <td>0.008698225</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>iris</td>\n",
       "      <td>EWD</td>\n",
       "      <td>7</td>\n",
       "      <td>0.02</td>\n",
       "      <td>ID3</td>\n",
       "      <td>0.79</td>\n",
       "      <td>4</td>\n",
       "      <td>0.015692</td>\n",
       "      <td>0.010634899</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>iris</td>\n",
       "      <td>EWD</td>\n",
       "      <td>10</td>\n",
       "      <td>0.006666667</td>\n",
       "      <td>ID3</td>\n",
       "      <td>0.95</td>\n",
       "      <td>4</td>\n",
       "      <td>0.016380</td>\n",
       "      <td>0.010643005</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>iris</td>\n",
       "      <td>EFD</td>\n",
       "      <td>4</td>\n",
       "      <td>0.04</td>\n",
       "      <td>ID3</td>\n",
       "      <td>0.84</td>\n",
       "      <td>4</td>\n",
       "      <td>0.016688</td>\n",
       "      <td>0.009439945</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>iris</td>\n",
       "      <td>EFD</td>\n",
       "      <td>7</td>\n",
       "      <td>0.04</td>\n",
       "      <td>ID3</td>\n",
       "      <td>0.95</td>\n",
       "      <td>4</td>\n",
       "      <td>0.023941</td>\n",
       "      <td>0.010675907</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset disc  param inconsistency models accuracy  con_features  time_disc  \\\n",
       "0    iris  EWD      4    0.06666667    ID3     0.84             4   0.016412   \n",
       "1    iris  EWD      7          0.02    ID3     0.79             4   0.015692   \n",
       "2    iris  EWD     10   0.006666667    ID3     0.95             4   0.016380   \n",
       "3    iris  EFD      4          0.04    ID3     0.84             4   0.016688   \n",
       "4    iris  EFD      7          0.04    ID3     0.95             4   0.023941   \n",
       "\n",
       "    time_train   bias variance  \n",
       "0  0.008698225  0.158    0.055  \n",
       "1  0.010634899  0.158    0.054  \n",
       "2  0.010643005  0.053    0.014  \n",
       "3  0.009439945  0.158    0.049  \n",
       "4  0.010675907  0.053     0.07  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb690ad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['EWD', 'EFD', 'FFD', 'ChiMerge', 'DT'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['disc'].unique() # get list of discretizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82abae21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['dataset', 'disc', 'param', 'inconsistency', 'models', 'accuracy',\n",
       "       'con_features', 'time_disc', 'time_train', 'bias', 'variance'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4baafad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 270 entries, 0 to 269\n",
      "Data columns (total 11 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   dataset        270 non-null    object \n",
      " 1   disc           270 non-null    object \n",
      " 2   param          270 non-null    int64  \n",
      " 3   inconsistency  270 non-null    object \n",
      " 4   models         270 non-null    object \n",
      " 5   accuracy       270 non-null    object \n",
      " 6   con_features   270 non-null    int64  \n",
      " 7   time_disc      270 non-null    float64\n",
      " 8   time_train     269 non-null    object \n",
      " 9   bias           234 non-null    object \n",
      " 10  variance       234 non-null    object \n",
      "dtypes: float64(1), int64(2), object(8)\n",
      "memory usage: 23.3+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4cf2753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ID3', 'CNB', 'Knn-VDM'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['models'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5daa08",
   "metadata": {},
   "source": [
    "# Wilcoxon_Complete pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ae483f",
   "metadata": {},
   "source": [
    "## 1.  Wilcoxon signed t test, bias\n",
    "Ref: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.wilcoxon.html\n",
    "Implement 4 replications: (DONE)\n",
    "- Regardless algorithms\n",
    "- Filter for each algorithm: CNB, ID3, Knn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9a9c06",
   "metadata": {},
   "source": [
    "## 1. 1 Bias, no filter in algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "869664de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparation: Prepare list of metrics for each discretization (test_list)\n",
    "# Step 1: Obtain bias for each discretization, convert into numeric, string values will be return as NaN\n",
    "ewd_bias = pd.to_numeric(data[data['disc']==\"EWD\"]['bias'],errors='coerce').tolist()\n",
    "efd_bias = pd.to_numeric(data[data['disc']==\"EFD\"]['bias'],errors='coerce').tolist()\n",
    "ffd_bias = pd.to_numeric(data[data['disc']==\"FFD\"]['bias'],errors='coerce').tolist()\n",
    "cm_bias = pd.to_numeric(data[data['disc']==\"ChiMerge\"]['bias'],errors='coerce').tolist()\n",
    "dt_bias = pd.to_numeric(data[data['disc']==\"DT\"]['bias'],errors='coerce').tolist()\n",
    "# Check number of metrics available for each discretizer\n",
    "# print(len(ewd_bias))\n",
    "# print(len(efd_bias))\n",
    "# print(len(ffd_bias))\n",
    "# print(len(cm_bias))\n",
    "# print(len(dt_bias))\n",
    "\n",
    "# Step 2: filter numeric values\n",
    "raw_list = [ewd_bias, efd_bias, ffd_bias, cm_bias, dt_bias]\n",
    "num_list = [] # filter numeric values only\n",
    "for metric in raw_list:\n",
    "#     metric_new = []\n",
    "#     for x in metric:\n",
    "#         if math.isnan(x) == False:\n",
    "#             metric_new.append(x)\n",
    "    metric_new = [x for x in metric if (math.isnan(x) == False)] # using list comprehension\n",
    "    #print(metric_new)\n",
    "    #print(len(metric_new))\n",
    "    num_list.append(metric_new)\n",
    "    \n",
    "# Step 3: random sample\n",
    "# For discretization methods with different value, randomly select so that the final sample size are equal\n",
    "# Reference: https://docs.python.org/3/library/random.html\n",
    "k = min(len(metric) for metric in num_list)\n",
    "test_list = []\n",
    "for metric in num_list:\n",
    "    random.seed(20)\n",
    "    if len(metric) > k:\n",
    "        metric = random.sample(metric, k=k)\n",
    "    else: metric = metric\n",
    "    #print(metric)\n",
    "    test_list.append(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "515b974e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialiation\n",
    "disc_key = ['ewd', 'efd', 'ffd', 'cm', 'dt']\n",
    "disc_value = test_list # list of metrics for each discretization after preparation\n",
    "test_stat = []\n",
    "p_value = []\n",
    "disc_compare = []\n",
    "# Create dictionary store discretization and series of accuracy\n",
    "disc = {}\n",
    "for key in disc_key:\n",
    "    for value in disc_value:\n",
    "        disc[key] = value\n",
    "        disc_value.remove(value)\n",
    "        break  \n",
    "\n",
    "# Create loop for Wilcoxon test (two sided) - handle diff = 0\n",
    "for i in disc_key:\n",
    "    for j in disc_key:\n",
    "        if i != j:\n",
    "            disc_compare.append(f'{i} vs {j}')\n",
    "            # print(f'{i} vs {j}')\n",
    "            # Compute difference list\n",
    "            diff_list = []\n",
    "            for m in range(0, len(disc[i])):\n",
    "                diff = disc[i][m] - disc[j][m]\n",
    "                #print(disc[i][m])\n",
    "                #print(disc[j][m])\n",
    "#                 print('diff = ', diff)\n",
    "#                 print('-------------')\n",
    "                diff_list.append(diff)\n",
    "                # print(diff_list)\n",
    "                \n",
    "            if all(item == 0 for item in diff_list) == False: # if the diff list does not contain all 0\n",
    "                test_stat.append(stats.wilcoxon(diff_list).statistic)\n",
    "                p_value.append(stats.wilcoxon(diff_list).pvalue)\n",
    "            else: # if the diff list contain only0, cannot do Wilcoxon test\n",
    "                error = 'N/A'\n",
    "                test_stat.append(error)\n",
    "                p_value.append(error)\n",
    "# print(test_stat)\n",
    "# print(p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc96320d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 3 lists to dataframe\n",
    "disc_compare = pd.DataFrame(disc_compare, columns=['disc_compare'])\n",
    "test_stat = pd.DataFrame(test_stat, columns=['wtest_stat'])\n",
    "p_value = pd.DataFrame(p_value, columns=['p_value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba3aa4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result table\n",
    "wt_result = pd.concat([disc_compare, test_stat, p_value], axis = 1)\n",
    "# Drop duplicate\n",
    "wt_result.drop_duplicates(subset=['p_value'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8d38811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disc_compare</th>\n",
       "      <th>wtest_stat</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ewd vs efd</td>\n",
       "      <td>251.5</td>\n",
       "      <td>0.815170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ewd vs ffd</td>\n",
       "      <td>201.0</td>\n",
       "      <td>0.238783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ewd vs cm</td>\n",
       "      <td>267.0</td>\n",
       "      <td>0.809380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ewd vs dt</td>\n",
       "      <td>218.5</td>\n",
       "      <td>0.267936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>efd vs ffd</td>\n",
       "      <td>240.0</td>\n",
       "      <td>0.653594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>efd vs cm</td>\n",
       "      <td>248.5</td>\n",
       "      <td>0.771929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>efd vs dt</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.231913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ffd vs cm</td>\n",
       "      <td>236.0</td>\n",
       "      <td>0.600577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ffd vs dt</td>\n",
       "      <td>124.0</td>\n",
       "      <td>0.008847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>cm vs dt</td>\n",
       "      <td>211.0</td>\n",
       "      <td>0.214305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   disc_compare  wtest_stat   p_value\n",
       "0    ewd vs efd       251.5  0.815170\n",
       "1    ewd vs ffd       201.0  0.238783\n",
       "2     ewd vs cm       267.0  0.809380\n",
       "3     ewd vs dt       218.5  0.267936\n",
       "5    efd vs ffd       240.0  0.653594\n",
       "6     efd vs cm       248.5  0.771929\n",
       "7     efd vs dt       187.0  0.231913\n",
       "10    ffd vs cm       236.0  0.600577\n",
       "11    ffd vs dt       124.0  0.008847\n",
       "15     cm vs dt       211.0  0.214305"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wt_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99d63a0",
   "metadata": {},
   "source": [
    "## 1.2 Bias, only CNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1640550e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "15\n",
      "20\n",
      "20\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "# Preparation: Prepare list of metrics for each discretization (test_list)\n",
    "# Step 1: Obtain bias for each discretization, convert into numeric, string values will be return as NaN\n",
    "# Filter for CNB\n",
    "# Obtain bias for each discretization, convert into numeric, string values will be return as NaN\n",
    "ewd_bias_cnb = pd.to_numeric(data[(data['disc']==\"EWD\") & (data['models']==\"CNB\")]['bias'],errors='coerce').tolist()\n",
    "efd_bias_cnb = pd.to_numeric(data[(data['disc']==\"EFD\") & (data['models']==\"CNB\")]['bias'],errors='coerce').tolist()\n",
    "ffd_bias_cnb = pd.to_numeric(data[(data['disc']==\"FFD\") & (data['models']==\"CNB\")]['bias'],errors='coerce').tolist()\n",
    "cm_bias_cnb = pd.to_numeric(data[(data['disc']==\"ChiMerge\") & (data['models']==\"CNB\")]['bias'],errors='coerce').tolist()\n",
    "dt_bias_cnb = pd.to_numeric(data[(data['disc']==\"DT\") & (data['models']==\"CNB\")]['bias'],errors='coerce').tolist()\n",
    "# Check number of metrics available for each discretizer\n",
    "print(len(ewd_bias_cnb))\n",
    "print(len(efd_bias_cnb))\n",
    "print(len(ffd_bias_cnb))\n",
    "print(len(cm_bias_cnb))\n",
    "print(len(dt_bias_cnb))\n",
    "\n",
    "# Step 2: filter numeric values\n",
    "raw_list = [ewd_bias_cnb,efd_bias_cnb, ffd_bias_cnb, cm_bias_cnb, dt_bias_cnb]\n",
    "num_list = [] # filter numeric values only\n",
    "for metric in raw_list:\n",
    "#     metric_new = []\n",
    "#     for x in metric:\n",
    "#         if math.isnan(x) == False:\n",
    "#             metric_new.append(x)\n",
    "    metric_new = [x for x in metric if (math.isnan(x) == False)] # using list comprehension\n",
    "    #print(metric_new)\n",
    "    #print(len(metric_new))\n",
    "    num_list.append(metric_new)\n",
    "    \n",
    "# Step 3: random sample\n",
    "# For discretization methods with different value, randomly select so that the final sample size are equal\n",
    "# Reference: https://docs.python.org/3/library/random.html\n",
    "k = min(len(metric) for metric in num_list)\n",
    "test_list = []\n",
    "for metric in num_list:\n",
    "    random.seed(20)\n",
    "    if len(metric) > k:\n",
    "        metric = random.sample(metric, k=k)\n",
    "    else: metric = metric\n",
    "    #print(metric)\n",
    "    test_list.append(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d65033f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialiation\n",
    "disc_key = ['ewd', 'efd', 'ffd', 'cm', 'dt']\n",
    "disc_value = test_list # list of metrics for each discretization after preparation\n",
    "test_stat = []\n",
    "p_value = []\n",
    "disc_compare = []\n",
    "# Create dictionary store discretization and series of accuracy\n",
    "disc = {}\n",
    "for key in disc_key:\n",
    "    for value in disc_value:\n",
    "        disc[key] = value\n",
    "        disc_value.remove(value)\n",
    "        break  \n",
    "\n",
    "# Create loop for Wilcoxon test (two sided) - handle diff = 0\n",
    "for i in disc_key:\n",
    "    for j in disc_key:\n",
    "        if i != j:\n",
    "            disc_compare.append(f'{i} vs {j}')\n",
    "            # print(f'{i} vs {j}')\n",
    "            # Compute difference list\n",
    "            diff_list = []\n",
    "            for m in range(0, len(disc[i])):\n",
    "                # diff = disc[i][m] - disc[j][m]\n",
    "                #print(disc[i][m])\n",
    "                #print(disc[j][m])\n",
    "#                 print('diff = ', diff)\n",
    "#                 print('-------------')\n",
    "                diff_list.append(diff)\n",
    "                # print(diff_list)\n",
    "                \n",
    "            if all(item == 0 for item in diff_list) == False: # if the diff list does not contain all 0\n",
    "                test_stat.append(stats.wilcoxon(diff_list).statistic)\n",
    "                p_value.append(stats.wilcoxon(diff_list).pvalue)\n",
    "            else: # if the diff list contain only0, cannot do Wilcoxon test\n",
    "                error = 'N/A'\n",
    "                test_stat.append(error)\n",
    "                p_value.append(error)\n",
    "# print(test_stat)\n",
    "# print(p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31f217db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 3 lists to dataframe\n",
    "disc_compare = pd.DataFrame(disc_compare, columns=['disc_compare'])\n",
    "test_stat = pd.DataFrame(test_stat, columns=['wtest_stat'])\n",
    "p_value = pd.DataFrame(p_value, columns=['p_value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff112ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result table\n",
    "wt_result = pd.concat([disc_compare, test_stat, p_value], axis = 1)\n",
    "# Drop duplicate\n",
    "wt_result.drop_duplicates(subset=['p_value'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "394d5633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disc_compare</th>\n",
       "      <th>wtest_stat</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ewd vs efd</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  disc_compare  wtest_stat   p_value\n",
       "0   ewd vs efd         0.0  0.000488"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wt_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4069c86d",
   "metadata": {},
   "source": [
    "## 1.2 Bias, only ID3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8981b526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "15\n",
      "20\n",
      "20\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "# Preparation: Prepare list of metrics for each discretization (test_list)\n",
    "# Step 1: Obtain bias for each discretization, convert into numeric, string values will be return as NaN\n",
    "# Filter for ID3\n",
    "# Obtain bias for each discretization, convert into numeric, string values will be return as NaN\n",
    "ewd_bias_ID3 = pd.to_numeric(data[(data['disc']==\"EWD\") & (data['models']==\"ID3\")]['bias'],errors='coerce').tolist()\n",
    "efd_bias_ID3 = pd.to_numeric(data[(data['disc']==\"EFD\") & (data['models']==\"ID3\")]['bias'],errors='coerce').tolist()\n",
    "ffd_bias_ID3 = pd.to_numeric(data[(data['disc']==\"FFD\") & (data['models']==\"ID3\")]['bias'],errors='coerce').tolist()\n",
    "cm_bias_ID3 = pd.to_numeric(data[(data['disc']==\"ChiMerge\") & (data['models']==\"ID3\")]['bias'],errors='coerce').tolist()\n",
    "dt_bias_ID3 = pd.to_numeric(data[(data['disc']==\"DT\") & (data['models']==\"ID3\")]['bias'],errors='coerce').tolist()\n",
    "# Check number of metrics available for each discretizer\n",
    "print(len(ewd_bias_ID3))\n",
    "print(len(efd_bias_ID3))\n",
    "print(len(ffd_bias_ID3))\n",
    "print(len(cm_bias_ID3))\n",
    "print(len(dt_bias_ID3))\n",
    "\n",
    "# Step 2: filter numeric values\n",
    "raw_list = [ewd_bias_ID3,efd_bias_ID3, ffd_bias_ID3, cm_bias_ID3, dt_bias_ID3]\n",
    "num_list = [] # filter numeric values only\n",
    "for metric in raw_list:\n",
    "#     metric_new = []\n",
    "#     for x in metric:\n",
    "#         if math.isnan(x) == False:\n",
    "#             metric_new.append(x)\n",
    "    metric_new = [x for x in metric if (math.isnan(x) == False)] # using list comprehension\n",
    "    #print(metric_new)\n",
    "    #print(len(metric_new))\n",
    "    num_list.append(metric_new)\n",
    "    \n",
    "# Step 3: random sample\n",
    "# For discretization methods with different value, randomly select so that the final sample size are equal\n",
    "# Reference: https://docs.python.org/3/library/random.html\n",
    "k = min(len(metric) for metric in num_list)\n",
    "test_list = []\n",
    "for metric in num_list:\n",
    "    random.seed(20)\n",
    "    if len(metric) > k:\n",
    "        metric = random.sample(metric, k=k)\n",
    "    else: metric = metric\n",
    "    #print(metric)\n",
    "    test_list.append(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "20b9c57b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anhtth/opt/anaconda3/lib/python3.9/site-packages/scipy/stats/morestats.py:3141: UserWarning: Exact p-value calculation does not work if there are ties. Switching to normal approximation.\n",
      "  warnings.warn(\"Exact p-value calculation does not work if there are \"\n"
     ]
    }
   ],
   "source": [
    "# Initialiation\n",
    "disc_key = ['ewd', 'efd', 'ffd', 'cm', 'dt']\n",
    "disc_value = test_list # list of metrics for each discretization after preparation\n",
    "test_stat = []\n",
    "p_value = []\n",
    "disc_compare = []\n",
    "# Create dictionary store discretization and series of accuracy\n",
    "disc = {}\n",
    "for key in disc_key:\n",
    "    for value in disc_value:\n",
    "        disc[key] = value\n",
    "        disc_value.remove(value)\n",
    "        break  \n",
    "\n",
    "# Create loop for Wilcoxon test (two sided) - handle diff = 0\n",
    "for i in disc_key:\n",
    "    for j in disc_key:\n",
    "        if i != j:\n",
    "            disc_compare.append(f'{i} vs {j}')\n",
    "            # print(f'{i} vs {j}')\n",
    "            # Compute difference list\n",
    "            diff_list = []\n",
    "            for m in range(0, len(disc[i])):\n",
    "                diff = disc[i][m] - disc[j][m]\n",
    "                #print(disc[i][m])\n",
    "                #print(disc[j][m])\n",
    "#                 print('diff = ', diff)\n",
    "#                 print('-------------')\n",
    "                diff_list.append(diff)\n",
    "                # print(diff_list)\n",
    "                \n",
    "            if all(item == 0 for item in diff_list) == False: # if the diff list does not contain all 0\n",
    "                test_stat.append(stats.wilcoxon(diff_list).statistic)\n",
    "                p_value.append(stats.wilcoxon(diff_list).pvalue)\n",
    "            else: # if the diff list contain only0, cannot do Wilcoxon test\n",
    "                error = 'N/A'\n",
    "                test_stat.append(error)\n",
    "                p_value.append(error)\n",
    "# print(test_stat)\n",
    "# print(p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a3542a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 3 lists to dataframe\n",
    "disc_compare = pd.DataFrame(disc_compare, columns=['disc_compare'])\n",
    "test_stat = pd.DataFrame(test_stat, columns=['wtest_stat'])\n",
    "p_value = pd.DataFrame(p_value, columns=['p_value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "88580c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result table\n",
    "wt_result = pd.concat([disc_compare, test_stat, p_value], axis = 1)\n",
    "# Drop duplicate\n",
    "wt_result.drop_duplicates(subset=['p_value'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c639d795",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disc_compare</th>\n",
       "      <th>wtest_stat</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ewd vs efd</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.034170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ewd vs ffd</td>\n",
       "      <td>36.5</td>\n",
       "      <td>0.207764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ewd vs cm</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.220899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ewd vs dt</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.063721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>efd vs ffd</td>\n",
       "      <td>43.5</td>\n",
       "      <td>0.389404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>efd vs cm</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.432626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>efd vs dt</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.083252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ffd vs ewd</td>\n",
       "      <td>36.5</td>\n",
       "      <td>0.187622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ffd vs efd</td>\n",
       "      <td>43.5</td>\n",
       "      <td>0.359131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ffd vs cm</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.182170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ffd vs dt</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.074647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>cm vs dt</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.094604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   disc_compare  wtest_stat   p_value\n",
       "0    ewd vs efd        12.0  0.034170\n",
       "1    ewd vs ffd        36.5  0.207764\n",
       "2     ewd vs cm        33.0  0.220899\n",
       "3     ewd vs dt        27.0  0.063721\n",
       "5    efd vs ffd        43.5  0.389404\n",
       "6     efd vs cm        40.0  0.432626\n",
       "7     efd vs dt        29.0  0.083252\n",
       "8    ffd vs ewd        36.5  0.187622\n",
       "9    ffd vs efd        43.5  0.359131\n",
       "10    ffd vs cm        22.0  0.182170\n",
       "11    ffd vs dt        20.0  0.074647\n",
       "15     cm vs dt        30.0  0.094604"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wt_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4712892c",
   "metadata": {},
   "source": [
    "## 1.3 Bias, only KNN-VDM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d62f5ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "15\n",
      "20\n",
      "20\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "# Preparation: Prepare list of metrics for each discretization (test_list)\n",
    "# Step 1: Obtain bias for each discretization, convert into numeric, string values will be return as NaN\n",
    "# Filter for Knn-VDM\n",
    "# Obtain bias for each discretization, convert into numeric, string values will be return as NaN\n",
    "ewd_bias_knn = pd.to_numeric(data[(data['disc']==\"EWD\") & (data['models']==\"Knn-VDM\")]['bias'],errors='coerce').tolist()\n",
    "efd_bias_knn = pd.to_numeric(data[(data['disc']==\"EFD\") & (data['models']==\"Knn-VDM\")]['bias'],errors='coerce').tolist()\n",
    "ffd_bias_knn = pd.to_numeric(data[(data['disc']==\"FFD\") & (data['models']==\"Knn-VDM\")]['bias'],errors='coerce').tolist()\n",
    "cm_bias_knn = pd.to_numeric(data[(data['disc']==\"ChiMerge\") & (data['models']==\"Knn-VDM\")]['bias'],errors='coerce').tolist()\n",
    "dt_bias_knn = pd.to_numeric(data[(data['disc']==\"ChiMerge\") & (data['models']==\"Knn-VDM\")]['bias'],errors='coerce').tolist()\n",
    "\n",
    "# Check number of metrics available for each discretizer\n",
    "print(len(ewd_bias_knn))\n",
    "print(len(efd_bias_knn))\n",
    "print(len(ffd_bias_knn))\n",
    "print(len(cm_bias_knn))\n",
    "print(len(dt_bias_knn))\n",
    "\n",
    "# Step 2: filter numeric values\n",
    "raw_list = [ewd_bias_knn,efd_bias_knn, ffd_bias_knn, cm_bias_knn, dt_bias_knn]\n",
    "num_list = [] # filter numeric values only\n",
    "for metric in raw_list:\n",
    "#     metric_new = []\n",
    "#     for x in metric:\n",
    "#         if math.isnan(x) == False:\n",
    "#             metric_new.append(x)\n",
    "    metric_new = [x for x in metric if (math.isnan(x) == False)] # using list comprehension\n",
    "    #print(metric_new)\n",
    "    #print(len(metric_new))\n",
    "    num_list.append(metric_new)\n",
    "    \n",
    "# Step 3: random sample\n",
    "# For discretization methods with different value, randomly select so that the final sample size are equal\n",
    "# Reference: https://docs.python.org/3/library/random.html\n",
    "k = min(len(metric) for metric in num_list)\n",
    "test_list = []\n",
    "for metric in num_list:\n",
    "    random.seed(20)\n",
    "    if len(metric) > k:\n",
    "        metric = random.sample(metric, k=k)\n",
    "    else: metric = metric\n",
    "    #print(metric)\n",
    "    test_list.append(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f8fed1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialiation\n",
    "disc_key = ['ewd', 'efd', 'ffd', 'cm', 'dt']\n",
    "disc_value = test_list # list of metrics for each discretization after preparation\n",
    "test_stat = []\n",
    "p_value = []\n",
    "disc_compare = []\n",
    "# Create dictionary store discretization and series of accuracy\n",
    "disc = {}\n",
    "for key in disc_key:\n",
    "    for value in disc_value:\n",
    "        disc[key] = value\n",
    "        disc_value.remove(value)\n",
    "        break  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bd943645",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anhtth/opt/anaconda3/lib/python3.9/site-packages/scipy/stats/morestats.py:3141: UserWarning: Exact p-value calculation does not work if there are ties. Switching to normal approximation.\n",
      "  warnings.warn(\"Exact p-value calculation does not work if there are \"\n",
      "/Users/anhtth/opt/anaconda3/lib/python3.9/site-packages/scipy/stats/morestats.py:3155: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    }
   ],
   "source": [
    "# Create loop for Wilcoxon test (two sided) - handle diff = 0\n",
    "for i in disc_key:\n",
    "    for j in disc_key:\n",
    "        if i != j:\n",
    "            disc_compare.append(f'{i} vs {j}')\n",
    "            #print(f'{i} vs {j}')\n",
    "            # Compute difference list\n",
    "            diff_list = []\n",
    "            for m in range(0, len(disc[i])):\n",
    "                diff = disc[i][m] - disc[j][m]\n",
    "                #print(disc[i][m])\n",
    "                #print(disc[j][m])\n",
    "#                 print('diff = ', diff)\n",
    "#                 print('-------------')\n",
    "                diff_list.append(diff)\n",
    "                # print(diff_list)\n",
    "                \n",
    "            if all(item == 0 for item in diff_list) == False: # if the diff list does not contain all 0\n",
    "                test_stat.append(stats.wilcoxon(diff_list).statistic)\n",
    "                p_value.append(stats.wilcoxon(diff_list).pvalue)\n",
    "            else: # if the diff list contain only0, cannot do Wilcoxon test\n",
    "                error = 'N/A'\n",
    "                test_stat.append(error)\n",
    "                p_value.append(error)\n",
    "# print(test_stat)\n",
    "# print(p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2263c095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 3 lists to dataframe\n",
    "disc_compare = pd.DataFrame(disc_compare, columns=['disc_compare'])\n",
    "test_stat = pd.DataFrame(test_stat, columns=['wtest_stat'])\n",
    "p_value = pd.DataFrame(p_value, columns=['p_value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "208a420b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result table\n",
    "wt_result = pd.concat([disc_compare, test_stat, p_value], axis = 1)\n",
    "# Drop duplicate\n",
    "wt_result.drop_duplicates(subset=['p_value'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1fa8cb9b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disc_compare</th>\n",
       "      <th>wtest_stat</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ewd vs efd</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.21875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ewd vs ffd</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.4375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ewd vs cm</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.5625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>efd vs ffd</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.84375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>efd vs cm</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.68583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ffd vs efd</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.6875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ffd vs cm</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>cm vs dt</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   disc_compare wtest_stat  p_value\n",
       "0    ewd vs efd        4.0  0.21875\n",
       "1    ewd vs ffd        6.0   0.4375\n",
       "2     ewd vs cm        7.0   0.5625\n",
       "5    efd vs ffd        8.5  0.84375\n",
       "6     efd vs cm        6.0  0.68583\n",
       "9    ffd vs efd        8.5   0.6875\n",
       "10    ffd vs cm       10.0      1.0\n",
       "15     cm vs dt        N/A      N/A"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wt_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6025d7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
