{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e739595",
   "metadata": {},
   "source": [
    "# Wilcoxon SIGNED test - ACCURACY\n",
    "By: Sam<br>\n",
    "Updated at: 16/10/2022<br>\n",
    "Compare performance of discretizers <br>\n",
    "Matched pairs settings\n",
    "Sample: 270 ML models after discretization (as at 16.10.2022)\n",
    "Purpose: pair-wise comparison metrics of the models using different discretization method\n",
    "\n",
    "===\n",
    "\n",
    "Input data: instrinsic properties and model performance metrics\n",
    "!!! **NB: Please update the data for metrics and export to csv before running this script!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1810bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5845bab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import evaluation data (updated at 16/10/2022)\n",
    "data = pd.read_csv(\"all_evaluation_161022.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e6fd0c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>disc</th>\n",
       "      <th>param</th>\n",
       "      <th>inconsistency</th>\n",
       "      <th>models</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>con_features</th>\n",
       "      <th>time_disc</th>\n",
       "      <th>time_train</th>\n",
       "      <th>bias</th>\n",
       "      <th>variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iris</td>\n",
       "      <td>EWD</td>\n",
       "      <td>4</td>\n",
       "      <td>0.06666667</td>\n",
       "      <td>ID3</td>\n",
       "      <td>0.84</td>\n",
       "      <td>4</td>\n",
       "      <td>0.016412</td>\n",
       "      <td>0.008698225</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>iris</td>\n",
       "      <td>EWD</td>\n",
       "      <td>7</td>\n",
       "      <td>0.02</td>\n",
       "      <td>ID3</td>\n",
       "      <td>0.79</td>\n",
       "      <td>4</td>\n",
       "      <td>0.015692</td>\n",
       "      <td>0.010634899</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>iris</td>\n",
       "      <td>EWD</td>\n",
       "      <td>10</td>\n",
       "      <td>0.006666667</td>\n",
       "      <td>ID3</td>\n",
       "      <td>0.95</td>\n",
       "      <td>4</td>\n",
       "      <td>0.016380</td>\n",
       "      <td>0.010643005</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>iris</td>\n",
       "      <td>EFD</td>\n",
       "      <td>4</td>\n",
       "      <td>0.04</td>\n",
       "      <td>ID3</td>\n",
       "      <td>0.84</td>\n",
       "      <td>4</td>\n",
       "      <td>0.016688</td>\n",
       "      <td>0.009439945</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>iris</td>\n",
       "      <td>EFD</td>\n",
       "      <td>7</td>\n",
       "      <td>0.04</td>\n",
       "      <td>ID3</td>\n",
       "      <td>0.95</td>\n",
       "      <td>4</td>\n",
       "      <td>0.023941</td>\n",
       "      <td>0.010675907</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset disc  param inconsistency models accuracy  con_features  time_disc  \\\n",
       "0    iris  EWD      4    0.06666667    ID3     0.84             4   0.016412   \n",
       "1    iris  EWD      7          0.02    ID3     0.79             4   0.015692   \n",
       "2    iris  EWD     10   0.006666667    ID3     0.95             4   0.016380   \n",
       "3    iris  EFD      4          0.04    ID3     0.84             4   0.016688   \n",
       "4    iris  EFD      7          0.04    ID3     0.95             4   0.023941   \n",
       "\n",
       "    time_train   bias variance  \n",
       "0  0.008698225  0.158    0.055  \n",
       "1  0.010634899  0.158    0.054  \n",
       "2  0.010643005  0.053    0.014  \n",
       "3  0.009439945  0.158    0.049  \n",
       "4  0.010675907  0.053     0.07  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb690ad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['EWD', 'EFD', 'FFD', 'ChiMerge', 'DT'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['disc'].unique() # get list of discretizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82abae21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['dataset', 'disc', 'param', 'inconsistency', 'models', 'accuracy',\n",
       "       'con_features', 'time_disc', 'time_train', 'bias', 'variance'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4baafad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 270 entries, 0 to 269\n",
      "Data columns (total 11 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   dataset        270 non-null    object \n",
      " 1   disc           270 non-null    object \n",
      " 2   param          270 non-null    int64  \n",
      " 3   inconsistency  270 non-null    object \n",
      " 4   models         270 non-null    object \n",
      " 5   accuracy       270 non-null    object \n",
      " 6   con_features   270 non-null    int64  \n",
      " 7   time_disc      270 non-null    float64\n",
      " 8   time_train     269 non-null    object \n",
      " 9   bias           234 non-null    object \n",
      " 10  variance       234 non-null    object \n",
      "dtypes: float64(1), int64(2), object(8)\n",
      "memory usage: 23.3+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4cf2753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ID3', 'CNB', 'Knn-VDM'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['models'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f48fed5",
   "metadata": {},
   "source": [
    "# Wilcoxon_Complete pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ae483f",
   "metadata": {},
   "source": [
    "## 1.  Wilcoxon signed t test, accuracy\n",
    "Ref: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.wilcoxon.html\n",
    "Implement 4 replications: (DONE)\n",
    "- Regardless algorithms\n",
    "- Filter for each algorithm: CNB, ID3, Knn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa58850",
   "metadata": {},
   "source": [
    "## 1. Accuracy, no filter in algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ef5cead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparation: Prepare list of metrics for each discretization (test_list)\n",
    "# Step 1: Obtain accuracy for each discretization, convert into numeric, string values will be return as NaN\n",
    "ewd_acc = pd.to_numeric(data[data['disc']==\"EWD\"]['accuracy'],errors='coerce').tolist()\n",
    "efd_acc = pd.to_numeric(data[data['disc']==\"EFD\"]['accuracy'],errors='coerce').tolist()\n",
    "ffd_acc = pd.to_numeric(data[data['disc']==\"FFD\"]['accuracy'],errors='coerce').tolist()\n",
    "cm_acc = pd.to_numeric(data[data['disc']==\"ChiMerge\"]['accuracy'],errors='coerce').tolist()\n",
    "dt_acc = pd.to_numeric(data[data['disc']==\"DT\"]['accuracy'],errors='coerce').tolist()\n",
    "# Check number of metrics available for each discretizer\n",
    "# print(len(ewd_acc))\n",
    "# print(len(efd_acc))\n",
    "# print(len(ffd_acc))\n",
    "# print(len(cm_acc))\n",
    "# print(len(dt_acc))\n",
    "\n",
    "# Step 2: filter numeric values\n",
    "raw_list = [ewd_acc, efd_acc, ffd_acc, cm_acc, dt_acc]\n",
    "num_list = [] # filter numeric values only\n",
    "for metric in raw_list:\n",
    "#     metric_new = []\n",
    "#     for x in metric:\n",
    "#         if math.isnan(x) == False:\n",
    "#             metric_new.append(x)\n",
    "    metric_new = [x for x in metric if (math.isnan(x) == False)] # using list comprehension\n",
    "    #print(metric_new)\n",
    "    #print(len(metric_new))\n",
    "    num_list.append(metric_new)\n",
    "    \n",
    "# Step 3: random sample\n",
    "# For discretization methods with different value, randomly select so that the final sample size are equal\n",
    "# Reference: https://docs.python.org/3/library/random.html\n",
    "k = min(len(metric) for metric in num_list)\n",
    "test_list = []\n",
    "for metric in num_list:\n",
    "    random.seed(20)\n",
    "    if len(metric) > k:\n",
    "        metric = random.sample(metric, k=k)\n",
    "    else: metric = metric\n",
    "    #print(metric)\n",
    "    test_list.append(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8612d553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialiation\n",
    "disc_key = ['ewd', 'efd', 'ffd', 'cm', 'dt']\n",
    "disc_value = test_list # list of metrics for each discretization after preparation\n",
    "test_stat = []\n",
    "p_value = []\n",
    "disc_compare = []\n",
    "# Create dictionary store discretization and series of accuracy\n",
    "disc = {}\n",
    "for key in disc_key:\n",
    "    for value in disc_value:\n",
    "        disc[key] = value\n",
    "        disc_value.remove(value)\n",
    "        break  \n",
    "\n",
    "# Create loop for Wilcoxon test (two sided) - handle diff = 0\n",
    "for i in disc_key:\n",
    "    for j in disc_key:\n",
    "        if i != j:\n",
    "            disc_compare.append(f'{i} vs {j}')\n",
    "            # print(f'{i} vs {j}')\n",
    "            # Compute difference list\n",
    "            diff_list = []\n",
    "            for m in range(0, len(disc[i])):\n",
    "                diff = disc[i][m] - disc[j][m]\n",
    "                #print(disc[i][m])\n",
    "                #print(disc[j][m])\n",
    "#                 print('diff = ', diff)\n",
    "#                 print('-------------')\n",
    "                diff_list.append(diff)\n",
    "                # print(diff_list)\n",
    "                \n",
    "            if all(item == 0 for item in diff_list) == False: # if the diff list does not contain all 0\n",
    "                test_stat.append(stats.wilcoxon(diff_list).statistic)\n",
    "                p_value.append(stats.wilcoxon(diff_list).pvalue)\n",
    "            else: # if the diff list contain only0, cannot do Wilcoxon test\n",
    "                error = 'N/A'\n",
    "                test_stat.append(error)\n",
    "                p_value.append(error)\n",
    "# print(test_stat)\n",
    "# print(p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fcac455c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 3 lists to dataframe\n",
    "disc_compare = pd.DataFrame(disc_compare, columns=['disc_compare'])\n",
    "test_stat = pd.DataFrame(test_stat, columns=['wtest_stat'])\n",
    "p_value = pd.DataFrame(p_value, columns=['p_value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "128116ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result table\n",
    "wt_result = pd.concat([disc_compare, test_stat, p_value], axis = 1)\n",
    "# Drop duplicate\n",
    "wt_result.drop_duplicates(subset=['p_value'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "468124b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disc_compare</th>\n",
       "      <th>wtest_stat</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ewd vs efd</td>\n",
       "      <td>297.0</td>\n",
       "      <td>0.571536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ewd vs ffd</td>\n",
       "      <td>293.5</td>\n",
       "      <td>0.381443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ewd vs cm</td>\n",
       "      <td>329.5</td>\n",
       "      <td>0.551990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ewd vs dt</td>\n",
       "      <td>293.0</td>\n",
       "      <td>0.377250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>efd vs ffd</td>\n",
       "      <td>351.5</td>\n",
       "      <td>0.782824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>efd vs cm</td>\n",
       "      <td>347.0</td>\n",
       "      <td>0.945856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>efd vs dt</td>\n",
       "      <td>273.5</td>\n",
       "      <td>0.159291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ffd vs cm</td>\n",
       "      <td>357.5</td>\n",
       "      <td>0.850432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ffd vs dt</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.045349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>cm vs dt</td>\n",
       "      <td>235.0</td>\n",
       "      <td>0.078696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   disc_compare  wtest_stat   p_value\n",
       "0    ewd vs efd       297.0  0.571536\n",
       "1    ewd vs ffd       293.5  0.381443\n",
       "2     ewd vs cm       329.5  0.551990\n",
       "3     ewd vs dt       293.0  0.377250\n",
       "5    efd vs ffd       351.5  0.782824\n",
       "6     efd vs cm       347.0  0.945856\n",
       "7     efd vs dt       273.5  0.159291\n",
       "10    ffd vs cm       357.5  0.850432\n",
       "11    ffd vs dt       157.0  0.045349\n",
       "15     cm vs dt       235.0  0.078696"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wt_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f913a1e4",
   "metadata": {},
   "source": [
    "## 1.2 Accuracy, only CNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8106b10b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "15\n",
      "20\n",
      "20\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "# Preparation: Prepare list of metrics for each discretization (test_list)\n",
    "# Step 1: Obtain accuracy for each discretization, convert into numeric, string values will be return as NaN\n",
    "# Filter for CNB\n",
    "# Obtain accuracy for each discretization, convert into numeric, string values will be return as NaN\n",
    "ewd_acc_cnb = pd.to_numeric(data[(data['disc']==\"EWD\") & (data['models']==\"CNB\")]['accuracy'],errors='coerce').tolist()\n",
    "efd_acc_cnb = pd.to_numeric(data[(data['disc']==\"EFD\") & (data['models']==\"CNB\")]['accuracy'],errors='coerce').tolist()\n",
    "ffd_acc_cnb = pd.to_numeric(data[(data['disc']==\"FFD\") & (data['models']==\"CNB\")]['accuracy'],errors='coerce').tolist()\n",
    "cm_acc_cnb = pd.to_numeric(data[(data['disc']==\"ChiMerge\") & (data['models']==\"CNB\")]['accuracy'],errors='coerce').tolist()\n",
    "dt_acc_cnb = pd.to_numeric(data[(data['disc']==\"DT\") & (data['models']==\"CNB\")]['accuracy'],errors='coerce').tolist()\n",
    "# Check number of metrics available for each discretizer\n",
    "print(len(ewd_acc_cnb))\n",
    "print(len(efd_acc_cnb))\n",
    "print(len(ffd_acc_cnb))\n",
    "print(len(cm_acc_cnb))\n",
    "print(len(dt_acc_cnb))\n",
    "\n",
    "# Step 2: filter numeric values\n",
    "raw_list = [ewd_acc_cnb,efd_acc_cnb, ffd_acc_cnb, cm_acc_cnb, dt_acc_cnb]\n",
    "num_list = [] # filter numeric values only\n",
    "for metric in raw_list:\n",
    "#     metric_new = []\n",
    "#     for x in metric:\n",
    "#         if math.isnan(x) == False:\n",
    "#             metric_new.append(x)\n",
    "    metric_new = [x for x in metric if (math.isnan(x) == False)] # using list comprehension\n",
    "    #print(metric_new)\n",
    "    #print(len(metric_new))\n",
    "    num_list.append(metric_new)\n",
    "    \n",
    "# Step 3: random sample\n",
    "# For discretization methods with different value, randomly select so that the final sample size are equal\n",
    "# Reference: https://docs.python.org/3/library/random.html\n",
    "k = min(len(metric) for metric in num_list)\n",
    "test_list = []\n",
    "for metric in num_list:\n",
    "    random.seed(20)\n",
    "    if len(metric) > k:\n",
    "        metric = random.sample(metric, k=k)\n",
    "    else: metric = metric\n",
    "    #print(metric)\n",
    "    test_list.append(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5307c38f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anhtth/opt/anaconda3/lib/python3.9/site-packages/scipy/stats/morestats.py:3141: UserWarning: Exact p-value calculation does not work if there are ties. Switching to normal approximation.\n",
      "  warnings.warn(\"Exact p-value calculation does not work if there are \"\n"
     ]
    }
   ],
   "source": [
    "# Initialiation\n",
    "disc_key = ['ewd', 'efd', 'ffd', 'cm', 'dt']\n",
    "disc_value = test_list # list of metrics for each discretization after preparation\n",
    "test_stat = []\n",
    "p_value = []\n",
    "disc_compare = []\n",
    "# Create dictionary store discretization and series of accuracy\n",
    "disc = {}\n",
    "for key in disc_key:\n",
    "    for value in disc_value:\n",
    "        disc[key] = value\n",
    "        disc_value.remove(value)\n",
    "        break  \n",
    "\n",
    "# Create loop for Wilcoxon test (two sided) - handle diff = 0\n",
    "for i in disc_key:\n",
    "    for j in disc_key:\n",
    "        if i != j:\n",
    "            disc_compare.append(f'{i} vs {j}')\n",
    "            # print(f'{i} vs {j}')\n",
    "            # Compute difference list\n",
    "            diff_list = []\n",
    "            for m in range(0, len(disc[i])):\n",
    "                diff = disc[i][m] - disc[j][m]\n",
    "                #print(disc[i][m])\n",
    "                #print(disc[j][m])\n",
    "#                 print('diff = ', diff)\n",
    "#                 print('-------------')\n",
    "                diff_list.append(diff)\n",
    "                # print(diff_list)\n",
    "                \n",
    "            if all(item == 0 for item in diff_list) == False: # if the diff list does not contain all 0\n",
    "                test_stat.append(stats.wilcoxon(diff_list).statistic)\n",
    "                p_value.append(stats.wilcoxon(diff_list).pvalue)\n",
    "            else: # if the diff list contain only0, cannot do Wilcoxon test\n",
    "                error = 'N/A'\n",
    "                test_stat.append(error)\n",
    "                p_value.append(error)\n",
    "# print(test_stat)\n",
    "# print(p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c24d6a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 3 lists to dataframe\n",
    "disc_compare = pd.DataFrame(disc_compare, columns=['disc_compare'])\n",
    "test_stat = pd.DataFrame(test_stat, columns=['wtest_stat'])\n",
    "p_value = pd.DataFrame(p_value, columns=['p_value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6c42f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result table\n",
    "wt_result = pd.concat([disc_compare, test_stat, p_value], axis = 1)\n",
    "# Drop duplicate\n",
    "wt_result.drop_duplicates(subset=['p_value'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a7dde02f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disc_compare</th>\n",
       "      <th>wtest_stat</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ewd vs efd</td>\n",
       "      <td>38.5</td>\n",
       "      <td>0.968700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ewd vs ffd</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ewd vs cm</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.151205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ewd vs dt</td>\n",
       "      <td>36.5</td>\n",
       "      <td>0.325806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>efd vs cm</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.100317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>efd vs dt</td>\n",
       "      <td>23.5</td>\n",
       "      <td>0.123830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ffd vs cm</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.390991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ffd vs dt</td>\n",
       "      <td>26.5</td>\n",
       "      <td>0.326613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>cm vs dt</td>\n",
       "      <td>21.5</td>\n",
       "      <td>0.305838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>dt vs ewd</td>\n",
       "      <td>36.5</td>\n",
       "      <td>0.357544</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   disc_compare  wtest_stat   p_value\n",
       "0    ewd vs efd        38.5  0.968700\n",
       "1    ewd vs ffd        52.0  1.000000\n",
       "2     ewd vs cm        25.0  0.151205\n",
       "3     ewd vs dt        36.5  0.325806\n",
       "6     efd vs cm        22.0  0.100317\n",
       "7     efd vs dt        23.5  0.123830\n",
       "10    ffd vs cm        38.0  0.390991\n",
       "11    ffd vs dt        26.5  0.326613\n",
       "15     cm vs dt        21.5  0.305838\n",
       "16    dt vs ewd        36.5  0.357544"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wt_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da97b22e",
   "metadata": {},
   "source": [
    "## 1.2 Accuracy, only ID3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a3a4c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "15\n",
      "20\n",
      "20\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "# Preparation: Prepare list of metrics for each discretization (test_list)\n",
    "# Step 1: Obtain accuracy for each discretization, convert into numeric, string values will be return as NaN\n",
    "# Filter for ID3\n",
    "# Obtain accuracy for each discretization, convert into numeric, string values will be return as NaN\n",
    "ewd_acc_ID3 = pd.to_numeric(data[(data['disc']==\"EWD\") & (data['models']==\"ID3\")]['accuracy'],errors='coerce').tolist()\n",
    "efd_acc_ID3 = pd.to_numeric(data[(data['disc']==\"EFD\") & (data['models']==\"ID3\")]['accuracy'],errors='coerce').tolist()\n",
    "ffd_acc_ID3 = pd.to_numeric(data[(data['disc']==\"FFD\") & (data['models']==\"ID3\")]['accuracy'],errors='coerce').tolist()\n",
    "cm_acc_ID3 = pd.to_numeric(data[(data['disc']==\"ChiMerge\") & (data['models']==\"ID3\")]['accuracy'],errors='coerce').tolist()\n",
    "dt_acc_ID3 = pd.to_numeric(data[(data['disc']==\"DT\") & (data['models']==\"ID3\")]['accuracy'],errors='coerce').tolist()\n",
    "# Check number of metrics available for each discretizer\n",
    "print(len(ewd_acc_ID3))\n",
    "print(len(efd_acc_ID3))\n",
    "print(len(ffd_acc_ID3))\n",
    "print(len(cm_acc_ID3))\n",
    "print(len(dt_acc_ID3))\n",
    "\n",
    "# Step 2: filter numeric values\n",
    "raw_list = [ewd_acc_ID3,efd_acc_ID3, ffd_acc_ID3, cm_acc_ID3, dt_acc_ID3]\n",
    "num_list = [] # filter numeric values only\n",
    "for metric in raw_list:\n",
    "#     metric_new = []\n",
    "#     for x in metric:\n",
    "#         if math.isnan(x) == False:\n",
    "#             metric_new.append(x)\n",
    "    metric_new = [x for x in metric if (math.isnan(x) == False)] # using list comprehension\n",
    "    #print(metric_new)\n",
    "    #print(len(metric_new))\n",
    "    num_list.append(metric_new)\n",
    "    \n",
    "# Step 3: random sample\n",
    "# For discretization methods with different value, randomly select so that the final sample size are equal\n",
    "# Reference: https://docs.python.org/3/library/random.html\n",
    "k = min(len(metric) for metric in num_list)\n",
    "test_list = []\n",
    "for metric in num_list:\n",
    "    random.seed(20)\n",
    "    if len(metric) > k:\n",
    "        metric = random.sample(metric, k=k)\n",
    "    else: metric = metric\n",
    "    #print(metric)\n",
    "    test_list.append(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4be48448",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anhtth/opt/anaconda3/lib/python3.9/site-packages/scipy/stats/morestats.py:3141: UserWarning: Exact p-value calculation does not work if there are ties. Switching to normal approximation.\n",
      "  warnings.warn(\"Exact p-value calculation does not work if there are \"\n",
      "/Users/anhtth/opt/anaconda3/lib/python3.9/site-packages/scipy/stats/morestats.py:3155: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    }
   ],
   "source": [
    "# Initialiation\n",
    "disc_key = ['ewd', 'efd', 'ffd', 'cm', 'dt']\n",
    "disc_value = test_list # list of metrics for each discretization after preparation\n",
    "test_stat = []\n",
    "p_value = []\n",
    "disc_compare = []\n",
    "# Create dictionary store discretization and series of accuracy\n",
    "disc = {}\n",
    "for key in disc_key:\n",
    "    for value in disc_value:\n",
    "        disc[key] = value\n",
    "        disc_value.remove(value)\n",
    "        break  \n",
    "\n",
    "# Create loop for Wilcoxon test (two sided) - handle diff = 0\n",
    "for i in disc_key:\n",
    "    for j in disc_key:\n",
    "        if i != j:\n",
    "            disc_compare.append(f'{i} vs {j}')\n",
    "            # print(f'{i} vs {j}')\n",
    "            # Compute difference list\n",
    "            diff_list = []\n",
    "            for m in range(0, len(disc[i])):\n",
    "                diff = disc[i][m] - disc[j][m]\n",
    "                #print(disc[i][m])\n",
    "                #print(disc[j][m])\n",
    "#                 print('diff = ', diff)\n",
    "#                 print('-------------')\n",
    "                diff_list.append(diff)\n",
    "                # print(diff_list)\n",
    "                \n",
    "            if all(item == 0 for item in diff_list) == False: # if the diff list does not contain all 0\n",
    "                test_stat.append(stats.wilcoxon(diff_list).statistic)\n",
    "                p_value.append(stats.wilcoxon(diff_list).pvalue)\n",
    "            else: # if the diff list contain only0, cannot do Wilcoxon test\n",
    "                error = 'N/A'\n",
    "                test_stat.append(error)\n",
    "                p_value.append(error)\n",
    "# print(test_stat)\n",
    "# print(p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "edaa296d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 3 lists to dataframe\n",
    "disc_compare = pd.DataFrame(disc_compare, columns=['disc_compare'])\n",
    "test_stat = pd.DataFrame(test_stat, columns=['wtest_stat'])\n",
    "p_value = pd.DataFrame(p_value, columns=['p_value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "401dfa3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result table\n",
    "wt_result = pd.concat([disc_compare, test_stat, p_value], axis = 1)\n",
    "# Drop duplicate\n",
    "wt_result.drop_duplicates(subset=['p_value'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0edd8d64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disc_compare</th>\n",
       "      <th>wtest_stat</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ewd vs efd</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.778106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ewd vs ffd</td>\n",
       "      <td>41.5</td>\n",
       "      <td>0.302795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ewd vs cm</td>\n",
       "      <td>29.5</td>\n",
       "      <td>0.263348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ewd vs dt</td>\n",
       "      <td>18.5</td>\n",
       "      <td>0.015076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>efd vs ffd</td>\n",
       "      <td>39.5</td>\n",
       "      <td>0.252380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>efd vs cm</td>\n",
       "      <td>27.5</td>\n",
       "      <td>0.207996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>efd vs dt</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.030151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ffd vs ewd</td>\n",
       "      <td>41.5</td>\n",
       "      <td>0.330261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ffd vs efd</td>\n",
       "      <td>39.5</td>\n",
       "      <td>0.276855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ffd vs cm</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.952260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ffd vs dt</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.063462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>cm vs dt</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.120544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>dt vs ewd</td>\n",
       "      <td>18.5</td>\n",
       "      <td>0.018066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   disc_compare  wtest_stat   p_value\n",
       "0    ewd vs efd        16.0  0.778106\n",
       "1    ewd vs ffd        41.5  0.302795\n",
       "2     ewd vs cm        29.5  0.263348\n",
       "3     ewd vs dt        18.5  0.015076\n",
       "5    efd vs ffd        39.5  0.252380\n",
       "6     efd vs cm        27.5  0.207996\n",
       "7     efd vs dt        22.0  0.030151\n",
       "8    ffd vs ewd        41.5  0.330261\n",
       "9    ffd vs efd        39.5  0.276855\n",
       "10    ffd vs cm        22.0  0.952260\n",
       "11    ffd vs dt        19.0  0.063462\n",
       "15     cm vs dt        32.0  0.120544\n",
       "16    dt vs ewd        18.5  0.018066"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wt_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0751228c",
   "metadata": {},
   "source": [
    "## 1.2 Accuracy, only KNN-VDM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7f924ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "15\n",
      "20\n",
      "20\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "# Preparation: Prepare list of metrics for each discretization (test_list)\n",
    "# Step 1: Obtain accuracy for each discretization, convert into numeric, string values will be return as NaN\n",
    "# Filter for Knn-VDM\n",
    "# Obtain accuracy for each discretization, convert into numeric, string values will be return as NaN\n",
    "ewd_acc_knn = pd.to_numeric(data[(data['disc']==\"EWD\") & (data['models']==\"Knn-VDM\")]['accuracy'],errors='coerce').tolist()\n",
    "efd_acc_knn = pd.to_numeric(data[(data['disc']==\"EFD\") & (data['models']==\"Knn-VDM\")]['accuracy'],errors='coerce').tolist()\n",
    "ffd_acc_knn = pd.to_numeric(data[(data['disc']==\"FFD\") & (data['models']==\"Knn-VDM\")]['accuracy'],errors='coerce').tolist()\n",
    "cm_acc_knn = pd.to_numeric(data[(data['disc']==\"ChiMerge\") & (data['models']==\"Knn-VDM\")]['accuracy'],errors='coerce').tolist()\n",
    "dt_acc_knn = pd.to_numeric(data[(data['disc']==\"ChiMerge\") & (data['models']==\"Knn-VDM\")]['accuracy'],errors='coerce').tolist()\n",
    "\n",
    "# Check number of metrics available for each discretizer\n",
    "print(len(ewd_acc_knn))\n",
    "print(len(efd_acc_knn))\n",
    "print(len(ffd_acc_knn))\n",
    "print(len(cm_acc_knn))\n",
    "print(len(dt_acc_knn))\n",
    "\n",
    "# Step 2: filter numeric values\n",
    "raw_list = [ewd_acc_knn,efd_acc_knn, ffd_acc_knn, cm_acc_knn, dt_acc_knn]\n",
    "num_list = [] # filter numeric values only\n",
    "for metric in raw_list:\n",
    "#     metric_new = []\n",
    "#     for x in metric:\n",
    "#         if math.isnan(x) == False:\n",
    "#             metric_new.append(x)\n",
    "    metric_new = [x for x in metric if (math.isnan(x) == False)] # using list comprehension\n",
    "    #print(metric_new)\n",
    "    #print(len(metric_new))\n",
    "    num_list.append(metric_new)\n",
    "    \n",
    "# Step 3: random sample\n",
    "# For discretization methods with different value, randomly select so that the final sample size are equal\n",
    "# Reference: https://docs.python.org/3/library/random.html\n",
    "k = min(len(metric) for metric in num_list)\n",
    "test_list = []\n",
    "for metric in num_list:\n",
    "    random.seed(20)\n",
    "    if len(metric) > k:\n",
    "        metric = random.sample(metric, k=k)\n",
    "    else: metric = metric\n",
    "    #print(metric)\n",
    "    test_list.append(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dbd8b869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.87, 0.97, 0.95, 0.83, 0.89, 0.91, 0.79, 0.77, 0.68], [0.92, 0.95, 0.95, 0.89, 0.87, 0.92, 0.92, 0.92, 0.77, 0.77, 0.77, 0.68, 0.7, 0.71], [0.97, 0.95, 0.84, 0.84, 0.77, 0.8, 0.79, 0.81, 0.71, 0.71, 0.69, 0.68], [0.95, 0.95, 0.31, 0.23, 0.22, 0.22, 0.91, 0.9, 0.91, 0.88, 0.71, 0.8, 0.77, 0.79], [0.95, 0.95, 0.31, 0.23, 0.22, 0.22, 0.91, 0.9, 0.91, 0.88, 0.71, 0.8, 0.77, 0.79]]\n"
     ]
    }
   ],
   "source": [
    "print(num_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0bd52114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c35b52f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.87, 0.97, 0.95, 0.83, 0.89, 0.91, 0.79, 0.77, 0.68], [0.68, 0.77, 0.95, 0.87, 0.95, 0.92, 0.71, 0.92, 0.89], [0.68, 0.69, 0.84, 0.77, 0.95, 0.79, 0.71, 0.71, 0.81], [0.8, 0.71, 0.31, 0.22, 0.95, 0.22, 0.79, 0.95, 0.23], [0.8, 0.71, 0.31, 0.22, 0.95, 0.22, 0.79, 0.95, 0.23]]\n"
     ]
    }
   ],
   "source": [
    "print(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "03a78dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(len(test_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8c005139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialiation\n",
    "disc_key = ['ewd', 'efd', 'ffd', 'cm', 'dt']\n",
    "disc_value = test_list # list of metrics for each discretization after preparation\n",
    "test_stat = []\n",
    "p_value = []\n",
    "disc_compare = []\n",
    "# Create dictionary store discretization and series of accuracy\n",
    "disc = {}\n",
    "for key in disc_key:\n",
    "    for value in disc_value:\n",
    "        disc[key] = value\n",
    "        disc_value.remove(value)\n",
    "        break  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "889fa084",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anhtth/opt/anaconda3/lib/python3.9/site-packages/scipy/stats/morestats.py:3141: UserWarning: Exact p-value calculation does not work if there are ties. Switching to normal approximation.\n",
      "  warnings.warn(\"Exact p-value calculation does not work if there are \"\n",
      "/Users/anhtth/opt/anaconda3/lib/python3.9/site-packages/scipy/stats/morestats.py:3155: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    }
   ],
   "source": [
    "# Create loop for Wilcoxon test (two sided)\n",
    "for i in disc_key:\n",
    "    for j in disc_key:\n",
    "        if i != j:\n",
    "            disc_compare.append(f'{i} vs {j}')\n",
    "            # print(f'{i} vs {j}')\n",
    "            # Compute difference list\n",
    "            diff_list = []\n",
    "            for m in range(0, len(disc[i])):\n",
    "                diff = disc[i][m] - disc[j][m]\n",
    "#                 print(disc[i][m])\n",
    "#                 print(disc[j][m])\n",
    "#                 print('diff = ', diff)\n",
    "#                 print('-------------')\n",
    "                diff_list.append(diff)\n",
    "                # print(diff_list)\n",
    "                \n",
    "            if all(item == 0 for item in diff_list) == False: # if the diff list does not contain all 0\n",
    "                test_stat.append(stats.wilcoxon(diff_list).statistic)\n",
    "                p_value.append(stats.wilcoxon(diff_list).pvalue)\n",
    "            else: # if the diff list contain only0, cannot do Wilcoxon test\n",
    "                error = 'N/A'\n",
    "                test_stat.append(error)\n",
    "                p_value.append(error)\n",
    "# print(test_stat)\n",
    "# print(p_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a31e4d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 3 lists to dataframe\n",
    "disc_compare = pd.DataFrame(disc_compare, columns=['disc_compare'])\n",
    "test_stat = pd.DataFrame(test_stat, columns=['wtest_stat'])\n",
    "p_value = pd.DataFrame(p_value, columns=['p_value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3e8b0807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result table\n",
    "wt_result = pd.concat([disc_compare, test_stat, p_value], axis = 1)\n",
    "# Drop duplicate\n",
    "wt_result.drop_duplicates(subset=['p_value'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c2e41873",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disc_compare</th>\n",
       "      <th>wtest_stat</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ewd vs efd</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.888638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ewd vs ffd</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.128906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ewd vs cm</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.04995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>efd vs ffd</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.027708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>efd vs cm</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.161429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ffd vs ewd</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.097656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ffd vs cm</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.262618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>cm vs dt</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   disc_compare wtest_stat   p_value\n",
       "0    ewd vs efd       17.0  0.888638\n",
       "1    ewd vs ffd        8.5  0.128906\n",
       "2     ewd vs cm        4.0   0.04995\n",
       "5    efd vs ffd        0.0  0.027708\n",
       "6     efd vs cm        8.0  0.161429\n",
       "8    ffd vs ewd        8.5  0.097656\n",
       "10    ffd vs cm       10.0  0.262618\n",
       "15     cm vs dt        N/A       N/A"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wt_result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
