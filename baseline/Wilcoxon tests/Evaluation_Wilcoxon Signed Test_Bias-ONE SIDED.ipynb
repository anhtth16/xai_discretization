{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e739595",
   "metadata": {},
   "source": [
    "# Wilcoxon SIGNED test-BIAS\n",
    "By: Sam<br>\n",
    "Updated at: 07/11/2022, performed ONE SIDED, less <br>\n",
    "Compare performance of discretizers <br>\n",
    "Matched pairs settings\n",
    "Sample: 270 ML models after discretization (as at 16/10/2022)\n",
    "Purpose: pair-wise comparison metrics of the models using different discretization method\n",
    "\n",
    "===\n",
    "\n",
    "Input data: instrinsic properties and model performance metrics\n",
    "!!! **NB: Please update the data for metrics and export to csv before running this script!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1810bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5845bab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import evaluation data (updated at 16/10/2022)\n",
    "data = pd.read_csv(\"all_evaluation_161022.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e6fd0c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>disc</th>\n",
       "      <th>param</th>\n",
       "      <th>inconsistency</th>\n",
       "      <th>models</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>con_features</th>\n",
       "      <th>time_disc</th>\n",
       "      <th>time_train</th>\n",
       "      <th>bias</th>\n",
       "      <th>variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iris</td>\n",
       "      <td>EWD</td>\n",
       "      <td>4</td>\n",
       "      <td>0.06666667</td>\n",
       "      <td>ID3</td>\n",
       "      <td>0.84</td>\n",
       "      <td>4</td>\n",
       "      <td>0.016412</td>\n",
       "      <td>0.008698225</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>iris</td>\n",
       "      <td>EWD</td>\n",
       "      <td>7</td>\n",
       "      <td>0.02</td>\n",
       "      <td>ID3</td>\n",
       "      <td>0.79</td>\n",
       "      <td>4</td>\n",
       "      <td>0.015692</td>\n",
       "      <td>0.010634899</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>iris</td>\n",
       "      <td>EWD</td>\n",
       "      <td>10</td>\n",
       "      <td>0.006666667</td>\n",
       "      <td>ID3</td>\n",
       "      <td>0.95</td>\n",
       "      <td>4</td>\n",
       "      <td>0.016380</td>\n",
       "      <td>0.010643005</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>iris</td>\n",
       "      <td>EFD</td>\n",
       "      <td>4</td>\n",
       "      <td>0.04</td>\n",
       "      <td>ID3</td>\n",
       "      <td>0.84</td>\n",
       "      <td>4</td>\n",
       "      <td>0.016688</td>\n",
       "      <td>0.009439945</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>iris</td>\n",
       "      <td>EFD</td>\n",
       "      <td>7</td>\n",
       "      <td>0.04</td>\n",
       "      <td>ID3</td>\n",
       "      <td>0.95</td>\n",
       "      <td>4</td>\n",
       "      <td>0.023941</td>\n",
       "      <td>0.010675907</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset disc  param inconsistency models accuracy  con_features  time_disc  \\\n",
       "0    iris  EWD      4    0.06666667    ID3     0.84             4   0.016412   \n",
       "1    iris  EWD      7          0.02    ID3     0.79             4   0.015692   \n",
       "2    iris  EWD     10   0.006666667    ID3     0.95             4   0.016380   \n",
       "3    iris  EFD      4          0.04    ID3     0.84             4   0.016688   \n",
       "4    iris  EFD      7          0.04    ID3     0.95             4   0.023941   \n",
       "\n",
       "    time_train   bias variance  \n",
       "0  0.008698225  0.158    0.055  \n",
       "1  0.010634899  0.158    0.054  \n",
       "2  0.010643005  0.053    0.014  \n",
       "3  0.009439945  0.158    0.049  \n",
       "4  0.010675907  0.053     0.07  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb690ad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['EWD', 'EFD', 'FFD', 'ChiMerge', 'DT'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['disc'].unique() # get list of discretizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82abae21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['dataset', 'disc', 'param', 'inconsistency', 'models', 'accuracy',\n",
       "       'con_features', 'time_disc', 'time_train', 'bias', 'variance'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4baafad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 270 entries, 0 to 269\n",
      "Data columns (total 11 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   dataset        270 non-null    object \n",
      " 1   disc           270 non-null    object \n",
      " 2   param          270 non-null    int64  \n",
      " 3   inconsistency  270 non-null    object \n",
      " 4   models         270 non-null    object \n",
      " 5   accuracy       270 non-null    object \n",
      " 6   con_features   270 non-null    int64  \n",
      " 7   time_disc      270 non-null    float64\n",
      " 8   time_train     269 non-null    object \n",
      " 9   bias           234 non-null    object \n",
      " 10  variance       234 non-null    object \n",
      "dtypes: float64(1), int64(2), object(8)\n",
      "memory usage: 23.3+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4cf2753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ID3', 'CNB', 'Knn-VDM'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['models'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5daa08",
   "metadata": {},
   "source": [
    "# Wilcoxon_Complete pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ae483f",
   "metadata": {},
   "source": [
    "## 1.  Wilcoxon signed t test, bias\n",
    "Ref: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.wilcoxon.html\n",
    "Implement 4 replications: (DONE)\n",
    "- Regardless algorithms\n",
    "- Filter for each algorithm: CNB, ID3, Knn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9a9c06",
   "metadata": {},
   "source": [
    "## 1. 1 Bias, no filter in algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "869664de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparation: Prepare list of metrics for each discretization (test_list)\n",
    "# Step 1: Obtain bias for each discretization, convert into numeric, string values will be return as NaN\n",
    "ewd_bias = pd.to_numeric(data[data['disc']==\"EWD\"]['bias'],errors='coerce').tolist()\n",
    "efd_bias = pd.to_numeric(data[data['disc']==\"EFD\"]['bias'],errors='coerce').tolist()\n",
    "ffd_bias = pd.to_numeric(data[data['disc']==\"FFD\"]['bias'],errors='coerce').tolist()\n",
    "cm_bias = pd.to_numeric(data[data['disc']==\"ChiMerge\"]['bias'],errors='coerce').tolist()\n",
    "dt_bias = pd.to_numeric(data[data['disc']==\"DT\"]['bias'],errors='coerce').tolist()\n",
    "# Check number of metrics available for each discretizer\n",
    "# print(len(ewd_bias))\n",
    "# print(len(efd_bias))\n",
    "# print(len(ffd_bias))\n",
    "# print(len(cm_bias))\n",
    "# print(len(dt_bias))\n",
    "\n",
    "# Step 2: filter numeric values\n",
    "raw_list = [ewd_bias, efd_bias, ffd_bias, cm_bias, dt_bias]\n",
    "num_list = [] # filter numeric values only\n",
    "for metric in raw_list:\n",
    "#     metric_new = []\n",
    "#     for x in metric:\n",
    "#         if math.isnan(x) == False:\n",
    "#             metric_new.append(x)\n",
    "    metric_new = [x for x in metric if (math.isnan(x) == False)] # using list comprehension\n",
    "    #print(metric_new)\n",
    "    #print(len(metric_new))\n",
    "    num_list.append(metric_new)\n",
    "    \n",
    "# Step 3: random sample\n",
    "# For discretization methods with different value, randomly select so that the final sample size are equal\n",
    "# Reference: https://docs.python.org/3/library/random.html\n",
    "k = min(len(metric) for metric in num_list)\n",
    "test_list = []\n",
    "for metric in num_list:\n",
    "    random.seed(20)\n",
    "    if len(metric) > k:\n",
    "        metric = random.sample(metric, k=k)\n",
    "    else: metric = metric\n",
    "    #print(metric)\n",
    "    test_list.append(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "515b974e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialiation\n",
    "disc_key = ['ewd', 'efd', 'ffd', 'cm', 'dt']\n",
    "disc_value = test_list # list of metrics for each discretization after preparation\n",
    "test_stat = []\n",
    "p_value = []\n",
    "disc_compare = []\n",
    "# Create dictionary store discretization and series of accuracy\n",
    "disc = {}\n",
    "for key in disc_key:\n",
    "    for value in disc_value:\n",
    "        disc[key] = value\n",
    "        disc_value.remove(value)\n",
    "        break  \n",
    "\n",
    "# Create loop for Wilcoxon test (two sided) - handle diff = 0\n",
    "for i in disc_key:\n",
    "    for j in disc_key:\n",
    "        if i != j:\n",
    "            disc_compare.append(f'{i} vs {j}')\n",
    "            # print(f'{i} vs {j}')\n",
    "            # Compute difference list\n",
    "            diff_list = []\n",
    "            for m in range(0, len(disc[i])):\n",
    "                diff = disc[i][m] - disc[j][m]\n",
    "                #print(disc[i][m])\n",
    "                #print(disc[j][m])\n",
    "#                 print('diff = ', diff)\n",
    "#                 print('-------------')\n",
    "                diff_list.append(diff)\n",
    "                # print(diff_list)\n",
    "                \n",
    "            if all(item == 0 for item in diff_list) == False: # if the diff list does not contain all 0\n",
    "                test_stat.append(stats.wilcoxon(diff_list, alternative = \"less\").statistic)\n",
    "                p_value.append(stats.wilcoxon(diff_list, alternative = \"less\").pvalue)\n",
    "            else: # if the diff list contain only0, cannot do Wilcoxon test\n",
    "                error = 'N/A'\n",
    "                test_stat.append(error)\n",
    "                p_value.append(error)\n",
    "# print(test_stat)\n",
    "# print(p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc96320d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 3 lists to dataframe\n",
    "disc_compare = pd.DataFrame(disc_compare, columns=['disc_compare'])\n",
    "test_stat = pd.DataFrame(test_stat, columns=['wtest_stat'])\n",
    "p_value = pd.DataFrame(p_value, columns=['p_value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba3aa4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result table\n",
    "wt_result = pd.concat([disc_compare, test_stat, p_value], axis = 1)\n",
    "# Drop duplicate\n",
    "wt_result.drop_duplicates(subset=['p_value'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8d38811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disc_compare</th>\n",
       "      <th>wtest_stat</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ewd vs efd</td>\n",
       "      <td>251.5</td>\n",
       "      <td>0.407585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ewd vs ffd</td>\n",
       "      <td>201.0</td>\n",
       "      <td>0.119392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ewd vs cm</td>\n",
       "      <td>294.0</td>\n",
       "      <td>0.595310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ewd vs dt</td>\n",
       "      <td>342.5</td>\n",
       "      <td>0.866032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>efd vs ewd</td>\n",
       "      <td>276.5</td>\n",
       "      <td>0.592415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>efd vs ffd</td>\n",
       "      <td>240.0</td>\n",
       "      <td>0.326797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>efd vs cm</td>\n",
       "      <td>279.5</td>\n",
       "      <td>0.614035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>efd vs dt</td>\n",
       "      <td>309.0</td>\n",
       "      <td>0.884044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ffd vs ewd</td>\n",
       "      <td>327.0</td>\n",
       "      <td>0.880608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ffd vs efd</td>\n",
       "      <td>288.0</td>\n",
       "      <td>0.673203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ffd vs cm</td>\n",
       "      <td>292.0</td>\n",
       "      <td>0.699711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ffd vs dt</td>\n",
       "      <td>404.0</td>\n",
       "      <td>0.995576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>cm vs ewd</td>\n",
       "      <td>267.0</td>\n",
       "      <td>0.404690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>cm vs efd</td>\n",
       "      <td>248.5</td>\n",
       "      <td>0.385965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>cm vs ffd</td>\n",
       "      <td>236.0</td>\n",
       "      <td>0.300289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>cm vs dt</td>\n",
       "      <td>350.0</td>\n",
       "      <td>0.892847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>dt vs ewd</td>\n",
       "      <td>218.5</td>\n",
       "      <td>0.133968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>dt vs efd</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.115956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>dt vs ffd</td>\n",
       "      <td>124.0</td>\n",
       "      <td>0.004424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>dt vs cm</td>\n",
       "      <td>211.0</td>\n",
       "      <td>0.107153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   disc_compare  wtest_stat   p_value\n",
       "0    ewd vs efd       251.5  0.407585\n",
       "1    ewd vs ffd       201.0  0.119392\n",
       "2     ewd vs cm       294.0  0.595310\n",
       "3     ewd vs dt       342.5  0.866032\n",
       "4    efd vs ewd       276.5  0.592415\n",
       "5    efd vs ffd       240.0  0.326797\n",
       "6     efd vs cm       279.5  0.614035\n",
       "7     efd vs dt       309.0  0.884044\n",
       "8    ffd vs ewd       327.0  0.880608\n",
       "9    ffd vs efd       288.0  0.673203\n",
       "10    ffd vs cm       292.0  0.699711\n",
       "11    ffd vs dt       404.0  0.995576\n",
       "12    cm vs ewd       267.0  0.404690\n",
       "13    cm vs efd       248.5  0.385965\n",
       "14    cm vs ffd       236.0  0.300289\n",
       "15     cm vs dt       350.0  0.892847\n",
       "16    dt vs ewd       218.5  0.133968\n",
       "17    dt vs efd       187.0  0.115956\n",
       "18    dt vs ffd       124.0  0.004424\n",
       "19     dt vs cm       211.0  0.107153"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wt_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99d63a0",
   "metadata": {},
   "source": [
    "## 1.2 Bias, only CNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1640550e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "15\n",
      "20\n",
      "20\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "# Preparation: Prepare list of metrics for each discretization (test_list)\n",
    "# Step 1: Obtain bias for each discretization, convert into numeric, string values will be return as NaN\n",
    "# Filter for CNB\n",
    "# Obtain bias for each discretization, convert into numeric, string values will be return as NaN\n",
    "ewd_bias_cnb = pd.to_numeric(data[(data['disc']==\"EWD\") & (data['models']==\"CNB\")]['bias'],errors='coerce').tolist()\n",
    "efd_bias_cnb = pd.to_numeric(data[(data['disc']==\"EFD\") & (data['models']==\"CNB\")]['bias'],errors='coerce').tolist()\n",
    "ffd_bias_cnb = pd.to_numeric(data[(data['disc']==\"FFD\") & (data['models']==\"CNB\")]['bias'],errors='coerce').tolist()\n",
    "cm_bias_cnb = pd.to_numeric(data[(data['disc']==\"ChiMerge\") & (data['models']==\"CNB\")]['bias'],errors='coerce').tolist()\n",
    "dt_bias_cnb = pd.to_numeric(data[(data['disc']==\"DT\") & (data['models']==\"CNB\")]['bias'],errors='coerce').tolist()\n",
    "# Check number of metrics available for each discretizer\n",
    "print(len(ewd_bias_cnb))\n",
    "print(len(efd_bias_cnb))\n",
    "print(len(ffd_bias_cnb))\n",
    "print(len(cm_bias_cnb))\n",
    "print(len(dt_bias_cnb))\n",
    "\n",
    "# Step 2: filter numeric values\n",
    "raw_list = [ewd_bias_cnb,efd_bias_cnb, ffd_bias_cnb, cm_bias_cnb, dt_bias_cnb]\n",
    "num_list = [] # filter numeric values only\n",
    "for metric in raw_list:\n",
    "#     metric_new = []\n",
    "#     for x in metric:\n",
    "#         if math.isnan(x) == False:\n",
    "#             metric_new.append(x)\n",
    "    metric_new = [x for x in metric if (math.isnan(x) == False)] # using list comprehension\n",
    "    #print(metric_new)\n",
    "    #print(len(metric_new))\n",
    "    num_list.append(metric_new)\n",
    "    \n",
    "# Step 3: random sample\n",
    "# For discretization methods with different value, randomly select so that the final sample size are equal\n",
    "# Reference: https://docs.python.org/3/library/random.html\n",
    "k = min(len(metric) for metric in num_list)\n",
    "test_list = []\n",
    "for metric in num_list:\n",
    "    random.seed(20)\n",
    "    if len(metric) > k:\n",
    "        metric = random.sample(metric, k=k)\n",
    "    else: metric = metric\n",
    "    #print(metric)\n",
    "    test_list.append(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d65033f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialiation\n",
    "disc_key = ['ewd', 'efd', 'ffd', 'cm', 'dt']\n",
    "disc_value = test_list # list of metrics for each discretization after preparation\n",
    "test_stat = []\n",
    "p_value = []\n",
    "disc_compare = []\n",
    "# Create dictionary store discretization and series of accuracy\n",
    "disc = {}\n",
    "for key in disc_key:\n",
    "    for value in disc_value:\n",
    "        disc[key] = value\n",
    "        disc_value.remove(value)\n",
    "        break  \n",
    "\n",
    "# Create loop for Wilcoxon test (two sided) - handle diff = 0\n",
    "for i in disc_key:\n",
    "    for j in disc_key:\n",
    "        if i != j:\n",
    "            disc_compare.append(f'{i} vs {j}')\n",
    "            # print(f'{i} vs {j}')\n",
    "            # Compute difference list\n",
    "            diff_list = []\n",
    "            for m in range(0, len(disc[i])):\n",
    "                # diff = disc[i][m] - disc[j][m]\n",
    "                #print(disc[i][m])\n",
    "                #print(disc[j][m])\n",
    "#                 print('diff = ', diff)\n",
    "#                 print('-------------')\n",
    "                diff_list.append(diff)\n",
    "                # print(diff_list)\n",
    "                \n",
    "            if all(item == 0 for item in diff_list) == False: # if the diff list does not contain all 0\n",
    "                test_stat.append(stats.wilcoxon(diff_list, alternative = \"less\").statistic)\n",
    "                p_value.append(stats.wilcoxon(diff_list, alternative = \"less\").pvalue)\n",
    "            else: # if the diff list contain only0, cannot do Wilcoxon test\n",
    "                error = 'N/A'\n",
    "                test_stat.append(error)\n",
    "                p_value.append(error)\n",
    "# print(test_stat)\n",
    "# print(p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31f217db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 3 lists to dataframe\n",
    "disc_compare = pd.DataFrame(disc_compare, columns=['disc_compare'])\n",
    "test_stat = pd.DataFrame(test_stat, columns=['wtest_stat'])\n",
    "p_value = pd.DataFrame(p_value, columns=['p_value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff112ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result table\n",
    "wt_result = pd.concat([disc_compare, test_stat, p_value], axis = 1)\n",
    "# Drop duplicate\n",
    "wt_result.drop_duplicates(subset=['p_value'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "394d5633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disc_compare</th>\n",
       "      <th>wtest_stat</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ewd vs efd</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  disc_compare  wtest_stat   p_value\n",
       "0   ewd vs efd         0.0  0.000244"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wt_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4069c86d",
   "metadata": {},
   "source": [
    "## 1.2 Bias, only ID3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8981b526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "15\n",
      "20\n",
      "20\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "# Preparation: Prepare list of metrics for each discretization (test_list)\n",
    "# Step 1: Obtain bias for each discretization, convert into numeric, string values will be return as NaN\n",
    "# Filter for ID3\n",
    "# Obtain bias for each discretization, convert into numeric, string values will be return as NaN\n",
    "ewd_bias_ID3 = pd.to_numeric(data[(data['disc']==\"EWD\") & (data['models']==\"ID3\")]['bias'],errors='coerce').tolist()\n",
    "efd_bias_ID3 = pd.to_numeric(data[(data['disc']==\"EFD\") & (data['models']==\"ID3\")]['bias'],errors='coerce').tolist()\n",
    "ffd_bias_ID3 = pd.to_numeric(data[(data['disc']==\"FFD\") & (data['models']==\"ID3\")]['bias'],errors='coerce').tolist()\n",
    "cm_bias_ID3 = pd.to_numeric(data[(data['disc']==\"ChiMerge\") & (data['models']==\"ID3\")]['bias'],errors='coerce').tolist()\n",
    "dt_bias_ID3 = pd.to_numeric(data[(data['disc']==\"DT\") & (data['models']==\"ID3\")]['bias'],errors='coerce').tolist()\n",
    "# Check number of metrics available for each discretizer\n",
    "print(len(ewd_bias_ID3))\n",
    "print(len(efd_bias_ID3))\n",
    "print(len(ffd_bias_ID3))\n",
    "print(len(cm_bias_ID3))\n",
    "print(len(dt_bias_ID3))\n",
    "\n",
    "# Step 2: filter numeric values\n",
    "raw_list = [ewd_bias_ID3,efd_bias_ID3, ffd_bias_ID3, cm_bias_ID3, dt_bias_ID3]\n",
    "num_list = [] # filter numeric values only\n",
    "for metric in raw_list:\n",
    "#     metric_new = []\n",
    "#     for x in metric:\n",
    "#         if math.isnan(x) == False:\n",
    "#             metric_new.append(x)\n",
    "    metric_new = [x for x in metric if (math.isnan(x) == False)] # using list comprehension\n",
    "    #print(metric_new)\n",
    "    #print(len(metric_new))\n",
    "    num_list.append(metric_new)\n",
    "    \n",
    "# Step 3: random sample\n",
    "# For discretization methods with different value, randomly select so that the final sample size are equal\n",
    "# Reference: https://docs.python.org/3/library/random.html\n",
    "k = min(len(metric) for metric in num_list)\n",
    "test_list = []\n",
    "for metric in num_list:\n",
    "    random.seed(20)\n",
    "    if len(metric) > k:\n",
    "        metric = random.sample(metric, k=k)\n",
    "    else: metric = metric\n",
    "    #print(metric)\n",
    "    test_list.append(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20b9c57b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anhtth/opt/anaconda3/lib/python3.9/site-packages/scipy/stats/morestats.py:3141: UserWarning: Exact p-value calculation does not work if there are ties. Switching to normal approximation.\n",
      "  warnings.warn(\"Exact p-value calculation does not work if there are \"\n"
     ]
    }
   ],
   "source": [
    "# Initialiation\n",
    "disc_key = ['ewd', 'efd', 'ffd', 'cm', 'dt']\n",
    "disc_value = test_list # list of metrics for each discretization after preparation\n",
    "test_stat = []\n",
    "p_value = []\n",
    "disc_compare = []\n",
    "# Create dictionary store discretization and series of accuracy\n",
    "disc = {}\n",
    "for key in disc_key:\n",
    "    for value in disc_value:\n",
    "        disc[key] = value\n",
    "        disc_value.remove(value)\n",
    "        break  \n",
    "\n",
    "# Create loop for Wilcoxon test (two sided) - handle diff = 0\n",
    "for i in disc_key:\n",
    "    for j in disc_key:\n",
    "        if i != j:\n",
    "            disc_compare.append(f'{i} vs {j}')\n",
    "            # print(f'{i} vs {j}')\n",
    "            # Compute difference list\n",
    "            diff_list = []\n",
    "            for m in range(0, len(disc[i])):\n",
    "                diff = disc[i][m] - disc[j][m]\n",
    "                #print(disc[i][m])\n",
    "                #print(disc[j][m])\n",
    "#                 print('diff = ', diff)\n",
    "#                 print('-------------')\n",
    "                diff_list.append(diff)\n",
    "                # print(diff_list)\n",
    "                \n",
    "            if all(item == 0 for item in diff_list) == False: # if the diff list does not contain all 0\n",
    "                test_stat.append(stats.wilcoxon(diff_list, alternative = \"less\").statistic)\n",
    "                p_value.append(stats.wilcoxon(diff_list, alternative = \"less\").pvalue)\n",
    "            else: # if the diff list contain only0, cannot do Wilcoxon test\n",
    "                error = 'N/A'\n",
    "                test_stat.append(error)\n",
    "                p_value.append(error)\n",
    "# print(test_stat)\n",
    "# print(p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a3542a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 3 lists to dataframe\n",
    "disc_compare = pd.DataFrame(disc_compare, columns=['disc_compare'])\n",
    "test_stat = pd.DataFrame(test_stat, columns=['wtest_stat'])\n",
    "p_value = pd.DataFrame(p_value, columns=['p_value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "88580c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result table\n",
    "wt_result = pd.concat([disc_compare, test_stat, p_value], axis = 1)\n",
    "# Drop duplicate\n",
    "wt_result.drop_duplicates(subset=['p_value'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c639d795",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disc_compare</th>\n",
       "      <th>wtest_stat</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ewd vs efd</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.982915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ewd vs ffd</td>\n",
       "      <td>83.5</td>\n",
       "      <td>0.906189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ewd vs cm</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.889551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ewd vs dt</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.972321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>efd vs ewd</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.017085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>efd vs ffd</td>\n",
       "      <td>76.5</td>\n",
       "      <td>0.820435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>efd vs cm</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.783687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>efd vs dt</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0.963501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ffd vs ewd</td>\n",
       "      <td>36.5</td>\n",
       "      <td>0.093811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ffd vs efd</td>\n",
       "      <td>43.5</td>\n",
       "      <td>0.179565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ffd vs cm</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.091085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ffd vs dt</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.962677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>cm vs ewd</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.110449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>cm vs efd</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.216313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>cm vs ffd</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.908915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>cm vs dt</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.958374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>dt vs ewd</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.031860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>dt vs efd</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.041626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>dt vs ffd</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.037323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>dt vs cm</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.047302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   disc_compare  wtest_stat   p_value\n",
       "0    ewd vs efd        66.0  0.982915\n",
       "1    ewd vs ffd        83.5  0.906189\n",
       "2     ewd vs cm        72.0  0.889551\n",
       "3     ewd vs dt        93.0  0.972321\n",
       "4    efd vs ewd        12.0  0.017085\n",
       "5    efd vs ffd        76.5  0.820435\n",
       "6     efd vs cm        65.0  0.783687\n",
       "7     efd vs dt        91.0  0.963501\n",
       "8    ffd vs ewd        36.5  0.093811\n",
       "9    ffd vs efd        43.5  0.179565\n",
       "10    ffd vs cm        22.0  0.091085\n",
       "11    ffd vs dt        71.0  0.962677\n",
       "12    cm vs ewd        33.0  0.110449\n",
       "13    cm vs efd        40.0  0.216313\n",
       "14    cm vs ffd        56.0  0.908915\n",
       "15     cm vs dt        90.0  0.958374\n",
       "16    dt vs ewd        27.0  0.031860\n",
       "17    dt vs efd        29.0  0.041626\n",
       "18    dt vs ffd        20.0  0.037323\n",
       "19     dt vs cm        30.0  0.047302"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wt_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4712892c",
   "metadata": {},
   "source": [
    "## 1.3 Bias, only KNN-VDM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d62f5ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "15\n",
      "20\n",
      "20\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "# Preparation: Prepare list of metrics for each discretization (test_list)\n",
    "# Step 1: Obtain bias for each discretization, convert into numeric, string values will be return as NaN\n",
    "# Filter for Knn-VDM\n",
    "# Obtain bias for each discretization, convert into numeric, string values will be return as NaN\n",
    "ewd_bias_knn = pd.to_numeric(data[(data['disc']==\"EWD\") & (data['models']==\"Knn-VDM\")]['bias'],errors='coerce').tolist()\n",
    "efd_bias_knn = pd.to_numeric(data[(data['disc']==\"EFD\") & (data['models']==\"Knn-VDM\")]['bias'],errors='coerce').tolist()\n",
    "ffd_bias_knn = pd.to_numeric(data[(data['disc']==\"FFD\") & (data['models']==\"Knn-VDM\")]['bias'],errors='coerce').tolist()\n",
    "cm_bias_knn = pd.to_numeric(data[(data['disc']==\"ChiMerge\") & (data['models']==\"Knn-VDM\")]['bias'],errors='coerce').tolist()\n",
    "dt_bias_knn = pd.to_numeric(data[(data['disc']==\"ChiMerge\") & (data['models']==\"Knn-VDM\")]['bias'],errors='coerce').tolist()\n",
    "\n",
    "# Check number of metrics available for each discretizer\n",
    "print(len(ewd_bias_knn))\n",
    "print(len(efd_bias_knn))\n",
    "print(len(ffd_bias_knn))\n",
    "print(len(cm_bias_knn))\n",
    "print(len(dt_bias_knn))\n",
    "\n",
    "# Step 2: filter numeric values\n",
    "raw_list = [ewd_bias_knn,efd_bias_knn, ffd_bias_knn, cm_bias_knn, dt_bias_knn]\n",
    "num_list = [] # filter numeric values only\n",
    "for metric in raw_list:\n",
    "#     metric_new = []\n",
    "#     for x in metric:\n",
    "#         if math.isnan(x) == False:\n",
    "#             metric_new.append(x)\n",
    "    metric_new = [x for x in metric if (math.isnan(x) == False)] # using list comprehension\n",
    "    #print(metric_new)\n",
    "    #print(len(metric_new))\n",
    "    num_list.append(metric_new)\n",
    "    \n",
    "# Step 3: random sample\n",
    "# For discretization methods with different value, randomly select so that the final sample size are equal\n",
    "# Reference: https://docs.python.org/3/library/random.html\n",
    "k = min(len(metric) for metric in num_list)\n",
    "test_list = []\n",
    "for metric in num_list:\n",
    "    random.seed(20)\n",
    "    if len(metric) > k:\n",
    "        metric = random.sample(metric, k=k)\n",
    "    else: metric = metric\n",
    "    #print(metric)\n",
    "    test_list.append(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f8fed1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialiation\n",
    "disc_key = ['ewd', 'efd', 'ffd', 'cm', 'dt']\n",
    "disc_value = test_list # list of metrics for each discretization after preparation\n",
    "test_stat = []\n",
    "p_value = []\n",
    "disc_compare = []\n",
    "# Create dictionary store discretization and series of accuracy\n",
    "disc = {}\n",
    "for key in disc_key:\n",
    "    for value in disc_value:\n",
    "        disc[key] = value\n",
    "        disc_value.remove(value)\n",
    "        break  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bd943645",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anhtth/opt/anaconda3/lib/python3.9/site-packages/scipy/stats/morestats.py:3141: UserWarning: Exact p-value calculation does not work if there are ties. Switching to normal approximation.\n",
      "  warnings.warn(\"Exact p-value calculation does not work if there are \"\n",
      "/Users/anhtth/opt/anaconda3/lib/python3.9/site-packages/scipy/stats/morestats.py:3155: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    }
   ],
   "source": [
    "# Create loop for Wilcoxon test (two sided) - handle diff = 0\n",
    "for i in disc_key:\n",
    "    for j in disc_key:\n",
    "        if i != j:\n",
    "            disc_compare.append(f'{i} vs {j}')\n",
    "            #print(f'{i} vs {j}')\n",
    "            # Compute difference list\n",
    "            diff_list = []\n",
    "            for m in range(0, len(disc[i])):\n",
    "                diff = disc[i][m] - disc[j][m]\n",
    "                #print(disc[i][m])\n",
    "                #print(disc[j][m])\n",
    "#                 print('diff = ', diff)\n",
    "#                 print('-------------')\n",
    "                diff_list.append(diff)\n",
    "                # print(diff_list)\n",
    "                \n",
    "            if all(item == 0 for item in diff_list) == False: # if the diff list does not contain all 0\n",
    "                test_stat.append(stats.wilcoxon(diff_list, alternative = \"less\").statistic)\n",
    "                p_value.append(stats.wilcoxon(diff_list, alternative = \"less\").pvalue)\n",
    "            else: # if the diff list contain only0, cannot do Wilcoxon test\n",
    "                error = 'N/A'\n",
    "                test_stat.append(error)\n",
    "                p_value.append(error)\n",
    "# print(test_stat)\n",
    "# print(p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2263c095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 3 lists to dataframe\n",
    "disc_compare = pd.DataFrame(disc_compare, columns=['disc_compare'])\n",
    "test_stat = pd.DataFrame(test_stat, columns=['wtest_stat'])\n",
    "p_value = pd.DataFrame(p_value, columns=['p_value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "208a420b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result table\n",
    "wt_result = pd.concat([disc_compare, test_stat, p_value], axis = 1)\n",
    "# Drop duplicate\n",
    "wt_result.drop_duplicates(subset=['p_value'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1fa8cb9b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disc_compare</th>\n",
       "      <th>wtest_stat</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ewd vs efd</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.109375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ewd vs ffd</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.21875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ewd vs cm</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.28125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>efd vs ewd</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.921875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>efd vs ffd</td>\n",
       "      <td>12.5</td>\n",
       "      <td>0.65625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>efd vs cm</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.657085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ffd vs ewd</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.84375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ffd vs efd</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.34375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ffd vs cm</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>cm vs ewd</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.78125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>cm vs efd</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.342915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>cm vs ffd</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.578125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>cm vs dt</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   disc_compare wtest_stat   p_value\n",
       "0    ewd vs efd        4.0  0.109375\n",
       "1    ewd vs ffd        6.0   0.21875\n",
       "2     ewd vs cm        7.0   0.28125\n",
       "4    efd vs ewd       17.0  0.921875\n",
       "5    efd vs ffd       12.5   0.65625\n",
       "6     efd vs cm        9.0  0.657085\n",
       "8    ffd vs ewd       15.0   0.84375\n",
       "9    ffd vs efd        8.5   0.34375\n",
       "10    ffd vs cm       10.0       0.5\n",
       "12    cm vs ewd       14.0   0.78125\n",
       "13    cm vs efd        6.0  0.342915\n",
       "14    cm vs ffd       11.0  0.578125\n",
       "15     cm vs dt        N/A       N/A"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wt_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6025d7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
